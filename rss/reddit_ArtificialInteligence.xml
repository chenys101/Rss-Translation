<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 01 Jul 2025 18:33:02 GMT</lastBuildDate>
    <item>
      <title>这可能是我们见过的最原始形式。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8ijy/this_is_probably_the_rawest_form_well_ever_see_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  像互联网一样，我将来会考虑AI Chatbots会更具资本化。他们将开始在输出中引入广告或会员链接。  一些赞助商的内容可能很明显，但我担心他们可能会开始采用隐秘的方法来满足您的需求并向您出售东西。这些事情可能是超级操纵性的（出于明显的原因），我可以看到公司将其作为营销工具。 也许已经有一些已经这样做的Genai服务了。但是我认为，一旦炒作解决，我们将看到更多的事情，而AI公司需要其他手段来推动他们的服务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ava_lanche9     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8ijy/this_is_probably_the_rawest_form_well_ever_see_ai/</guid>
      <pubDate>Tue, 01 Jul 2025 17:55:13 GMT</pubDate>
    </item>
    <item>
      <title>创建我自己的AI助手，从头开始</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8hqt/creating_my_own_ai_assistant_from_scratch_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我想从头开始使用chatgpt做自己的AI助手。这是一个必须能够做所有事情的助手。我基本上希望它是我自己的jarvis。我希望能够要求它编写任何脚本并自行实施它以检查天气，检查股市，并在可能的情况下在线检查任何内容。要在议程中进行更改，请订购一些东西，...一切都在本地完成，以保护我的隐私。 ，因为我正在采用免费的Chatgpt计划，我现在正在努力使我的AI自动自动驾驶自主，因此我只能与我自己的AI一起工作，而不是与Cantgpt一起工作。经过大约40个小时的工作，我已经重新启动了，因为我学到了很多东西，我们（我和chatgpt）有点打破了AI。 我一直在与ChatGpt遇到的问题，以及为什么我想拥有自己的AI并运行自己的AI是为了为我编码，并且一直在为我编码，并且不断忘记我们的foldersstructure或我们在过去的工作。一旦对话变得不稳定，因为我无法编码并且不断复制代码很长时间，我就开始进行新的对话，并且必须再次解释某些事情，因为Chatgpt的内存也不是最好的。 我正在使用Ollama作为“ Engine”    如果您有任何技巧或技巧或想在我走得更远时进行更新，请让我知道。 现在，我已经建立了一个实时环境和一个实时环境，并且测试环境能够接触测试，并且现场测试能够检查并确保检查脚本的最新脚本，并在需要的情况下进行测试，并在测试中进行测试，并在测试中进行了测试，一旦完成了测试，则一旦完成了测试，一旦完成了测试，一旦完成了测试，则可以进行测试，一旦完成了测试，一旦需要进行测试。 Live So Live可以升级自身而不会崩溃的情况。 这似乎是踏入AI自主权的逻辑步骤。 ，我也没有编码背景，我不是系统工程师或其他。我很合乎逻辑，我喜欢学习，但绝不是我是编码员。 无论如何，我很想听听这里的每个人，想法，想法，评论，让它rip： - ）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/rouffious     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8hqt/creating_my_own_ai_assistant_from_scratch_with/</guid>
      <pubDate>Tue, 01 Jul 2025 17:54:22 GMT</pubDate>
    </item>
    <item>
      <title>本周在AI中为开发人员：OpenAi大脑排水，更便宜的成绩单和人为冠军的法律胜利</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8cwh/this_week_in_ai_for_devs_openai_brain_drain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是新闻/趋势/工具列表与开发人员相关我在上周（6月24日自6月24日以来）。主要是：前往元元的顶级OpenAi人才，拟人化的得分是合理的胜利，Salesforce依靠AI，以及Gemini Cli  等新工具，如果我错过了任何东西，请让我知道！  &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/rfizzy     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8cwh/this_week_in_ai_for_devs_openai_brain_drain/</guid>
      <pubDate>Tue, 01 Jul 2025 17:49:06 GMT</pubDate>
    </item>
    <item>
      <title>“非临床信息如何塑造LLM中的临床决策”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp5092/how_nonclinical_information_shapes_clinical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    “将大语模型（LLM）集成到临床诊断中，需要仔细了解用户输入的临床无关方面如何直接影响生成的治疗建议，从而对最终用户的临床结果进行临床结果。在研究人口属性对临床LLM推理的影响的先前研究的基础上，本研究探讨了非临床相关属性如何塑造LLM的临床决策。通过对患者信息的扰动，我们评估了当更改非临床信息时，LLM行为是否保持一致，准确和公正。这些扰动通过复制在电子数据处理期间可能发生的结构错误来评估临床LLM推理的脆弱性，并模拟多元化，脆弱的患者群体中患者AI系统之间的相互作用。我们的发现表明，LLM治疗建议和临床准确性的显着降解，以减少对患者的护理分配的方式显着降解。此外，性别亚组之间以及模型延长的性别亚组之间的治疗建议存在很大差异。我们还将扰动框架应用于会话临床数据集，以发现即使在对话中，LLM临床精度也会降低扰动后的扰动，并且在扰动影响性别亚组中的差异也存在。通过分析响应现实但修改的临床环境的LLM输出，我们的工作加深了对医学LLMS固有的敏感性，不准确性和偏见的理解，为部署患者AI Systems提供了关键的见解。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lp5092/how_nonclinical_information_shapes_clinical/”&gt; [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp5092/how_nonclinical_information_shapes_clinical/</guid>
      <pubDate>Tue, 01 Jul 2025 15:42:40 GMT</pubDate>
    </item>
    <item>
      <title>AI初创公司在确保负责任的发展和部署方面面临哪些关键的道德考虑和实际挑战？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在考虑明年申请Tetr College of商业AI计划，如果选择，我将建立AI-Power Ventures。但是，AI的道德含义在我看来。  除了理论讨论之外，实施负责任的AI开发和部署方面面临哪些实际挑战，尤其是对于资源有限的精益团队？ 我想确保我不仅要建立创新的，而且还建立了伦理和可信赖的AI Solutions      &lt;！ -  sc_-sc_on-&gt; &lt;！提交由＆＃32; /u/u/ubabu     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</guid>
      <pubDate>Tue, 01 Jul 2025 08:33:21 GMT</pubDate>
    </item>
    <item>
      <title>除了代码外，大语言模型在软件开发中的多维影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lowcw8/beyond_code_the_multidimensional_impacts_of_large/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要发展：“超越代码：大语模型在软件开发中的多维影响”，由Sardar Fatooreh Bonabi，Sarah Bana，Sarah Bana，Tingting Nian和Vijay Gurbarcaxani撰写。  本研究对诸如ChatGPT之类的大型语言模型（LLM）的方式提出了令人信服的见解，尤其是在开源软件（OSS）行业中。以下是一些关键发现：    生产力提高：访问CHATGPT会使开发人员的生产率提高了6.4％。有趣的是，在新手开发人员中观察到了最大的生产率提高，这表明LLMS极大地帮助了他们的编码工作。      增强的知识共享：Chatgpt的可用性还丰富了协作的协作，知识展示活动增加了9.6％的稳定后的恢复。这表明LLM促进了开发人员之间的社区参与和同行反馈。     技能获取改进：开发人员在Chatgpt Access禁令期间的技能获取下降8.4％，突显了其在促进新编程语言学习中的作用。该研究强调，LLM对处理复杂或文献记载的语言的开发人员特别有益。        依赖上下文依赖的益处：技能发展的影响各不相同，揭示了他们在技术上是在技术上是在技术上是在陡峭的学习环境中出现的最大优势，或者当开发人员面临陡峭的学习curves curves。效果：开发人员之间的不同经验水平表现出不同的好处。虽然新手开发人员在很大程度上依赖LLM来提高生产力，但中级开发人员可以最大化知识共享和技能提高，展示了对组织中量身定制的培训和使用策略的需求。     这些发现这些发现的需求强调了他们在软件开发方面的多元化范围，从而使他们在软件开发方面的范围内的范围不超出了范围的范围。增强。 在此处探索完整的故障：原始纸提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lowcw8/beyond_code_the_multidimensional_impacts_of_large/</guid>
      <pubDate>Tue, 01 Jul 2025 08:29:45 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻6/30/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lot1uu/oneminute_daily_ai_news_6302025/</link>
      <description><![CDATA[ Microsoft says new AI tool can diagnose patients 4 times more accurately than human doctors.[1] Apple weighs using Anthropic or OpenAI to power Siri in major reversal, Bloomberg News reports.[2] Amazon launches一个新的AI基金会模型，可以为其机器人车队提供动力并部署其第100万个机器人。[3]   A.I。视频从未过得更好。你能告诉你是真实的吗？[4]   包括： https://bushaicave.com/2025/06/06/06/30/one-news-daily-daily-news-news-news-news-news-6-6-6-6-6-30-30-30-20-20-20-20-25/  [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lot1uu/oneminute_daily_ai_news_6302025/</guid>
      <pubDate>Tue, 01 Jul 2025 04:54:17 GMT</pubDate>
    </item>
    <item>
      <title>大美丽的账单包括人工智能供应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loqtnw/big_beautiful_bill_includes_ai_provision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  喜欢标题，  BBB包括一项规定，该条款将为国家提供5亿次联邦资金来支持AI和宽带基础设施，前提是他们并没有针对AI的使用范围，但没有特别的范围，而是在保护儿童和coperift的情况下，并不是在保护儿童和coperifters of to dic dic of th dic dic of th dic of tim nifformate of th dic of to n of th dic of tim n of th dic of tim n of th do n of Surgruction of Die of ticrultion&#39;&#39;负担” AI系统和模型。  This also includes 6.1 billion dollars for infrastructure and systems used in border surveillance, 450 million dollars in AI autonomous naval shipbuilding, 145 million in AI for automated aerial naval attack drones, 250 million for AI projects in the US Cyber​​ Systems command, and a 115 million for AI systems that help protect nuclear facilities, to name a few. Seems to me like a decision在未固定的基础架构或负责任地使用AI之间。  思想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/criewolf     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loqtnw/big_beautiful_bill_includes_ai_provision/</guid>
      <pubDate>Tue, 01 Jul 2025 02:52:11 GMT</pubDate>
    </item>
    <item>
      <title>AI公司将如何使用REDDIT数据进行操作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loqsw8/how_will_ai_companies_use_reddit_data_for_traing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  几乎是标题。 Reddit是未验证的主张和意见的集合。这基本上是虚构的。 AI如何利用这些数据使自己更加聪明？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/14mth30n3     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1loqsw8/how_will_will_ai_ai_companies_cempanies_reddit_data_for_for_traing/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loqsw8/how_will_ai_companies_use_reddit_data_for_traing/</guid>
      <pubDate>Tue, 01 Jul 2025 02:51:02 GMT</pubDate>
    </item>
    <item>
      <title>LLM进度高原吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想我一直在想，LLM会在某个时候平稳，需要新的突破才能将其提升到一个新的水平。 您同意这一前提吗？如果是这样，您认为我们在哪里曲线？  或可能太模糊的问题，这完全取决于您如何衡量进度？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lomj6i/is_llm_llm_progress_plateau/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</guid>
      <pubDate>Mon, 30 Jun 2025 23:23:09 GMT</pubDate>
    </item>
    <item>
      <title>苹果公司正在考虑使用AI技术从人类或OpenAI来为Siri提供动力，从而使自己的内部型号旁观。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loimh2/apple_is_considering_using_ai_technology_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，苹果是否应该购买整个公司或为其技术合作的问题？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/creative-hotel8682     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loimh2/apple_is_considering_using_ai_technology_from/</guid>
      <pubDate>Mon, 30 Jun 2025 20:40:40 GMT</pubDate>
    </item>
    <item>
      <title>那么未来是每月200美元的型号吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lobzmn/so_the_future_is_200_per_month_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Max的困惑将以该价格推出，以及Google和Openai，其高级级别非常昂贵，最终将转化为较差的技术和较低层的工具。真正的技术霸主是否希望我们花一笔钱，而全世界95％的钱将是一个极其毫无疑问的艰辛？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lobzmn/so_the_future_is_is_is_200_per_per_month_models/”&gt; [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lobzmn/so_the_future_is_200_per_month_models/</guid>
      <pubDate>Mon, 30 Jun 2025 16:26:31 GMT</pubDate>
    </item>
    <item>
      <title>微软表示，其新的AI系统诊断出患者的精度是人类医生的4倍</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lo7m9h/microsoft_says_its_new_ai_system_diagnosed/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Microsoft团队使用了304个案例研究，该案例研究从《新英格兰医学杂志》中提出了一个名为“顺序诊断基准（SDBENCH）”的测试。一个语言模型将每个案例陷入了医生为了诊断而进行的逐步过程。  Microsoft的研究人员随后建立了一个名为MAI Diagnostic Croundestrator（MAI-DXO）的系统，该系统查询了几个领先的AI模型，其中包括GPT的Openai的GPT，Google的Google的Gemini，Enthropic的claude anda anda anda and anda and anda gpt，包括 在他们的实验中，Mai-Dxo的表现优于人类医生，与医生的20％相比，MAI-DXO的表现优于80％。它还通过选择较便宜的测试和程序将成本降低了20％。 &#39;这种编排机制 - 以这种持续链风格一起工作的多个代理 - 这将使我们更接近医疗超级智能，” Suleyman说。 。 href =“ https://www.wired.com/story/microsoft-medical-superintelligence-diabnosis/”&gt; href =“ https://www.reddit.com/user/wiredmagazine”&gt;/u/wiredmagazine     [link]   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lo7m9h/microsoft_says_its_new_ai_ai_system_diacnose/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lo7m9h/microsoft_says_its_new_ai_system_diagnosed/</guid>
      <pubDate>Mon, 30 Jun 2025 13:32:16 GMT</pubDate>
    </item>
    <item>
      <title>我们能否停止假装像Openai这样的公司的目标对人类有益，并最终承认这只是巨大的现金抢购吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lo1juj/can_we_stop_pretending_that_goals_of_companies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直一遍又一遍地听到相同的东西 -  AI在这里治愈癌症，它是为了解决气候危机和所有的大问题，我们太小了，无法解决。      bs bs在乌克兰（Putin虽然他唯一的目标是一场土地征服战争，以抓住乌克兰的矿物丰富部分。 与人工智能行业一样，这些公司一直在告诉我们，他们如何非营利的福族公司，这些公司只想帮助我们提高生活质量，而在未来的情况下，人类在未来的情况下却没有利润，因为未来的报道都会;他们肯定会交付。 现实是，整个行业都在围绕货币旋转 - 尽快变得肮脏的富人，同时忽略AI可能对我们产生的任何安全性或负面影响。多年来，Openai一直试图弄清楚如何解决各种问题，并在其研发部门中尝试许多不同的AI项目。他们拥有庞大的安全团队，希望确保负责任地发展而不会对人类产生负面影响。为什么这项技术如此受欢迎，如此受大公司如此之大的支持，以至于他们可以看到巨大的潜力来代替人类劳动力，而不是治愈癌症或解决气候，而是要削减人工工人并增加利润。 他们在其他方向上杀死了所有研究，以其他方向和拆除的安全团队杀死了所有的安全团队，停止了所有的公共研究，使所有东西都成为了所有的机密和分泌的东西，因为他们只是将所有这些都放在了所有这些方向上，因为他们只是在所有这些方向上，因为这一切只是在所有这些方向上，因为这一切只是在所有这些方向上，因为这一切只是在这些方向上，因为这一切只是在这些方向上，因为这一切都在这方面，因为它上的焦点是焦点。而且没有人关心这实际上是在破坏了数百万人的生活，而这些人在之前和将来都从事不错的工作，这很可能会破坏数十亿美元的生活。只要它会使他们成为数万万富翁。 好运，购买“便宜的毒品”治愈AI制造的癌症，这仅在您住在纸箱中的街道上时只有1000美元，因为AI杀死了人类可用的所有工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petr_bena     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lo1juj/can_we_stop_pretending_that_goals_of_companies/</guid>
      <pubDate>Mon, 30 Jun 2025 07:41:42 GMT</pubDate>
    </item>
    <item>
      <title>AMA：护栏与牵引牵引</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi reddit！ 我是Cary Coglianese，这是《期刊风险分析》中新文章的作者之一， 关于我们称为“牵引”策略的“牵引”策略的价值。在本文中，我的合着者， colton crum ，我解释了“皮带”策略是什么，以及为什么由于ai grodigation glive glive from Adimigation glive glive from Adimig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig的方法。  我们的目标是我们的论文激发有关有效AI监管的思维方式的富有成效的公共政策对话。因此，我们渴望讨论它。  您怎么看？ AI是否应该受到“护栏”或“皮带”的监管？   风险分析的发行人也可以在此之前发布问题和评论。您可以在此处访问文章： https://onlinelelibrary.wile.wile.wiley.com/doi/doi/epdf/10.1111/1111/risa.7000020 eytry of the Presteria可免费下载以下从： https：//papers.ssrn.com.ssrn.com/sol3/papers/ppapers.cfmstart prisher.abstrack_iid pripply pribly prangermative perter pr&gt; 风险分析文章在这里： https://www.sra.org/2025/05/25/the-future-of-ai-why-why-why-why-leashes-are-are-better-ter-than-guardrails/   对于那些有兴趣进一步采取狗行走规则和AI治理之间相似之处的人，我们还拥有一份全新的工作论文，题为“关于诱惑（和释放）AI创新”。我们也很高兴谈论它。可以通过SSRN： https://papers.ssrn.com/sol3/ppapers/ppapers.ppapers.cfm？有帮助的是，我和我的合着者在下面列出了我们的BIOS。  期待您的评论和问题。  cary   ###     Cary”&gt; Cary Coglianese 是爱德华·B·希尔斯法学教授，政治学教授，宾夕法尼亚大学宾夕法尼亚州监管计划主任。 Coglianese博士是一名领先的跨学科学者，讲述了技术和业务在政府决策中的作用，最近为有关人工智能及其在法律和公共政策中的影响而做出了贡献。他撰写了许多有关行政法，AI，风险管理，私人治理等的书籍和同行评审的文章。  是巴黎圣母院的计算机科学博士候选人。他的研究兴趣和出版物包括计算机愿景，生物识别技术，人类AI团队，解释性以及对AI和机器学习系统的有效监管和治理策略。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/carycoglianese     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</guid>
      <pubDate>Sun, 29 Jun 2025 15:08:29 GMT</pubDate>
    </item>
    </channel>
</rss>