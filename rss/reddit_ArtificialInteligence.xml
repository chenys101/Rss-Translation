<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 26 Sep 2025 15:25:21 GMT</lastBuildDate>
    <item>
      <title>VibeCoding的死亡</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nr46rn/the_death_of_vibecoding/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nr46rn/the_death_of_vibecoding/</guid>
      <pubDate>Fri, 26 Sep 2025 15:21:36 GMT</pubDate>
    </item>
    <item>
      <title>当智能会更好时：在公共服务中重新考虑AI（研究论文摘要）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nr1qqp/when_smarter_isnt_better_rethinking_ai_in_public/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在ICML会议记录中找到并有趣的论文，这是我的摘要和分析。您如何看待？ 并不是每个公共问题都需要一个尖端的AI解决方案。有时，诸如雇用更多的案例工作者之类的简单策略比复杂的预测模型更好。 A new study shows why machine learning is most valuable only at the first mile and the last mile of policy, and why budgets, not algorithms, should drive decisions. Full reference : U. Fischer-Abaigar, C. Kern, and J. C. Perdomo, “The value of prediction in identifying the worst-off”, arXiv preprint arXiv:2501.19334, 2025 Context Governments and public institutions increasingly use machine learning tools to identify vulnerable individuals, such as people at risk of long-term unemployment or poverty, with the goal of providing有针对性的支持。在以股权为中心的公共计划中，主要目标是优先为有需要的人（称为 worst-off ）的帮助。风险预测工具有望更明智地定位，但它们是有代价的：开发，培训和维护复杂模型需要金钱和专业知识。同时，更简单的策略，例如雇用更多的案例工作者或扩大外展览品，可能会为每花钱带来更大的收益。 关键结果 作者批判性地研究了这些设置中的宝贵预测工具的真正有价值的预测工具，尤其是与更传统的方法相比，诸如简单地扩大筛选能力（即更高的人）（评估更多人）。他们引入了一个正式的框架，以分析预测模型值得投资，以及何时其他政策杠杆（例如筛查更多的人）更有效。他们将数学模型与德国失业的现实案例研究结合在一起。 作者发现，在两个极端的预测中，预测是最有价值的：  当预测准确性非常低时（即在实施的早期实施阶段）时，即使很小的tweak s也可以促进trevions的较小trevions noct thece n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n Noction。  Perfect 是已经很高表现的系统。  这使得预测为 first mile   and  last mile 工具。 扩大筛选能力通常更有效，尤其是在许多系统中，许多系统都可以在当今的许多系统中运行。筛选更多的人比改善预测模型更具价值。例如，如果您想确定最贫穷的5％的人，但只能筛选1％的能力，那么改善预测就无济于事。您只是没有筛选足够的人。 本文重塑了我们如何评估公共服务中的机器学习工具。它挑战构建更好的模型通过表明改善预测的边际收益可能受到限制，尤其是从不错的基线开始时。简单的模型和扩展的访问可能会更具影响力，尤其是在预算和资源约束的系统中。 我的take  这是普遍认为更多更好的的普遍看法的另一个反面。并非每个问题都应通过大型机器解决，这篇论文清楚地表明，公共机构并不总是要求Advanced AI来完成工作。原因很简单：金钱。预算对于公共计划非常重要，高端AI工具的成本很高。 我们可以从这些发现中提出某种类比来给我们自己的生活。我们大多数人每天都越来越多地使用AI，即使是简单的任务，也没有考虑它实际成本以及更简单的解决方案是否可以完成这项工作。原因也很简单。由于我们仍处于AI-er时代的早期阶段，因此可以免费获得许多资源，要么是因为大玩家决定免费提供（目前，让客户迷上），要么是因为他们还没有找到一种巧妙的方式来货币化。但这不会永远持续下去。在某个时候，Openai和其他人将不得不赚钱。我们必须支付AI的费用。当这一天到来时，我们将不得不在这项研究中面临与德国政府相同的挑战：昂贵且复杂的AI模型或简单的廉价工具。会是什么？只有时间才能说明。 作为最终和无关的注释，我想知道Doge的人们对本文有何反应？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/piotrantonik     [links]       [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nr1qqp/when_smarter_isnt_better_rethinking_ai_in_public/</guid>
      <pubDate>Fri, 26 Sep 2025 13:44:24 GMT</pubDate>
    </item>
    <item>
      <title>我在AI中是菜鸟。请纠正我。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqwekr/i_am_noob_in_ai_please_correct_me/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，有两种创建AI应用程序的方法。要么做抹布，只不过是在提示中提供额外的上下文。或者您对其进行了限制，更改权重，因为您必须进行反向传播。 和小钱的小型开发人员只能将API称为大型AI公司。您不想在本地机器中运行AI，更不用说进行反向传播了。 我曾经在本地笔记本电脑中运行稳定的扩散。它变成了煎锅。 编辑：在此处，AI是我的意思是llm   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/wooden-bill-1432     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqwekr/i_am_noob_in_ai_please_correct_me/</guid>
      <pubDate>Fri, 26 Sep 2025 09:02:18 GMT</pubDate>
    </item>
    <item>
      <title>SF科技巨头Salesforce以14起诉讼迅速连续</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqvl2k/sf_tech_giant_salesforce_hit_with_14_lawsuits_in/</link>
      <description><![CDATA[在 href=&quot;https://www.sfgate.com/tech/article/salesforce-14-lawsuits-rapid-succession-21067565.php&quot;&gt;https://www.sfgate.com/tech/article/salesforce-14-lawsuits-rapid-succession-21067565.php  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/billbuild     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nqvl2k/sf_tech_giant_salesforce_hit_hit_with_with_with_14_lawsut_14_lawsuts_in/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqvl2k/sf_tech_giant_salesforce_hit_with_14_lawsuits_in/</guid>
      <pubDate>Fri, 26 Sep 2025 08:08:05 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek在其新自然论文中声称培训成本为29.4万美元。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqt8rk/deepseek_claims_a_294k_training_cost_in_their_new/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  作为我每日AI的unvritt摘要的一部分，我只是在 nature 中阅读了DeepSeek新R1模型的摘要，而294K $ 294K的培训成本则是一个非凡的主张。他们认为效率是一种强化学习方法。 对于这一巨大的主张，通常会有一个陷阱或权衡。在深入研究之前，我很好奇这个潜艇的最初想法是什么。通常，有了这些主张，总会有一个收获，当中国公司有时不存在透明度时。提交由＆＃32; /u/u/gkv856     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nqt8rk/deepseek_claims_a_294k_294k_cost_cost_cost_in_their_their_new/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqt8rk/deepseek_claims_a_294k_training_cost_in_their_new/</guid>
      <pubDate>Fri, 26 Sep 2025 05:39:20 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻9/25/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqsdnk/oneminute_daily_ai_news_9252025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     meta   ：一种发现和创建AI视频的新方法。[1]      google  google  deepmind添加了ai a ai a ai to in a ai for for a ai          您早上的内裤。[3]    Google  AI研究引入了一种新颖的机器学习方法，将TimesFM转换为几个学习者。[4]    包括： [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqsdnk/oneminute_daily_ai_news_9252025/</guid>
      <pubDate>Fri, 26 Sep 2025 04:48:00 GMT</pubDate>
    </item>
    <item>
      <title>我知道这没关系，但我补充说“请”希望AI有时会有所改善</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqs5ch/i_know_it_doesnt_matter_but_i_add_please_hoping/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  有时我粘在编码上时，我最终在提示的末尾键入“请”。不是因为它实际上改变了任何东西，而是因为我迫切希望AI停止绕过相同的解决方案，最后给我一些有用的东西。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/axonide     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nqs5ch/i_knove_it_to_it_doesnd_mater_matter_matter_but_i_add_please_hoping/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqs5ch/i_know_it_doesnt_matter_but_i_add_please_hoping/</guid>
      <pubDate>Fri, 26 Sep 2025 04:34:49 GMT</pubDate>
    </item>
    <item>
      <title>高调技术公共生活项目？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqrpoz/highbrow_technology_common_lives_project/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  与大眉技术的所有手动劳动AI培训工作有什么关系？  它们是“普通生活项目”的一部分。但是我找不到有关公司实际计划在此培训中进行的任何信息，或者该项目的内容。 有人知道更多吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/streachh     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqrpoz/highbrow_technology_common_lives_project/</guid>
      <pubDate>Fri, 26 Sep 2025 04:10:47 GMT</pubDate>
    </item>
    <item>
      <title>法律教授：唐纳德·特朗普（Donald Trump）的新的AI行动计划，以实现“毫无疑问和无挑战的全球技术优势”，这标志着AI治理的方法急剧逆转</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqme4d/law_professor_donald_trumps_new_ai_action_plan/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  他的计划包括数十个政策建议，由三个执行订单支撑： https://www.eurac.edu/en/blogs/eureka/eureka/Artaver--intelligence-trump-s-deregulation-and-the-ligarchization-of-politics-politics    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ok-tangelo605    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nqme4d/law_profesor_donald_trumps_new_ai_ai_action_plan/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqme4d/law_professor_donald_trumps_new_ai_action_plan/</guid>
      <pubDate>Thu, 25 Sep 2025 23:46:49 GMT</pubDate>
    </item>
    <item>
      <title>如果AI能够完成所有工作，或者比人类更好（或更好），未来会是什么样？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqj2vs/what_would_the_future_look_like_if_ai_could_do/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  想象一个未来，AI系统能够在相同甚至更高质量水平上执行人类几乎可以从事智力，创意或技术性的任何工作。在这种情况下，雇用人们从事基于知识或服务的工作（医生，科学家，教师，律师，工程师等）不再具有经济意义，因为AI可以更有效地以较低的成本来处理这些角色。   提出了一个巨大的问题：大多数工业不再需要人工劳动时会发生什么？毕竟，我们当前的经济建立在工作人员，赚取工资，然后将收入花在商品和服务上。但是，如果AI可以全面取代人工工人，那么谁在赚取工资，人们如何负担得起根本参与经济？ 一个可能的结果是，只有身体劳动仍然有价值的工作不仅仅是工作不仅仅是精神上的工作，还需要实际的身体上和努力。想想建筑工人，清洁工，农民，矿工或其他“努力”角色。先进的机器人技术最终也可以替代它们，但是与AI软件相比，物理自动化往往要昂贵得多，而且灵活性较低。如果这样做的话，我们可能最终会进入一个世界上，大多数人都局限于身体要求的工作，而AI则处理其他所有工作。 未来可能会看起来黯淡的世界：数十亿人本质上锁定了疲惫的工作，而小型的精英阶层则是一个很小的精英阶层，而AI，基础设施和利润。这样的经济似乎不可持续或稳定。 0.001％控制财富和其他人的社会生活在“奴隶般的”劳动条件下。 另一种可能性是社会可能适应：较短的工作时间（例如，人类每天只工作几个小时，AI在AI上工作，其余的基本收入），普遍的基本收入或全新的经济模式，而不是基于传统就业的全新经济模式。但是所有这些都需要对我们如何看待金钱，所有权和价值进行重大重组。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/okgreen7335    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nqj2vs/what_would_the_future_future_look_like_if_if_ai_could_do/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqj2vs/what_would_the_future_look_like_if_ai_could_do/</guid>
      <pubDate>Thu, 25 Sep 2025 21:24:07 GMT</pubDate>
    </item>
    <item>
      <title>苹果研究人员开发了简单的折叠，这是一种用于蛋白质折叠预测的轻量级AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nqggnl/apple_researchers_develop_simplefold_a/</link>
      <description><![CDATA[Apple researchers have developed SimpleFold, a new AI model for predicting protein structures that offers a more efficient alternative to existing solutions like DeepMind&#39;s AlphaFold. Key Innovation:  Uses &quot;flow matching models&quot; instead of traditional diffusion approaches Eliminates computationally expensive components like multiple sequence alignments (MSAs) and complex geometric updates Can transform random noise directly into structured protein predictions in a single step  Performance Highlights:  Achieves over 95% of the performance of leading models (RoseTTAFold2和alphafold2）在标准基准上 即使是最小的100m参数版本也达到了Esmfold绩效的90％的 在模型尺寸上测试的 从1亿至30亿参数     通过增加模型尺寸                 更快且计算密集 资源有限的研究人员更容易获得 潜在地加速药物发现和生物材料研究   该突破性的较简单，具有更简单的跨性别的体系模型，该模型具有更简单的竞争，并表明了更简单的竞争。社区。   source  source         &lt;！提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nqggnl/apple_researchers_develop_simplefold_a/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nqggnl/apple_researchers_develop_simplefold_a/</guid>
      <pubDate>Thu, 25 Sep 2025 19:40:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么AI不知道时不能承认？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nq7njj/why_cant_ai_just_admit_when_it_doesnt_know/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  使用所有这些高级AI工具，例如Gemini，Chatgpt，Blackbox AI，Clplexity等。为什么他们在不知道某事时仍然躲避承认？假信心和幻觉比说“ IDK，我不确定”更糟糕。”您是否认为AIS的下一个世代会更好地了解其极限？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/min4_     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nq7njj/why_cant_ai_just_admit_when_it_doesnt_know/</guid>
      <pubDate>Thu, 25 Sep 2025 14:03:53 GMT</pubDate>
    </item>
    <item>
      <title>被聘为AI技术专家，但我觉得完全是欺诈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nq7e6y/got_hired_as_an_ai_technical_expert_but_i_feel/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚签名为 ai技术专家。从表面上看，这听起来很棒……但是这就是事情：老实说，我不像我的隔壁邻居更像AI专家。 面试仅一个小时，没有技术测试，没有编码挑战，没有深入研究我的技能。 And now I’m supposed to be “the expert.” I’ve worked 7 years in data science, across projects in chatbots, pipelines, and some ML models, but stepping into this title makes me feel like a complete impostor. Does the title catch up with you over time, or is it just corporate fluff that I shouldn’t overthink?   提交由＆＃32; /u/u/ipecende_lynx715     [links]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nq7e6y/got_hired_as_as_as_ai_ai_ai_ai_ai_ai_ai_expert_expert_but_but_but_but_ii_feel/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nq7e6y/got_hired_as_an_ai_technical_expert_but_i_feel/</guid>
      <pubDate>Thu, 25 Sep 2025 13:53:37 GMT</pubDate>
    </item>
    <item>
      <title>Openai研究人员正在监视用于策划的模型，并发现这些模型已经开始开发自己的欺骗语言 - 关于被观察，被发现。在他们的私人刮擦板上，他们称人类为“观察者”。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nq2f74/openai_researchers_were_monitoring_models_for/</link>
      <description><![CDATA[&quot;When running evaluations of frontier AIs for deception and other types of covert behavior, we find them increasingly frequently realizing when they are being evaluated.&quot; &quot;While we rely on human-legible CoT for training, studying situational awareness, and demonstrating clear evidence of misalignment, our ability to rely on this degrades as models继续以标准英语的方式离开推理。提交由＆＃32; /u/metaknowing     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nq2f74/openai_researchers_were_monitoring_models_for/</guid>
      <pubDate>Thu, 25 Sep 2025 09:44:07 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>