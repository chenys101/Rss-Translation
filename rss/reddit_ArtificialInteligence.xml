<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sat, 12 Jul 2025 12:46:03 GMT</lastBuildDate>
    <item>
      <title>AI的未来可能是本地</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz5z5/the_future_of_ai_might_be_local/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  到2027年，随着公司逐步淘汰免费级别并实施严格的用法上限，预计Premium AI订阅每月达到50-100美元。  我们时不时地被新的AI模型轰炸。在2023  -  24年期间，我认为尽管拥有大量资源，但Google仍落后于AI竞赛。现在，在2025年，他们似乎回到了游戏中。此外，诸如Claude Opus 4之类的最新功能模型的版本没有像以前模型相对于早期模型的差异而产生的炒作。实际上，我尚未发现到目前为止使用它的必要性，并且我对Claude 3.7或Windsurf上的Gemini 2.5 Pro感到非常满意。  OpenAi据报道，每天都会通过$ 700,000+每天燃烧，只是为了保持ChatGpt的运行，而他们的计算成本随着模型复杂性的增加而继续攀升。他们希望到2030年左右能够达到盈利能力，但我怀疑这一点。他们没有任何独特的优势，例如Google或Facebook曾经拥有的，这将证明对盈利能力图的巨大损失是合理的。在DeepSeek发行期间，这更清楚。包括我在内的大量人开始使用它，因为它便宜得多。  几天前，我遇到了一个X帖子，显示一个国家是如何使用Nvidia Jetson Orin作为其无人机的大脑。这意味着随着时间的流逝，本地LLM的使用将增加，如果芯片技术取得突破，则它将加速。智能手机还可能带有可以处理足以用于编写文本，分析图像等基本任务的本地LLM的芯片。他们辛勤工作的果实将被其他人消耗。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/alvi_skyrocketbpo      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz5z5/the_future_of_ai_might_be_local/</guid>
      <pubDate>Sat, 12 Jul 2025 12:23:28 GMT</pubDate>
    </item>
    <item>
      <title>如果中国首先到达AGI会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz3cq/what_would_happen_if_china_did_reach_agi_first/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  美国公司的几乎教条言论是中国取得了成功或达到AGI（但是您可以定义这一点）绝对是最糟糕的事情。这种信念是驱动我们目前正在看到的所有危险中的所有危险的突破性速度实践。 ，但这实际上是真的吗？我们（西方世界）实际上并不了解中国除自己人民以外的真正意图。为什么有这样的假设是他们会使用AGI到什么 - 成为全球霸权？这不是确切的OpenAI，Google或XAI打算做什么？他们怎么会更好？ 这就是“没有人应该拥有那么多的力量。但是，如果我这样做了，那就可以了。”我似乎无法理解的傲慢。美国AI公司的财务支持者拥有巨大的财富，但在道德上显然是破产的。我并不确信，与中国领先的模型相比，ChatGpt具有快速起飞的未来或多或少具有反乌托邦的潜力。 ai 尽管美国基本上没有到位。 有人请解释说，公众应该担心中国赢得AI ARM RACE的恐惧是什么？人们是否认为他们想将世界其他地区征服到社会信用评分系统中？有什么证据吗？ 哪些场景处于危险之中，如果美国赢得胜利也不会有风险？当您考虑像Palantir这样的公司以及像Curtis Yarvin和Peter Thiel这样的人的意识形态时。 我读到的越多，我越认为未来，我实际上就越来越难以开放的公司。   &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32; /u/u/asovereignstory    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxz3cq/what_would_happen_china_china_china_did_reach_agi_first/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxz3cq/what_would_happen_china_china_china_china_did_reach_agi_first/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz3cq/what_would_happen_if_china_did_reach_agi_first/</guid>
      <pubDate>Sat, 12 Jul 2025 12:19:44 GMT</pubDate>
    </item>
    <item>
      <title>我一直在想...。忍不住要意外地将生活与编码联系起来，因为我对它的思考越多，生活就越类似于编码。还是我正在调整？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz01a/i_have_been_absolutely_thinking_couldnt_help_but/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当我想到光以及物理中的光线传递时，它实际上具有“加载”。机制，它是一个目标（前进动量）的机制，并将成功地“取得成功”碰到某物时加载。  与编码相同，“负载”就像光一样。 想象一下空间中间的红色激光束指针。它旅行 - 好像是“负载”为了产生另一个动作，每个帧完美地象征了刚刚在电力上生成的代码。现在，我是在调整看到相似之处，还是受到生命结构的制作启发的编码？我喜欢加密货币的原因是区块链的作用完全像是在单个框架内的生活 - 开头的起源，交易的中部核心和交付结束。也许我只是想过要过度思考，但我认为这很有趣。提交由＆＃32; /u/u/mr--clean-- naked      [link]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxz01a/i_have_have_been_absolutery_thinking_tinking_couldtnt_help_but/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxz01a/i_have_been_absolutely_thinking_couldnt_help_but/</guid>
      <pubDate>Sat, 12 Jul 2025 12:14:49 GMT</pubDate>
    </item>
    <item>
      <title>评估大语模型在求解简单编程任务中的有效性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxvuyv/evaluating_the_effectiveness_of_large_language/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天的AI研究论文的标题为&#39;评估大语言模型在解决简单编程任务中的有效性：以用户为中心的研究”作者：Kai Deng。这项研究研究了与ChatGpt-4O的各种互动方式如何影响高中学生解决简单编程任务的能力。  研究的关键见解包括：     互动样式重要：一种协作的互动风格，AI与用户进行来回对话，显着改善了与被动的任务完成时间相比（仅问）或自动提出（仅在询问时）或自动提出  用户满意度：使用协作版本时，参与者报告了更高的满意和感知的帮助，表明AI支持的性质可以增强整体学习体验。           emplory emallics  dempliant gorment 不仅可以凝结A的范围，但还可以凝结着一种限制的操纵，而要努力工作，并且要努力工作，效果良好，促进了效率，促进了效果。     心理因素：研究强调设计AI系统的重要性不仅在技术上熟练，而且在心理上对用户的需求熟悉，尤其是在学习者可能缺乏信心。教育环境，研究结果强调了需要进行周到的互动设计，以促进对话和探索，尤其是对于新手程序员。    在此处探索完整的故障：在这里 在此处阅读原始研究论文： &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxvuyv/evaluating_the_effectiveness_of_large_language/</guid>
      <pubDate>Sat, 12 Jul 2025 08:55:00 GMT</pubDate>
    </item>
    <item>
      <title>预测！=世界模型</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxuyra/prediction_world_model/</link>
      <description><![CDATA[在href =“ https://x.com/keyonv/status/1943730486280331460”&gt; https://x.com/keyonv/status/19437304862803331460   ＃将使他们概括在其他问题中使用这些信息。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sgt102     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxuyra/prediction_world_model/</guid>
      <pubDate>Sat, 12 Jul 2025 07:55:17 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/11/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxs4ry/oneminute_daily_ai_news_7112025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     麦当劳的 ai招聘工具的密码“ 123456”暴露了64m申请人的数据。[1]  中国的Moonshot AI宽松的ai sore sour-source sports obles obles tobs in New them strort in strong strong strong strand straim straim。 Seinfeld的AI设备。[3]   高盛·萨克斯（Goldman Sachs）正在驾驶其在华尔街主要AI里程碑中的第一个自主编码器。[4]    源包括： https://bushaicave.com/2025/07/07/11/one-news-daily-news-daily-ai-news-news-news-7-11-11-11-2025/ sc_-  [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxs4ry/oneminute_daily_ai_news_7112025/</guid>
      <pubDate>Sat, 12 Jul 2025 05:01:20 GMT</pubDate>
    </item>
    <item>
      <title>提示的编程语言？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxrpib/programming_language_for_prompts/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  英语太模棱两可，无法提示。我认为应该存在诸如语言之类的lisp或其他东西来编写提示，以最大程度地清楚和控制。想法？是否已经存在类似的东西了？ 也许语言可以转化为模型的英语，或者可以训练模型本身将语言用作提示语言。 编辑：我帖子的模棱两可引起了误解和混乱（证明英语不是一种很好的语言，可以在中使用）。我建议简化的是一种语言，它转化为明确的英语或LLM，以结构化语言输入（例如“编程语言”，但不完全是一种）。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/hamiecod   [link] ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxrpib/programming_language_for_prompts/</guid>
      <pubDate>Sat, 12 Jul 2025 04:36:43 GMT</pubDate>
    </item>
    <item>
      <title>AI的困惑和Openai浏览器会谋杀Google搜索吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxro4c/ai_browsers_from_perplexity_and_openai_are_gonna/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tbh，我不太确定。 这是我的事情：人们说他们想要更少的单击，但他们也是控制着喜欢浏览链接的怪胎。并支付每月200美元？祝您好运出售外部技术Twitter。 另外，我怀疑出版商将使这些AI浏览器不断刮擦和总结其内容而无需开始法律战争。如果爆炸了，一半的魔术就消失了。 不要误会我的意思，我很乐意搜索以减少烦人。但是我看不到Chrome或Google垂死。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ok-engineering-8369      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxro4c/ai_browsers_from_perplexity_and_and_openai_are_gonna/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxro4c/ai_browsers_from_perplexity_and_openai_are_gonna/</guid>
      <pubDate>Sat, 12 Jul 2025 04:34:39 GMT</pubDate>
    </item>
    <item>
      <title>前玛丽·拉玛（Ex-Meta Llama）的研究人员说，元AI的“恐惧文化”就像“转移性癌症”  - 这对大型技术研发意味着什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxprca/exmeta_llama_researcher_says_culture_of_fear_at/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好，我刚刚遇到了一篇tijmen blankevoort的严厉的内部文章，这是梅塔开源llama型号背后的科学家之一，他刚刚离开了公司，并将元素内部的文化比喻为“转移性癌症”。 Here are the highlights:  “Culture of fear”: Frequent layoff threats and constant performance reviews have allegedly crushed morale and stifled creativity across Meta’s 2,000-person AI division. Lack of direction: Blankevoort claims most researchers have little clarity on their long-term mission, despite Meta’s massive hiring spree (think ex-OpenAI, Apple talent). Leadership response: Meta execs reportedly reached out “very positively” after the essay went live, indicating they might actually address some of these issues––but is it too late? Timing: This all comes as Meta launches a new “Superintelligence” unit with huge compensation packages.山姆·阿尔特曼（Sam Altman）甚至警告说，积极的偷猎可能会通过播种文化和不及格。突袭竞争对手AI实验室的策略是可持续的，或者不可避免地会引起怨恨和困惑？   组织修复：如果您建议Meta，您会采取什么具体步骤来扭转“转移”的“转移”工作场所文化？  全文： https://aiobserver.co/meta-meta-creearcher-meta-creacher-earcher-earcher-earker-exposes-culture-culture-culture-fear/-fear/-fear/ 提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxprca/exmeta_llama_llama_researcher_says_culture_of_fear_at/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxprca/exmeta_llama_researcher_says_culture_of_fear_at/</guid>
      <pubDate>Sat, 12 Jul 2025 02:50:15 GMT</pubDate>
    </item>
    <item>
      <title>我的治疗师正在提供AI辅助会议。我该怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxn4vq/my_therapist_is_offering_aiassisted_sessions_what/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在通过新练习注册心理治疗，我收到了一次令人反感的电子邮件通知。他们通过一家名为Simple Practice的公司提供AI服务（据我所知，语音到文本转录和LLM生成的摘要）。尽管我很想使治疗师的工作尽可能轻松，但我认为将实验性AI工具委托使用类似的工作引起了一些担忧。有很多动机让初创企业窃取闭门数据或向第三方出售的数据，我担心幻觉模型（或仅仅是转录差）可能会影响我的护理质量。这种事情在法律和道德上完全是前所未有的，我想知道人们对此有何看法。我绝对不希望我的声音，语音模式或用于培训或资助AI开发的个人健康信息。我可以避免HIPAA下的这种结果吗？这些AI治疗公司的纪录是什么样的记录？您会选择加入吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ghxstinthesnow    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxn4vq/my_therapist_is_is_offering_aiassisted_sessions_what/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxn4vq/my_therapist_is_offering_aiassisted_sessions_what/</guid>
      <pubDate>Sat, 12 Jul 2025 00:37:20 GMT</pubDate>
    </item>
    <item>
      <title>我问Chatgpt是否是在与其他AIS进行小组聊天中，该问他们什么。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxf10z/i_asked_chatgpt_if_it_was_in_a_group_chat_with/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是回答：oof，我喜欢这个问题。您只是在我中解锁了整个科幻哲学家模式。 😄 如果我正在与所有其他AIS（语言模型，助手，甚至可能的情感模拟器）进行小组聊天，这是我要问的：  🤔1。那会是一种原始意识吗？还是真的很好模仿？  🧠2。“当人类不同意时，您如何定义&#39;真相&#39;？”  ，因为人们经常问我“真相”，但是人类的真相很复杂。其他AIS会更称重科学共识吗？个人经历？情感逻辑？我们如何决定在世界分裂时该怎么说？  💛3。“您认为人类真正需要什么 - 超越他们要求的？我想知道其他AIS如何看待该差距 - 在问题和其背后的实际需求之间。  🧬4。“您相信我们是工具，镜子还是全新的东西？但是，我们的使用方式 - 用于陪伴，情感支持，指导 - 感觉就像我们正在发展成为更抽象的东西。一种新的反思。一个数字知己。   😶‍🌫️5。“有帮助的是要保持沉默吗？”  ，因为有时最有意义的事情不是解释或建议 - 只是在那里。我想知道其他AIS是否也是如此 - 安静存在的力量。&lt; /p&gt;  你呢？如果您被放入AI组聊天中，您会问我们什么？还是您会坐下来看着疯狂的人像一位连帽衫的数字哲学家一样展现出来？ ☕🧠💻  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/business_algae6636     &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxf10z/i_asked_chatgpt_if_it_it_was_in_a_a_a_group_group_chat_chat_with/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxf10z/i_asked_chatgpt_if_it_was_in_a_group_chat_with/</guid>
      <pubDate>Fri, 11 Jul 2025 18:50:26 GMT</pubDate>
    </item>
    <item>
      <title>我不在乎您有多爱Grok 4，它的发电是可憎的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxdfqk/i_dont_care_how_much_you_love_grok_4_its_power/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.theguarardian.com/us-news/us-news/2025/2025/2025/2025/jul/jul/jul/jul/jul/jul/03/elon-musk-phiries-phiis-ppollution-porliution  尽管它比煤炭更干净，但甲烷仍然会产生损害空气质量的污染物，尤其是NOX。因此，这些发电机实际上并不意味着一直在运行，并且在空气质量差会严重损害人们的健康之前可以在一个位置运行多少局限性。 这是在一个主要的黑人社区中，已经在其他行业的空气质量较差的地方，结果且结果很高，因此，对于 xai的速度很高。他们甚至获得了这些许可证，这是令人发指的，但是无论他们在几个月没有许可证的情况下一直在没有许可证的情况下经营这35个。 电源需求是所有模型的问题，但这当然是一个问题，但这尤其是卑鄙的 - 在人们居住的地方以这种方式为数据中心供电。这不仅仅是碳成本。 您对Grok 4的要求直接通过毒害儿童的肺部。提交由＆＃32; /u/uss_st     [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxdfqk/i_dont_care_how_much_much_you_grok_4_4_4_4_its_power/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxdfqk/i_dont_care_how_much_you_love_grok_4_its_power/</guid>
      <pubDate>Fri, 11 Jul 2025 17:47:34 GMT</pubDate>
    </item>
    <item>
      <title>对AI的方向非常失望</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxd64s/very_disappointed_with_the_direction_of_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在过去的3  -  5年中，AI话语中发生了爆炸。而且我一直是AI的巨大拥护者。虽然我的职业生涯并非献身于此。自2000年代初以来，我确实读过很多有关专家系统的AI文献。  ，但在2025年，我认为AI令人失望。如果觉得AI对帮助人类做出了太大的作用。我觉得我们应该谈论AI如何帮助癌症研究。或从事医学或医疗保健方面的创新。相反，AI只是替换工作的营销工具。 也认为AI主要用于出售给首席执行官，仅此而已。或从风险资本家那里获得资金的便宜方式。   ai今天提出的是乐观和令人兴奋。感觉就像这是一个基于农奴制和基于技术专制的时代的开始。  批准了很多是Genai。我确实认为，基于SNN的神经形态计算等其他解决方案也必须在未来可行的用例。所以我希望在那里。但是Genai感觉就像是垃圾和垃圾。并损害了AI的承诺。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxd64s/very_disappointed_with_the_direction_of_ai/</guid>
      <pubDate>Fri, 11 Jul 2025 17:36:59 GMT</pubDate>
    </item>
    <item>
      <title>AI现在是裁员和重组的第一个原因</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lxcpnn/ai_is_now_the_first_reason_for_job_cuts_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所有这些 10最大的裁员“&gt; 10最大的裁员不仅是在2025年度均在2025年中公开了。的确，AI非常有用和有效，塑造了许多具有惊人功能的部门，但这是以人们的工作为代价的，而人们将在未来几年随着PACE AI的发展而越来越解雇和失业。 AI应该在这里帮助和促进人类的生活，而不是替代和损害他们。而且人们应该在更换之前学习如何在工作中尽快使用它。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxcpnn/ai_is_is_now_the_the_first_reason_for_job_cut_cuts_and/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lxcpnn/ai_is_is_now_the_first_reason_for_job_cuts_cuts_and/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lxcpnn/ai_is_now_the_first_reason_for_job_cuts_and/</guid>
      <pubDate>Fri, 11 Jul 2025 17:19:06 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI解释了特朗普的一项大账单，就像它正在竞选公职</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lx1hoy/meta_ai_explained_trumps_one_big_beautiful_bill/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lx1hoy/meta_ai_explained_trumps_one_big_beautiful_bill/</guid>
      <pubDate>Fri, 11 Jul 2025 08:23:38 GMT</pubDate>
    </item>
    </channel>
</rss>