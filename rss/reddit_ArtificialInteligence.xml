<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 08 Sep 2025 15:23:13 GMT</lastBuildDate>
    <item>
      <title>将LLM与自我评分的JSON Rubrics（CHATGPT vs LE CHAT/MISTRAL）进行比较</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbq3dp/comparing_llms_with_selfscoring_json_rubrics/</link>
      <description><![CDATA[I ran a small experiment to compare ChatGPT Pro 5 Thinking and Le Chat Pro Thinking (Mistral), but instead of just asking “who explains better,” I made them self-score their own answers in JSON against a strict rubric. I did this because most model comparisons are主观。我想要一种可重现的方法来基准：   相似性得分数学（如果子分数不累加，则不会夸大100s）。     证据要求（每个分数≥0.75都必须引用答案文本。   NA处理策略（没有偷偷摸摸的重新归一化）。  我的测试案例是两个硬域：PFIC/表格8621税收报告（美国税法复杂） +欧盟居住法的情况（以及其他5个测试案例）。两者都需要精确，引用和时间表。 我写了一份主评估者提示，该提示使模型：  输出输出一个实质性答案（your_answer）。 在标语上得分（通过/li&gt;          forts     {sellyity_score＆quot;：; quaritatory_accuracy＆quot;：{{0.95}; {得分＆quot＆quot;：1.0}}     数学失败：累加到〜94.7，而不是100     p1; p1; “固定得分为94.7”}，{优先级：; quot;我需要再次提示每一轮遵循规则执行。 Observations, Le Chat Pro has a habit of:  Fast, but consistently over-scores itself. Often giving itself 100.0/100 - though its dimension scores summed up lower (from 86.3 - 94.6) Using generic evidence (“Filing deadline discussed”?) instead of quoting citation. Leaning在非规则上（要求严格的规则执行时，要组成的东西）。     chatgpt pro观察    在数学上更严格，标记的缺陷/未知数，并提出了可行的改进。当模型膨胀自己的性能时，检查 +证据要求会暴露出来。 自我评分的标题将“主观感觉”变成可测量且可重复的东西。所有LLM都倾向于做出答案，而不是不知道。 观看一个LLM“成绩本身” A a+，而另一个红色衬里的人则既有趣又有见地的   ，这是一个爆炸。迫不及待地想自我审核更多的llms对待难题。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/goldczar     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbq3dp/comparing_llms_with_selfscoring_json_rubrics/</guid>
      <pubDate>Mon, 08 Sep 2025 15:01:13 GMT</pubDate>
    </item>
    <item>
      <title>Anthropic同意在AI版权案中达成15亿美元的和解协议</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbneu6/anthropic_agrees_to_15_billion_settlement_in_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，拟人化只是同意咳嗽 15亿美元 在盗版书籍上训练他们的AI。作为解决方案的一部分，作者的每本书  。 来源：  很酷，很酷。只是想知道……如果我将我在网上编写的所有随机内容添加到这些模型中……我欠了多少？ 🤔  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/calliope_kekule     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbneu6/anthropic_agrees_to_15_billion_settlement_in_ai/</guid>
      <pubDate>Mon, 08 Sep 2025 13:14:00 GMT</pubDate>
    </item>
    <item>
      <title>我担心我的同事和工作场所。不是因为我们都被替换，而是因为每个人都如此妄想...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbnbnx/im_concerned_for_my_colleagues_and_workplace_not/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我为在线心理健康服务工作。我们所有人都在家工作，并通过在线电子邮件类型消息，实时聊天和MH论坛等来支持不同年龄段的人。   是，我们的系统过去一直陷入困境。我们依靠手动回复单个消息，手动风险评估所有内容，依靠Google Drive，模板，Google表。我们似乎是一家公司，坚持AI无法有效地或以人类所能做的方式做事的想法。 让我们扮演我们角色的一个方面来说明这一点。使用我们服务的人可以使用在线生命日记来跟踪他们的思想并跟踪自己的感受。我们依靠一个单独的软件来编码日记条目，然后将其粘贴到Google表中。然后，我们将最新的表手动复制并粘贴在每个条目上，并检查风险，如有必要，并在每个用户配置文件上手动记录我们的操作。 我觉得这可以通过AI轻松完成，并进行一些巧妙的编程和提示。甚至没有那么清晰的TBF，哎呀，给我几天，我认为我可以分类。  另一个例子：消息传递。一家巨额利润的公司是否真的认为支付数百名辅导员单独输入对某人的回应而不是AI可以在需要的同时进行数千次的AI的回应是经济的？  我是一名实习治疗师，我看到了设计精良，精心制作的人际关系的好处。但是，即使我也能看到，当您将其归于声称自己想要一个人的人时，他们真正想要的是其他人知道与他们同在的世界的感觉的想法。  坦率地说，AI可以轻松地实现这一目标 - 它所需要的只是一家额外关注利润和效率的公司，您可以拥有一个在线治疗师，他们可能会像您一样犯错，但也可以访问最新的心理治疗理论，并且可以访问这种有缺陷的错误（如果这会使您更加舒适地感到更加舒适，则会使这种有缺陷的错误变得更加舒适）。  我并不是说像我为之工作的公司不应该存在，或者是对AI在这些领域中接管的特别是错误的。也许人们总是希望另一个人的“老式”支持。  ，但令我沮丧的是，我们不是诚实地谈论这个问题，或者对这意味着我们可以发展和发展的含义感到兴奋。  您回来的只是：&#39;IT将带我们的工作&#39;或“它不安全”或“我不信任它”    缺乏对我们家门口创新的细微差别和开放性的惊人。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1nbnbnx/im_concerned_for_my_my_colleagues_and_and_workplace_not/”&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbnbnx/im_concerned_for_my_colleagues_and_workplace_not/</guid>
      <pubDate>Mon, 08 Sep 2025 13:10:00 GMT</pubDate>
    </item>
    <item>
      <title>非线性动力学是AI的前进道路中缺失的步骤吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbm84i/is_nonlinear_dynamics_the_missing_step_in_ais/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai进度到目前为止的进步已经大大倾斜了野蛮的缩放量表 -  lanarger模型，更多的计算和不断扩展的数据集。该策略取得了令人印象深刻的结果，但也开始显示回报率降低。每个规模的飞跃成本要高得多，同时仅产生增量收益。如果智能不仅仅是统计模式匹配，那么下一个真正的进步可能不是大小，而是结构。与线性因果关系不同，非线性系统捕获反馈回路，临界点和对初始条件的敏感依赖性 - 蝴蝶效应的现实是，小变化会导致根本不同的结果。能够以这种方式推理的AI不仅可以预测数据的最有可能延续。它可以绘制出微妙的信号向外波纹，模式如何增强或取消以及整个系统如何在压力下发展。那是跟踪关系的智能，而不仅仅是表面相关性。 想象一下，这种AI在血浆行为中检测到了人类研究人员忽略的淡淡但危险的关系。本常异常似乎微不足道，但通过非线性动力学进行了追踪，它揭示了稳定融合反应的途径。在线性框架中无形的单一微妙变化可以解锁全新的能源生产时代。因此，问题是：AI研究是否应该开始将非线性动态整合到其核心体系结构中，而不是依靠野蛮的计算？如果是这样，此移动是否可以标记真正的“智能爆炸”，而不是通过原始马力，而是通过遵循改变一切的隐藏关联的能力？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/spinred     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbm84i/is_nonlinear_dynamics_the_missing_step_in_ais/</guid>
      <pubDate>Mon, 08 Sep 2025 12:21:12 GMT</pubDate>
    </item>
    <item>
      <title>AI软件与普通软件（未来实际上是前进的）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbjmas/ai_software_vs_normal_software_where_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人们没有意识到“正常”软件和AI驱动系统之间存在基本差异...      普通软件是基于规则的。如果发生了，请进行B。相同的输入→相同的输出。可预测但刚性。   AI软件是基于模型的。它从数据中学习模式。相同的输入→并非总是相同的输出。它可以适应，预测甚至有时令人惊讶。  目前，世界上大多数人仍在传统软件上运行。银行，航空公司，政府系统，所有确定性法规。但是AI在边缘处蔓延：欺诈检测，聊天机器人，推荐引擎，语音识别，自适应接口。&lt; /p&gt; 这是关键：并非所有内容都将被AI（核控制和飞机自动驾驶仪）代替。但是任何地方都可以触动人，语言，决策，偏好，感知，AI层正在成为新的正常状态...  我们正在输入某些人所说的“软件2.0”。，而不是工程师的硬编码硬编码，而不是在每个规则上进行硬编码，他们训练系统和形状数据集。 tiktok提要，Spotifyrecs。 企业：Microsoft copilot，Word/excel中的Microsoft Copilot，带有嵌入式AI的Salesforce，具有嵌入式的AI，物流平台，预测延迟。 npcs）。  那么……这是所有软件的未来吗？几乎是如此。在5  -  10年内，AI模块将作为登录屏幕标准化。如果您的应用程序无法适应，它将看起来已经过时了。 好奇这里的其他人认为...   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nice2bnice2     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbjmas/ai_software_vs_normal_software_where_the_future/</guid>
      <pubDate>Mon, 08 Sep 2025 10:00:17 GMT</pubDate>
    </item>
    <item>
      <title>如果AI接管，今天实际投资实际上是安全的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbjhbe/whats_actually_safe_to_invest_today_in_if_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直看到人们说AI将在接下来的10  -  25年中消除大量工作。如果这是真的，我试图弄清楚什么甚至不会被破坏。 我向chatgpt询问了想法，这给了我通常的模糊的东西。  所以我在这里问：如果大多数人最终失业或就业不足，什么实际上保持价值？我们看到放气了，一切都下降了吗？或者是否存在基本上“防护”的地区 - 例如食品，住房，土地，能源，医疗保健等。 您现在将您的钱投入到了10  -  20  -  30年的安全状态？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no/no-lion-8243     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbjhbe/whats_actually_safe_to_invest_today_in_if_ai/</guid>
      <pubDate>Mon, 08 Sep 2025 09:51:37 GMT</pubDate>
    </item>
    <item>
      <title>如果我们95％的人没有工作怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbhfl0/what_if_95_of_us_dont_have_a_job/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当失业率上升时，我们都在哭泣。 5％，6％，8％感到疯狂吗？ The AI we have today could replace 50–60% of existing jobs—imagine reaching AGI. One of today’s most shocking headline I found today is that Salesforce openly announced 4,000 layoffs after deploying ai 。  您认为您的工作安全吗？老实说，我觉得命运已经被封为时间问题了。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/gkv856     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbhfl0/what_if_95_of_us_dont_have_a_job/</guid>
      <pubDate>Mon, 08 Sep 2025 07:37:36 GMT</pubDate>
    </item>
    <item>
      <title>15 AI写作工具测试：残酷的真相</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbengw/15_ai_writing_tools_tested_the_brutal_truth/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbengw/15_ai_writing_tools_tested_the_brutal_truth/</guid>
      <pubDate>Mon, 08 Sep 2025 04:47:27 GMT</pubDate>
    </item>
    <item>
      <title>解决硬件瓶颈：OpenAI标志与Broadcom的$ 10B交易用于自定义AI芯片</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbee81/solving_hardware_bottlenecks_openai_signs_10b/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   OpenAI与Broadcom合作，通过巨额$ 100亿美元的订单，用于自定义AI服务器机架，以供应其下一代型号。宣布消息后，周五，他们的股票飙升了11％。  这是什么意思：AI的进度由于芯片短缺而撞墙，因此这协议突出了扩大规模所需的疯狂投资。定制芯片可以使AI培训更快，更便宜，从聊天机器人到科学研究的一切都可以加快突破性。但这也显示了AI军备竞赛现在如何与硬件有关 - 这是一个令人着迷的地方。   https://www.wsj.com/tech/tech/tech/tech/ai/ai/openai-broadcom-deal-deal-deal-abroad-deal-abood-chips-ai-ai-chips-chips-5c7201d2222222222  [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbee81/solving_hardware_bottlenecks_openai_signs_10b/</guid>
      <pubDate>Mon, 08 Sep 2025 04:32:44 GMT</pubDate>
    </item>
    <item>
      <title>是什么将AI主流化数十亿美元？关于人工智能时代社会层面的想法。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbdirh/what_will_make_ai_mainstream_for_billions_ideas/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我注意到AI Power用户之间的差距很大，那些理解，思考并可以尝试AI和其余的人之间的差距。其中包括CS人，心理学家，学者，一些企业家，经验丰富的开发人员和STEM的学生。总共大概不到1000万人，大多数人聚集在湾区和中国。 现在，一些快速数学：chatgpt，使用了最广泛使用的AI产品，报告约800m每月活跃的用户。从临时电子邮件和多个注册的重复项中考虑，我估计全球范围约400m唯一的用户。假设大多数触摸AI的人至少尝试过GPT，我们称AI用户的上限为 。 ，但这是捕获：大多数只是将其用作答案机器，学生作业的学生，​​少年开发代码，有影响力的人的内容（可怕）。同时，我们正在讨论AGI/ASI，自动化，安全性，情感和社会动态，并深入融入日常生活中。 即使40亿人有数字了解或具有一定的互联网访问，这将使他们进入这一转变，而不仅仅是被动旁观者，而是像参与者一样？在这个早期阶段，收养的不平等已经很大，而且只会加深。  这就是为什么我一直在思考：互联网繁荣使Facebook成为社交和主流。今天的AI等效是什么？我通常认为社交层是产品主流。将是什么或类型的社会层面？ （我不知道角色扮演或聊天机器人的有效性）   有什么想法吗？有什么想法或想象力吗？或观点。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/beyondplayful2229     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbdirh/what_will_make_ai_mainstream_for_billions_ideas/</guid>
      <pubDate>Mon, 08 Sep 2025 03:46:27 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻9/7/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbdij0/oneminute_daily_ai_news_972025/</link>
      <description><![CDATA[ ‘Godfather of AI’ says the technology will create massive unemployment and send profits soaring — ‘that is the capitalist system’.[1] OpenAI is reorganizing its Model Behavior team, a small but influential group of researchers who shape how the company’s AI models interact with people.[2]  拥抱脸开源式vision：一个新的多模式数据集，配备2400万个样品用于训练视觉模型（VLMS）[3]     openai  backs ai-made ai-made ai-made a-made动画片。 href =“ https://bushaicave.com/2025/09/07/one-minute-daily-daily-daily-ai-news-9-7-2025/”&gt; https://bushaicave.com/2025/09/09/07/07/one-minute-news-news-news-news-news-9-9-7-7-7-2025/-c-  [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbdij0/oneminute_daily_ai_news_972025/</guid>
      <pubDate>Mon, 08 Sep 2025 03:46:06 GMT</pubDate>
    </item>
    <item>
      <title>AI不仅是结束入门级工作。我们知道这是职业阶梯的终结（CNBC）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nbb5g1/ai_is_not_just_ending_entrylevel_jobs_its_the_end/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nbb5g1/ai_is_not_just_ending_entrylevel_jobs_its_the_end/</guid>
      <pubDate>Mon, 08 Sep 2025 01:47:29 GMT</pubDate>
    </item>
    <item>
      <title>关于AI的最危险的事情不是您认为的</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb3toy/the_most_dangerous_thing_about_ai_isnt_what_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  每个人都担心失业和机器人起义。这位物理学家认为，真正的威胁是认知漂移，对共享现实的逐渐侵蚀。 他的观点：AI不仅像人类那样传播错误信息，还可以从头开始构建整个现实。从未发生过的深击。从未进行过的研究。但是，从来没有存在的专家。 它发生缓慢。就像科罗拉多河通过谷物雕刻大峡谷谷物一样，我们信任的每一次小转变似乎都很微不足道，直到我们突然生活在完全不同的世界中。 我们已经看到了它：    -  ai-ai-ai-ne-priept&#39;&#39;对于任何主张，您想提出  - 算法，以决定值得一看的（再见，个人事实检查）  - 人们越来越信任AI顾问和虚拟助手来塑造他们的意见&lt; /p&gt; ，但在这里，作者错过了一些巨大的东西：人类一直在宣传和公司进行现实，并为未来的宣传而制造现实。 AI并没有发明假新闻，它只是使其可扩展和个性化。 ，当他谈论“现实控制”时相对于传统审查制度，或者当数据本身变得合成时，他的锚点失去了锚点，他正在做一些重要的事情。 最恐怖的部分？我们的大脑被连接到突然的威胁，而不是逐渐侵蚀。到认知漂移显而易见时，倒转可能为时已晚。 仅对于框架而言，值得阅读。认知漂移终于给了我们我们所有人都感动但无法表达的东西的话。  https://www.outlookindia.com/international/the-silent-threat-of-ai-epistemic-drift   提交由＆＃32; /u/u/petermossack     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb3toy/the_most_dangerous_thing_about_ai_isnt_what_you/</guid>
      <pubDate>Sun, 07 Sep 2025 20:24:54 GMT</pubDate>
    </item>
    <item>
      <title>AI气泡有多糟？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1nb01ke/just_how_bad_would_an_ai_bubble_be/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   rogékarma：“美国正在经历非凡的，AI燃料的经济繁荣：股市飙升，这要归功于AI-Camped Is相关的科技巨头的泡沫价值，而实际的经济却在数百万美元的投资中促进了数百万美元的投资中心。人们相信AI会使工人更加生产力，这反过来将使公司的利润提高到难以想象的水平。  未能在现实世界中传达。将最多的钱投入人工智能的技术巨头尚不在收回投资。研究表明，试图合并AI的公司几乎没有影响其底线。和寻求AI替代工作流离失所证据的经济学家大部分都空了。如果泡沫破裂，它可能会使互联网崩溃感到羞耻 - 而技术巨头及其硅谷支持者将不会是唯一受苦的人。当麻省理工学院的研究人员最近跟踪了300个公开披露的AI计划的结果时，他们发现95％的项目未能为利润带来任何增长。 McKinsey＆amp;公司发现，有71％的公司报告使用了生成AI，其中80％以上的公司报告说，该技术对收入没有“切实影响”。鉴于这些趋势，一家技术支持公司Gartner最近宣布，AI进入了技术发展的“幻灭之陷”阶段。然而，生产力最终会融入它，生产力飙升。延误和取消，今年发布的人通常比过去的模型更少得多。 href =“ https://theatln.tc/bwoz8ahp”&gt; https://theatln.tc/bwoz8ahp     &lt;！ -  sc_on-&gt; &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/theatlantic     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1nb01ke/just_how_bad_would_an_ai_bubble_be/</guid>
      <pubDate>Sun, 07 Sep 2025 17:59:04 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里要求社区提供帮助，在此帖子之外，这些问题将被删除。 每个人都可以回答：不促进自我促销，否参考或跟踪链接。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1n5ppdb/monthly_is_is_there_a_a_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1n5ppdb/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Mon, 01 Sep 2025 14:09:29 GMT</pubDate>
    </item>
    </channel>
</rss>