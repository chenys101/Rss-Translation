<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 01 Jul 2025 15:26:16 GMT</lastBuildDate>
    <item>
      <title>网格可以跟上AI疯狂的能量食欲吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp0n8d/can_the_grid_keep_up_with_ais_insane_energy/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着AI的爆炸，对电力的需求也是如此。培训和运行大型AI模型需要大量的数据中心，这些中心是 Energy Monsters 。单个AI服务器机架可以拉120kW，而普通架子只能仅5到10kW。将其乘以数千个架子，很明显：AI对电网施加了严重的压力。 问题？网格并不是为这种不可预测的高尖峰使用而建造的。在全球范围内，数据中心的能源需求预计在5年内将增加一倍，而AI是主要驱动力。如果没有任何变化，我们冒险停电，瓶颈和停滞的创新。帮助管理网格本身（优化流动，预测潮流）  底线：AI的能量需求是真实的，快速上升的，并且有可能超过空间基础架构。该技术正在向前赛车，但是网格需要赶上，或者从创新到气候目标的一切都可能撞到墙。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/secure_candidate_221      [link]     32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp0n8d/can_the_grid_keep_up_with_ais_insane_energy/</guid>
      <pubDate>Tue, 01 Jul 2025 12:41:56 GMT</pubDate>
    </item>
    <item>
      <title>AI初创公司在确保负责任的发展和部署方面面临哪些关键的道德考虑和实际挑战？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在考虑明年申请Tetr College of商业AI计划，如果选择，我将建立AI-Power Ventures。但是，AI的道德含义在我看来。  除了理论讨论之外，实施负责任的AI开发和部署方面面临哪些实际挑战，尤其是对于资源有限的精益团队？ 我想确保我不仅要建立创新的，而且还建立了伦理和可信赖的AI Solutions      &lt;！ -  sc_-sc_on-&gt; &lt;！提交由＆＃32; /u/u/ubabu     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</guid>
      <pubDate>Tue, 01 Jul 2025 08:33:21 GMT</pubDate>
    </item>
    <item>
      <title>除了代码外，大语言模型在软件开发中的多维影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lowcw8/beyond_code_the_multidimensional_impacts_of_large/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要发展：“超越代码：大语模型在软件开发中的多维影响”，由Sardar Fatooreh Bonabi，Sarah Bana，Sarah Bana，Tingting Nian和Vijay Gurbarcaxani撰写。  本研究对诸如ChatGPT之类的大型语言模型（LLM）的方式提出了令人信服的见解，尤其是在开源软件（OSS）行业中。以下是一些关键发现：    生产力提高：访问CHATGPT会使开发人员的生产率提高了6.4％。有趣的是，在新手开发人员中观察到了最大的生产率提高，这表明LLMS极大地帮助了他们的编码工作。      增强的知识共享：Chatgpt的可用性还丰富了协作的协作，知识展示活动增加了9.6％的稳定后的恢复。这表明LLM促进了开发人员之间的社区参与和同行反馈。     技能获取改进：开发人员在Chatgpt Access禁令期间的技能获取下降8.4％，突显了其在促进新编程语言学习中的作用。该研究强调，LLM对处理复杂或文献记载的语言的开发人员特别有益。        依赖上下文依赖的益处：技能发展的影响各不相同，揭示了他们在技术上是在技术上是在技术上是在陡峭的学习环境中出现的最大优势，或者当开发人员面临陡峭的学习curves curves。效果：开发人员之间的不同经验水平表现出不同的好处。虽然新手开发人员在很大程度上依赖LLM来提高生产力，但中级开发人员可以最大化知识共享和技能提高，展示了对组织中量身定制的培训和使用策略的需求。     这些发现这些发现的需求强调了他们在软件开发方面的多元化范围，从而使他们在软件开发方面的范围内的范围不超出了范围的范围。增强。 在此处探索完整的故障：原始纸提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lowcw8/beyond_code_the_multidimensional_impacts_of_large/</guid>
      <pubDate>Tue, 01 Jul 2025 08:29:45 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻6/30/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lot1uu/oneminute_daily_ai_news_6302025/</link>
      <description><![CDATA[ Microsoft says new AI tool can diagnose patients 4 times more accurately than human doctors.[1] Apple weighs using Anthropic or OpenAI to power Siri in major reversal, Bloomberg News reports.[2] Amazon launches一个新的AI基金会模型，可以为其机器人车队提供动力并部署其第100万个机器人。[3]   A.I。视频从未过得更好。你能告诉你是真实的吗？[4]   包括： https://bushaicave.com/2025/06/06/06/30/one-news-daily-daily-news-news-news-news-news-6-6-6-6-6-30-30-30-20-20-20-20-25/  [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lot1uu/oneminute_daily_ai_news_6302025/</guid>
      <pubDate>Tue, 01 Jul 2025 04:54:17 GMT</pubDate>
    </item>
    <item>
      <title>大美丽的账单包括人工智能供应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loqtnw/big_beautiful_bill_includes_ai_provision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  喜欢标题，  BBB包括一项规定，该条款将为国家提供5亿次联邦资金来支持AI和宽带基础设施，前提是他们并没有针对AI的使用范围，但没有特别的范围，而是在保护儿童和coperift的情况下，并不是在保护儿童和coperifters of to dic dic of th dic dic of th dic of tim nifformate of th dic of to n of th dic of tim n of th dic of tim n of th do n of Surgruction of Die of ticrultion&#39;&#39;负担” AI系统和模型。  This also includes 6.1 billion dollars for infrastructure and systems used in border surveillance, 450 million dollars in AI autonomous naval shipbuilding, 145 million in AI for automated aerial naval attack drones, 250 million for AI projects in the US Cyber​​ Systems command, and a 115 million for AI systems that help protect nuclear facilities, to name a few. Seems to me like a decision在未固定的基础架构或负责任地使用AI之间。  思想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/criewolf     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loqtnw/big_beautiful_bill_includes_ai_provision/</guid>
      <pubDate>Tue, 01 Jul 2025 02:52:11 GMT</pubDate>
    </item>
    <item>
      <title>AI公司将如何使用REDDIT数据进行操作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loqsw8/how_will_ai_companies_use_reddit_data_for_traing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  几乎是标题。 Reddit是未验证的主张和意见的集合。这基本上是虚构的。 AI如何利用这些数据使自己更加聪明？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/14mth30n3     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1loqsw8/how_will_will_ai_ai_companies_cempanies_reddit_data_for_for_traing/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loqsw8/how_will_ai_companies_use_reddit_data_for_traing/</guid>
      <pubDate>Tue, 01 Jul 2025 02:51:02 GMT</pubDate>
    </item>
    <item>
      <title>下行情况是什么样的？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lomyr9/what_does_the_downside_case_look_like/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果Ai/vr的方式被夸大了AI，那么这种情况是什么样的？ ，假设LLM在过去五年中没有在未来5年中前进。  显然，所有创业公司都失去了资金，最终崩溃了，并被购买。还有什么？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/steelmanfallacy     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lomyr9/what_does_the_downside_case_look_like/</guid>
      <pubDate>Mon, 30 Jun 2025 23:42:47 GMT</pubDate>
    </item>
    <item>
      <title>AI上疲倦的千禧一代的沉思</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lompi9/musings_of_a_weary_millennial_on_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lompi9/musings_of_a_weary_millennial_on_ai/</guid>
      <pubDate>Mon, 30 Jun 2025 23:31:09 GMT</pubDate>
    </item>
    <item>
      <title>LLM进度高原吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想我一直在想，LLM会在某个时候平稳，需要新的突破才能将其提升到一个新的水平。 您同意这一前提吗？如果是这样，您认为我们在哪里曲线？  或可能太模糊的问题，这完全取决于您如何衡量进度？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lomj6i/is_llm_llm_progress_plateau/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</guid>
      <pubDate>Mon, 30 Jun 2025 23:23:09 GMT</pubDate>
    </item>
    <item>
      <title>苹果公司正在考虑使用AI技术从人类或OpenAI来为Siri提供动力，从而使自己的内部型号旁观。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loimh2/apple_is_considering_using_ai_technology_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，苹果是否应该购买整个公司或为其技术合作的问题？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/creative-hotel8682     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loimh2/apple_is_considering_using_ai_technology_from/</guid>
      <pubDate>Mon, 30 Jun 2025 20:40:40 GMT</pubDate>
    </item>
    <item>
      <title>同意还是不同意？：“ AI可以将人文学科作为一个受欢迎的研究领域催化兴趣”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lof9oo/agree_or_disagree_ai_could_catalyze_interest_in/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我刚刚阅读共同智慧：与沃顿商业教授Ethan Mollick一起生活和与AI 一起生活和合作。这是我在AI上读过的最好的东西，不是我同意其中的所有内容...但是，他比我更了解。那就是，有一部分对我来说是过分乐观的。我已经粘贴了下面的完整段落，但是要点是在这句话中：“ AI可以催化对人文科学的兴趣，因为人文学科的知识使AI用户具有独特的资格来与AI一起使用AI。但是，我只是看不到AI激励人文学科的研究，至少不是在社会规模上。我希望我错了，他是对的。您如何看待？ 完整的通过：   AI接受了大量人类文化遗产的训练，因此通常可以最好由了解该遗产的人挥舞着。为了让AI做独特的事情，您需要比使用相同的AI系统更深入地了解文化的某些部分。因此，现在，在许多方面，人文专业可以生产一些最有趣的“代码”。作家通常是提示AI的书面材料的最好的，因为他们擅长描述他们想要创造的效果（“以不祥的音符结束”，“使音调变得越来越疯狂”）。他们是好的编辑，因此他们可以向AI提供说明（“使第二段更加生动”）。他们可以通过了解两者的许多例子来快速对观众和样式进行实验（“像纽约客一样使这一切都像约翰·麦克菲（John McPhee）的风格”）。他们可以操纵叙事，使AI以他们想要的方式思考。 Chatgpt不会在乔治·华盛顿和特里·格罗斯之间进行采访，因为这种情况似乎令人难以置信。但是，如果您说服乔治·华盛顿（George Washington）可能有一台时间机器，很乐意回复。  ...  我们的新AIS已经接受了大量文化历史的培训，并正在使用它来为我们提供文本和图像来响应我们的查询。但是，没有索引或映射他们所知道的以及他们可能最有帮助的地方。因此，我们需要对不寻常领域有深入或广泛了解的人来以其他人无法使用的方式使用AI，开发出意外而有价值的提示并测试其工作方式的局限性。 AI可以将人文学科作为一个受欢迎的研究领域催化兴趣，因为人文科学的知识使AI使用者具有独特的资格与AI合作。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/staticsand     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lof9oo/agree_or_disagree_ai_could_catalyze_interest_in/</guid>
      <pubDate>Mon, 30 Jun 2025 18:30:21 GMT</pubDate>
    </item>
    <item>
      <title>那么未来是每月200美元的型号吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lobzmn/so_the_future_is_200_per_month_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Max的困惑将以该价格推出，以及Google和Openai，其高级级别非常昂贵，最终将转化为较差的技术和较低层的工具。真正的技术霸主是否希望我们花一笔钱，而全世界95％的钱将是一个极其毫无疑问的艰辛？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lobzmn/so_the_future_is_is_is_200_per_per_month_models/”&gt; [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lobzmn/so_the_future_is_200_per_month_models/</guid>
      <pubDate>Mon, 30 Jun 2025 16:26:31 GMT</pubDate>
    </item>
    <item>
      <title>微软表示，其新的AI系统诊断出患者的精度是人类医生的4倍</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lo7m9h/microsoft_says_its_new_ai_system_diagnosed/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Microsoft团队使用了304个案例研究，该案例研究从《新英格兰医学杂志》中提出了一个名为“顺序诊断基准（SDBENCH）”的测试。一个语言模型将每个案例陷入了医生为了诊断而进行的逐步过程。  Microsoft的研究人员随后建立了一个名为MAI Diagnostic Croundestrator（MAI-DXO）的系统，该系统查询了几个领先的AI模型，其中包括GPT的Openai的GPT，Google的Google的Gemini，Enthropic的claude anda anda anda and anda and anda gpt，包括 在他们的实验中，Mai-Dxo的表现优于人类医生，与医生的20％相比，MAI-DXO的表现优于80％。它还通过选择较便宜的测试和程序将成本降低了20％。 &#39;这种编排机制 - 以这种持续链风格一起工作的多个代理 - 这将使我们更接近医疗超级智能，” Suleyman说。 。 href =“ https://www.wired.com/story/microsoft-medical-superintelligence-diabnosis/”&gt; href =“ https://www.reddit.com/user/wiredmagazine”&gt;/u/wiredmagazine     [link]   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lo7m9h/microsoft_says_its_new_ai_ai_system_diacnose/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lo7m9h/microsoft_says_its_new_ai_system_diagnosed/</guid>
      <pubDate>Mon, 30 Jun 2025 13:32:16 GMT</pubDate>
    </item>
    <item>
      <title>我们能否停止假装像Openai这样的公司的目标对人类有益，并最终承认这只是巨大的现金抢购吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lo1juj/can_we_stop_pretending_that_goals_of_companies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直一遍又一遍地听到相同的东西 -  AI在这里治愈癌症，它是为了解决气候危机和所有的大问题，我们太小了，无法解决。      bs bs在乌克兰（Putin虽然他唯一的目标是一场土地征服战争，以抓住乌克兰的矿物丰富部分。 与人工智能行业一样，这些公司一直在告诉我们，他们如何非营利的福族公司，这些公司只想帮助我们提高生活质量，而在未来的情况下，人类在未来的情况下却没有利润，因为未来的报道都会;他们肯定会交付。 现实是，整个行业都在围绕货币旋转 - 尽快变得肮脏的富人，同时忽略AI可能对我们产生的任何安全性或负面影响。多年来，Openai一直试图弄清楚如何解决各种问题，并在其研发部门中尝试许多不同的AI项目。他们拥有庞大的安全团队，希望确保负责任地发展而不会对人类产生负面影响。为什么这项技术如此受欢迎，如此受大公司如此之大的支持，以至于他们可以看到巨大的潜力来代替人类劳动力，而不是治愈癌症或解决气候，而是要削减人工工人并增加利润。 他们在其他方向上杀死了所有研究，以其他方向和拆除的安全团队杀死了所有的安全团队，停止了所有的公共研究，使所有东西都成为了所有的机密和分泌的东西，因为他们只是将所有这些都放在了所有这些方向上，因为他们只是在所有这些方向上，因为这一切只是在所有这些方向上，因为这一切只是在所有这些方向上，因为这一切只是在这些方向上，因为这一切只是在这些方向上，因为这一切都在这方面，因为它上的焦点是焦点。而且没有人关心这实际上是在破坏了数百万人的生活，而这些人在之前和将来都从事不错的工作，这很可能会破坏数十亿美元的生活。只要它会使他们成为数万万富翁。 好运，购买“便宜的毒品”治愈AI制造的癌症，这仅在您住在纸箱中的街道上时只有1000美元，因为AI杀死了人类可用的所有工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petr_bena     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lo1juj/can_we_stop_pretending_that_goals_of_companies/</guid>
      <pubDate>Mon, 30 Jun 2025 07:41:42 GMT</pubDate>
    </item>
    <item>
      <title>AMA：护栏与牵引牵引</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi reddit！ 我是Cary Coglianese，这是《期刊风险分析》中新文章的作者之一， 关于我们称为“牵引”策略的“牵引”策略的价值。在本文中，我的合着者， colton crum ，我解释了“皮带”策略是什么，以及为什么由于ai grodigation glive glive from Adimigation glive glive from Adimig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig的方法。  我们的目标是我们的论文激发有关有效AI监管的思维方式的富有成效的公共政策对话。因此，我们渴望讨论它。  您怎么看？ AI是否应该受到“护栏”或“皮带”的监管？   风险分析的发行人也可以在此之前发布问题和评论。您可以在此处访问文章： https://onlinelelibrary.wile.wile.wiley.com/doi/doi/epdf/10.1111/1111/risa.7000020 eytry of the Presteria可免费下载以下从： https：//papers.ssrn.com.ssrn.com/sol3/papers/ppapers.cfmstart prisher.abstrack_iid pripply pribly prangermative perter pr&gt; 风险分析文章在这里： https://www.sra.org/2025/05/25/the-future-of-ai-why-why-why-why-leashes-are-are-better-ter-than-guardrails/   对于那些有兴趣进一步采取狗行走规则和AI治理之间相似之处的人，我们还拥有一份全新的工作论文，题为“关于诱惑（和释放）AI创新”。我们也很高兴谈论它。可以通过SSRN： https://papers.ssrn.com/sol3/ppapers/ppapers.ppapers.cfm？有帮助的是，我和我的合着者在下面列出了我们的BIOS。  期待您的评论和问题。  cary   ###     Cary”&gt; Cary Coglianese 是爱德华·B·希尔斯法学教授，政治学教授，宾夕法尼亚大学宾夕法尼亚州监管计划主任。 Coglianese博士是一名领先的跨学科学者，讲述了技术和业务在政府决策中的作用，最近为有关人工智能及其在法律和公共政策中的影响而做出了贡献。他撰写了许多有关行政法，AI，风险管理，私人治理等的书籍和同行评审的文章。  是巴黎圣母院的计算机科学博士候选人。他的研究兴趣和出版物包括计算机愿景，生物识别技术，人类AI团队，解释性以及对AI和机器学习系统的有效监管和治理策略。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/carycoglianese     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</guid>
      <pubDate>Sun, 29 Jun 2025 15:08:29 GMT</pubDate>
    </item>
    </channel>
</rss>