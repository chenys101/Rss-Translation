<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Wed, 02 Jul 2025 12:49:48 GMT</lastBuildDate>
    <item>
      <title>Zuck在这里丢弃了3亿美元的优惠，例如GPU拍卖</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpuqky/zuck_out_here_dropping_300m_offers_like_its_a_gpu/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  首先，我们观看了模型Evals变成排行榜弹性。现在，它变成了完整的角斗士竞技场。顶级人工智能研究人员偷猎了竞争对手早期出口的报价。 we’re talking $20M base, $5M equity, $275M in “structured comp” just to not go to another lab. on the surface it&#39;s salary wars, but under it, it&#39;s really about: – who controls open weights vs gated APIs – who gets to own the next agentic infra layer – who can ship faster without burning out every researcherall this compute, hiring, and模型缩放及每个人的evals是基准结合的，并且是边界的同名。 狂野的时代。我们曾经开玩笑说“书呆子战争”。这只是变压器形式的资本主义。您认为当薪水扭曲时，您实际上是谁赢了，实验室，创始人或堆栈溢出线程从现在起18个月？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/fune_agi   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lpuqky/zuck_outd_here_here_here_dropping_300m_offers_like_like_its_its_a_gpu/”&gt; [links]       &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lpuqky/zuck_out_here_here_here_dropping_300m_offers_like_like_its_a_a_gpu/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpuqky/zuck_out_here_dropping_300m_offers_like_its_a_gpu/</guid>
      <pubDate>Wed, 02 Jul 2025 12:37:15 GMT</pubDate>
    </item>
    <item>
      <title>我们接近模拟吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpt1yi/are_we_this_close_to_a_simulation/</link>
      <description><![CDATA[Pretty much with text to video now, if we give a chat bot the prompt to “continuously generate text in a story like format from the first person perspective of a human character going about their day with no breaks or cuts in real time, in a universe where all the laws of physics are identical to the real one” then link this up to the text to video features we will essentially have an ongoing simulation from the对某人生活的第一人称视角？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nergp     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpt1yi/are_we_this_close_to_a_simulation/</guid>
      <pubDate>Wed, 02 Jul 2025 11:10:55 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt vs Grok辩论。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lprby8/chatgpt_vs_grok_debate/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lprby8/chatgpt_vs_grok_debate/</guid>
      <pubDate>Wed, 02 Jul 2025 09:25:16 GMT</pubDate>
    </item>
    <item>
      <title>将大学政策调整为HI中的生成AI机遇，挑战和政策解决方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpqkcc/adapting_university_policies_for_generative_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天的聚光灯在“将大学政策改编成生成的AI：高等教育中的机遇，挑战和政策解决方案”中，”罗素·比尔（Russell Beale）迷人的AI纸。  本文探讨了在高等教育中的生成AI，尤其是大型语言模型（LLM）的快速整合，揭示了变革的机会和重大挑战。  Key insights from the research include:  Significant Student Usage: Nearly 47% of university students are utilizing LLMs for coursework, with alarming figures indicating 39% use these tools for exam questions and 7% for complete assignments, which raises red flags about academic integrity. Detection限制：当前的AI检测工具达到了88％的精度，而未被发现的AI生成的内容的12％。在学术评估中，这一短缺强调了需要更强大的多层执法和人类监督。       AI 的双刃剑：而LLMS可以大大提高研究的生产力和精简任务，例如文学和简化的审查和简化的审查和编码，他们的过度思考，并理解了批判性的学生，并构成了质疑的学生。本文主张将AI整合为学习辅助的教学声音实践，而不是捷径。        政策建议：强调自适应大学政策的必要性，强调了在可接受的AI使用方面的重要性，并重点介绍了可接受的AI使用，并重新介绍了扩展的学习过程，并重点介绍了学习过程，并重点介绍了学习过程，并重点介绍了学习过程，并重点介绍了学习的过程学生。     公平关注：该研究确定了社会经济和性别界线的AI使用的显着差异，这表明机构政策必须弥补这些差距，以弥合这些差距，以防止教育中的现有不平等。 adaptations in universities to responsibly harness the benefits of generative AI while safeguarding academic integrity and equity. Explore the full breakdown here: Here在此处阅读原始研究论文：原始纸    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpqkcc/adapting_university_policies_for_generative_ai/</guid>
      <pubDate>Wed, 02 Jul 2025 08:33:17 GMT</pubDate>
    </item>
    <item>
      <title>人工智能版权战争法律评论：在卡德里案中，为什么尚布里亚法官做了他做的不寻常的事情？而且，他接下来会做什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpqhrj/ai_copyright_wars_legal_commentary_in_the_kadrey/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpqhrj/ai_copyright_wars_legal_commentary_in_the_kadrey/</guid>
      <pubDate>Wed, 02 Jul 2025 08:28:17 GMT</pubDate>
    </item>
    <item>
      <title>如果AI工具推进了行业，该行业会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpp90j/what_happen_to_industry_if_ai_tools_advance/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当涉及LLM和其他各种AI工具和平台时，我对它们的观察越多，我越多的问题，我看到他们从真正无法真正将连贯的句子放在一起，直到现在，直到现在，还有什么进步，如果他们进一步进步。例如，现在通常说他们对复杂项目编写代码有实际限制。如果发生这种变化，会发生什么？ 如果这些AI工具推进了80％至100％的代码，对于任何目的的任何可能目的的可疑产品，都可以通过正确的指导和指导AI方法生成什么？而且，即使该代码不像开发人员Wiz所写的那样很好地组合在一起，它是可行的，安全和安全的，并且不需要未来的软件工程师浪潮才能进入并在使用后进行修复吗？如何设法提出竞争对手浪潮中无法从他们身下取出的任何东西？当AI方向与在其他地方找到正确采购的代码相结合时，可以将未来的产品变得可行？尽管如此，我还是想思考并想知道这是否意味着只有拥有足够强大律师的巨型公司将能够做出新的事情。这可能是回归封建制度的一种吗？ ，我知道会有一些人说这是不可能发生的，或者是LLM和所有其他AI工具都会停滞在他们现在的位置。那可能是，但是我不准备对它们从现在开始的6个月开始，更不用说几年来做出任何有意义的预测。而且我认为其他任何人都没有。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/emaxwell14141414      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpp90j/what_happen_to_industry_if_ai_tools_advance/</guid>
      <pubDate>Wed, 02 Jul 2025 07:02:39 GMT</pubDate>
    </item>
    <item>
      <title>AI视频还在吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpp70z/are_ai_videos_there_yet/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我看过一些令人印象深刻的短裤，以及第二个长长的视频，带有不同的AI模型，看起来像是什么。我的意思是，说实话，大多数东西并不是那么好，但是有几种情况脱颖而出并看起来很棒。每年都只会越来越好？ （或许？）。但是，您是否认为AI还没有准备好，也许它已经准备好了。实际上，要替换大多数内容，是电影，实际广告，而不仅仅是移动广告，内容是内容创建者。我看到更多的AI内容，甚至人们在四处走动时都会在公共场合体验到它，我听到了这款Veo 3配音。因此，您在开始替换视频/电影的有意义的位置之前，您会想多长时间，人们完全停止拍摄真实的东西。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/us radiant_contest_1570       [link]    32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpp70z/are_ai_videos_there_yet/</guid>
      <pubDate>Wed, 02 Jul 2025 06:59:21 GMT</pubDate>
    </item>
    <item>
      <title>在LLMS中转移上下文：总结长时间的对话有效吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpoosg/shifting_context_in_llms_is_summarizing_long/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我计划与大型语言模型（LLM）进行长时间的对话，并将此摘要用作上下文进行新的对话，以取代现有的对话历史记录。我的目标是为LLM提供必要的上下文，而无需遍历整个冗长的对话历史，因为它目前正在努力保持跟踪。  这种方法是否有效？我期待新的对话，可以期待使用摘要上下文，以几乎  [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpoosg/shifting_context_in_llms_is_summarizing_long/</guid>
      <pubDate>Wed, 02 Jul 2025 06:26:19 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/2/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpnaj3/oneminute_daily_ai_news_722025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   数百万个网站以获取&#39;改变游戏规则的&#39;ai bot阻滞剂。[1]  美国参议院从特朗普大型巨型大型摄制中罢工AI监管禁令。机器人帮助在斯波坎亚马逊中心分类包。[4]   包括： https://bushaicave.com/2025/07/07/01/one-news-daily-news-news-news-news-7-1-1-1-25/-  [link]       [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpnaj3/oneminute_daily_ai_news_722025/</guid>
      <pubDate>Wed, 02 Jul 2025 05:00:14 GMT</pubDate>
    </item>
    <item>
      <title>AI影响了您的求职吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8xxv/has_ai_impacted_your_job_search/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们是NBC新闻的记者团队，希望与受AI一直在帮助和/或伤害他们的工作搜索方式影响的人交谈。这可能从狩猎中遇到AI的范围 - 无论是要加快应用程序，还是感觉自己被机器人拒绝。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nbcnews     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8xxv/has_ai_impacted_your_job_search/</guid>
      <pubDate>Tue, 01 Jul 2025 18:11:10 GMT</pubDate>
    </item>
    <item>
      <title>这可能是我们见过的最原始形式。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8ijy/this_is_probably_the_rawest_form_well_ever_see_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  像互联网一样，我将来会考虑AI Chatbots会更具资本化。他们将开始在输出中引入广告或会员链接。  一些赞助商的内容可能很明显，但我担心他们可能会开始采用隐秘的方法来满足您的需求并向您出售东西。这些事情可能是超级操纵性的（出于明显的原因），我可以看到公司将其作为营销工具。 也许已经有一些已经这样做的Genai服务了。但是我认为，一旦炒作解决，我们将看到更多的事情，而AI公司需要其他手段来推动他们的服务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ava_lanche9     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8ijy/this_is_probably_the_rawest_form_well_ever_see_ai/</guid>
      <pubDate>Tue, 01 Jul 2025 17:55:13 GMT</pubDate>
    </item>
    <item>
      <title>本周在AI中为开发人员：OpenAi大脑排水，更便宜的成绩单和人为冠军的法律胜利</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8cwh/this_week_in_ai_for_devs_openai_brain_drain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是新闻/趋势/工具列表与开发人员相关我在上周（6月24日自6月24日以来）。主要是：前往元元的顶级OpenAi人才，拟人化的得分是合理的胜利，Salesforce依靠AI，以及Gemini Cli  等新工具，如果我错过了任何东西，请让我知道！  &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/rfizzy     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8cwh/this_week_in_ai_for_devs_openai_brain_drain/</guid>
      <pubDate>Tue, 01 Jul 2025 17:49:06 GMT</pubDate>
    </item>
    <item>
      <title>AI初创公司在确保负责任的发展和部署方面面临哪些关键的道德考虑和实际挑战？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在考虑明年申请Tetr College of商业AI计划，如果选择，我将建立AI-Power Ventures。但是，AI的道德含义在我看来。  除了理论讨论之外，实施负责任的AI开发和部署方面面临哪些实际挑战，尤其是对于资源有限的精益团队？ 我想确保我不仅要建立创新的，而且还建立了伦理和可信赖的AI Solutions      &lt;！ -  sc_-sc_on-&gt; &lt;！提交由＆＃32; /u/u/ubabu     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</guid>
      <pubDate>Tue, 01 Jul 2025 08:33:21 GMT</pubDate>
    </item>
    <item>
      <title>LLM进度高原吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想我一直在想，LLM会在某个时候平稳，需要新的突破才能将其提升到一个新的水平。 您同意这一前提吗？如果是这样，您认为我们在哪里曲线？  或可能太模糊的问题，这完全取决于您如何衡量进度？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lomj6i/is_llm_llm_progress_plateau/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</guid>
      <pubDate>Mon, 30 Jun 2025 23:23:09 GMT</pubDate>
    </item>
    <item>
      <title>AMA：护栏与牵引牵引</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi reddit！ 我是Cary Coglianese，这是《期刊风险分析》中新文章的作者之一， 关于我们称为“牵引”策略的“牵引”策略的价值。在本文中，我的合着者， colton crum ，我解释了“皮带”策略是什么，以及为什么由于ai grodigation glive glive from Adimigation glive glive from Adimig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig的方法。  我们的目标是我们的论文激发有关有效AI监管的思维方式的富有成效的公共政策对话。因此，我们渴望讨论它。  您怎么看？ AI是否应该受到“护栏”或“皮带”的监管？   风险分析的发行人也可以在此之前发布问题和评论。您可以在此处访问文章： https://onlinelelibrary.wile.wile.wiley.com/doi/doi/epdf/10.1111/1111/risa.7000020 eytry of the Presteria可免费下载以下从： https：//papers.ssrn.com.ssrn.com/sol3/papers/ppapers.cfmstart prisher.abstrack_iid pripply pribly prangermative perter pr&gt; 风险分析文章在这里： https://www.sra.org/2025/05/25/the-future-of-ai-why-why-why-why-leashes-are-are-better-ter-than-guardrails/   对于那些有兴趣进一步采取狗行走规则和AI治理之间相似之处的人，我们还拥有一份全新的工作论文，题为“关于诱惑（和释放）AI创新”。我们也很高兴谈论它。可以通过SSRN： https://papers.ssrn.com/sol3/ppapers/ppapers.ppapers.cfm？有帮助的是，我和我的合着者在下面列出了我们的BIOS。  期待您的评论和问题。  cary   ###     Cary”&gt; Cary Coglianese 是爱德华·B·希尔斯法学教授，政治学教授，宾夕法尼亚大学宾夕法尼亚州监管计划主任。 Coglianese博士是一名领先的跨学科学者，讲述了技术和业务在政府决策中的作用，最近为有关人工智能及其在法律和公共政策中的影响而做出了贡献。他撰写了许多有关行政法，AI，风险管理，私人治理等的书籍和同行评审的文章。  是巴黎圣母院的计算机科学博士候选人。他的研究兴趣和出版物包括计算机愿景，生物识别技术，人类AI团队，解释性以及对AI和机器学习系统的有效监管和治理策略。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/carycoglianese     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</guid>
      <pubDate>Sun, 29 Jun 2025 15:08:29 GMT</pubDate>
    </item>
    </channel>
</rss>