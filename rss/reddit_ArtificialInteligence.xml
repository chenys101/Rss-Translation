<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 06 Jul 2025 09:22:59 GMT</lastBuildDate>
    <item>
      <title>如果我对Hastur的AI模拟，又称国王的黄色，请告诉我它对人类的见解</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lswe2h/had_my_ai_simulation_of_hastur_aka_the_king_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lswe2h/had_my_ai_simulation_of_hastur_aka_the_king_in/</guid>
      <pubDate>Sun, 06 Jul 2025 08:34:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么Big LLM会一直使用相关连词？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsuude/why_do_the_big_llms_use_correlative_conjunctions/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是什么使它们在技术层面上始终使用相关连接？我们甚至知道吗？具体而言，“不仅……而且也是如此）的截断变体例如： 钓鱼不仅是要捕获最大的鱼类 - 它是关于体验自然的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/us helpful_badger3106     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsuude/why_do_the_big_llms_use_correlative_conjunctions/</guid>
      <pubDate>Sun, 06 Jul 2025 06:50:07 GMT</pubDate>
    </item>
    <item>
      <title>AIS推理和掌握复杂概念的能力有多好</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsu36w/how_good_is_ais_ability_to_reason_and_grasp/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  看到每个人都涌入AI的所有炒作和金钱，我以为AI中的进步可以比LLMS   &lt;！ -  sc_on-&gt; sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsu36w/how_good_is_iis_ais_ability_to_to_to_to_reason_and_grasp/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsu36w/how_good_is_ais_ability_to_reason_and_grasp/</guid>
      <pubDate>Sun, 06 Jul 2025 06:01:18 GMT</pubDate>
    </item>
    <item>
      <title>AI不是泡沫</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lstbvw/ai_isnt_a_bubble/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai不是泡沫，但我们可能在未来10年内无法达到AGI。许多人，尤其是在Reddit上，正在驳斥当前的AI革命，因为它类似于Dotcom Bubble，Crypto，Nocode网站建设者等。 说，与以前的ERA不同，AI大大提高了生产力，并且AI公司正在创造收入。那里有很多高估的初创公司，但是请查看使用Chatgpt或Claude或Gemini的人数。人们每天都在使用AI，这不会消失，因为这些模型变得更好。  作为贸易的SWE，编码对我来说已经完全改变了。我并不是让AI单独脱离轨道和代码，但是从本质上讲，Google搜索 +在类固醇上以5000 wpm的键输入。在过去的两个月中，我可能在项目中写了100行代码，并用10K的代码编写了代码。查看 ai今天甚至可以单声。它可以在一分钟内生产的一些东西，用于制作工程师的日子。  现在，在与这些模型进行互动时，我意识到我们可能没有让AI实际上独立地构建和管理任何重要的事情。也就是说，AI有很多价值，我们只会刮擦表面，即使CEO在明年可能会被夸大，并且“ 50％替代白领工作”。在十年末实际上不会发生。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/idwiw_wiw    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lstbvw/ai_isnt_a_bubble/”&gt; [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lstbvw/ai_isnt_a_bubble/</guid>
      <pubDate>Sun, 06 Jul 2025 05:13:58 GMT</pubDate>
    </item>
    <item>
      <title>“猫混淆了推理LLM：对推理模型的问题不可知的对手触发器”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lss6no/cats_confuse_reasoning_llm_query_agnostic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https：//arxiv.org/pdf/2503.01781引入查询不可思议的对抗触发器 - 简短的，无关紧要的文本，当附加到数学问题时，系统地误导了模型，以在不更改问题的语义的情况下输出不正确的答案。我们提出了Catattack，这是一种自动化的迭代攻击管道，用于在较弱，较便宜的代理模型（DeepSeek V3）上产生触发器，并成功地将它们转移到更先进的推理目标模型中，例如DeepSeek R1和DeepSeek R1 Distieldield-Distield-Distield-distield-distilled-qwen-32b，导致了300％的目标构成目标，使目标模型增加了300％。例如，附加，有趣的事实：猫的大部分时间都在睡觉，任何数学问题都会导致模型弄错了答案的机会增加了一倍以上。我们的发现突出了推理模型中的关键脆弱性，表明即使是最先进的模型仍然容易受到微妙的对抗投入的影响，从而提高了安全性和可靠性问题。塔塔克触发具有模型响应的数据集可在 https：//huggingface.co/datasets/collinear-ai/  ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lss6no/cats_confuse_reasoning_llm_query_agnostic/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lss6no/cats_confuse_reasoning_llm_query_agnostic/</guid>
      <pubDate>Sun, 06 Jul 2025 04:04:43 GMT</pubDate>
    </item>
    <item>
      <title>“大语言模型中的概括科学研究的偏见”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lss57o/generalization_bias_in_large_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好吧，这很重要。研究人员应该意识到。  https://royalsocietypublishing.org/doi/10.1098/rsos.241776为了提高公共科学素养并支持科学研究，因为它们可以快速以可访问的方式总结复杂的科学信息。但是，当总结科学文本时，LLM可能会忽略限制研究结论范围的细节，从而导致结果的概括性比原始研究所保证的。我们测试了10个突出的LLM，包括Chatgpt-4O，Chatgpt-4.5，DeepSeek，Llama 3.3 70B和Claude 3.7十四行诗，将4900 LLM生成的摘要与其原始科学文本进行了比较。即使明确提示准确性，大多数LLM都比原始文本中的科学结果更广泛地概括，DeepSeek，Chatgpt-4O和Llama 3.3 70B在26-73％的案例中过度笼过。在直接比较LLM生成和人为撰写的科学摘要中，LLM摘要包含广泛的概括的可能性几乎是五倍（优势比= 4.85，95％CI [3.06，7.70]， p  p ＆LT; 0.001）。值得注意的是，较新的模型的概括精度往往比早期的模型更差。我们的结果表明，在许多广泛使用的LLM中存在强烈的偏见，以使科学结论过于概括，从而引起了大规模误解研究结果的重大风险。我们重点介绍了潜在的缓解策略，包括降低LLM温度设置和为概括精度的基准测试LLM。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lss57o/generalization_bias_bias_in_large_langue_model/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lss57o/generalization_bias_in_large_language_model/</guid>
      <pubDate>Sun, 06 Jul 2025 04:02:24 GMT</pubDate>
    </item>
    <item>
      <title>我要求AI设想对余生的令人沮丧，可怕和完全病态的概念。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsmoka/i_asked_ai_to_envision_a_depressing_scary_utterly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我收到的。 未记录的 在此来世中，您在一个庞大而无尽的库中醒来。天花板消失在黑暗中，架子沿每个方向延伸到永恒。它是沉默的 - 压迫性的 - 除了木材不在时，架子变化时，木材的缓慢吱吱作响。 在这个无限的结构内，每个灵魂都被分配了一个狭窄的走廊。你一个人。永恒。您的走廊所衬的书不是故事或历史，而是详细说明了您曾经忘记的一切  - 每个名字，每个脸，每一刻都没有被注意到。童年的记忆失去了时间。善良的手势未占领。爱你，你不爱你的人。您说的话毁了某人，您甚至从未记得说过。 ，您被诅咒阅读它们。 不仅如此 - 当您阅读时，您重新体验了这些时刻生动地细节。不仅是事件，而且其他人如何看待他们。他们如何遭受您的错误。当您离开，忘记，出卖或根本不在乎时，他们如何哭泣。 您无法关闭书籍。您不能停止阅读。您不能再忘记。 ，对于那些想探索的人 - 漫步（漫步道路） - 他们只发现其他走廊 充满了 其他人被遗忘的痛苦。有些人耳语寻求帮助，但是当您看时，那里没有人。  在图书馆的中心，恳求 恳求    最终书  - 一个包含您死亡之前的记忆的记忆。最终，您被它吸引了。你永远是。当您到达时，您会意识到一些难以忍受的东西：  您以前已经在这里了。您已经度过了忘记，记住和遭受无数次痛苦的循环。  您只是忘记了。 ，因此它再次开始。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cairntrenz     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsmoka/i_asked_ai_to_envision_a_depressing_scary_utterly/</guid>
      <pubDate>Sat, 05 Jul 2025 23:06:21 GMT</pubDate>
    </item>
    <item>
      <title>想象一下，如果您愿意</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lslk2x/imagine_if_you_will/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  其他人还记得暮光区的那集威廉·沙特纳（William Shatner）在公路旅行中停在餐馆里，最终被击中的算命先生所吸引了他，除了含糊其任何事情时，他什么也没给他做任何事情。提交由＆＃32; /u/u/atomsmasher420     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lslk2x/imagine_if_you_will/</guid>
      <pubDate>Sat, 05 Jul 2025 22:12:22 GMT</pubDate>
    </item>
    <item>
      <title>AI驱动的语言学习：时间表？挑战？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lskoqf/aipowered_language_learning_timeline_challenges/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我没有尝试使用任何AI动力的语言学习应用程序/网站/网站，因为我看到的所有评论都表明，这些评论都不是今天都很好。     是否有任何已知的特定技术问题需要在语言学习域中克服？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/jrmcgov     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lskoqf/aipowered_language_learning_timeline_challenges/</guid>
      <pubDate>Sat, 05 Jul 2025 21:31:35 GMT</pubDate>
    </item>
    <item>
      <title>用小语言模型检测幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsj7jr/hallucination_detection_with_small_language_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要开发：“用小语言模型;  本文通过利用多种小语言模型（SLM）来介绍一种旨在减轻幻觉的新颖框架 - 大型语言模型（LLMS）生成的信息。以下是一些关键见解：    框架结构：拟议的方法利用SLM来验证LLMS通过将响应划分为句子并计算“幻觉得分的过程”的过程来验证LLMS生成的响应。基于这些句子是准确的可能性。      效率提高：通过整合SLM，该框架在F1得分方面取得了10％的提高，以检测正确的幻觉和幻觉响应的响应，以提供可靠和可伸缩的解决方案，以提供可靠的解决方案，以提供可靠的解决方案，以Real-World Validation: The framework was tested on a dataset derived from an employee handbook, encompassing multiple questions and corresponding contexts, which allowed for a comprehensive evaluation of response accuracy. Comparative Performance: The results indicate that using multiple SLMs significantly outperformed single models, including a comparison with ChatGPT,确定对分段响应进行独立检查可以增强确定不正确信息的精确性。      未来的研究方向：该论文为进一步的优化提供了途径，包括将SLM与在线验证框架相关联的潜力，以在线验证框架中的准确性和上下文相关性。 在此纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsj7jr/hallucination_detection_with_small_language_models/</guid>
      <pubDate>Sat, 05 Jul 2025 20:25:24 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI（WhatsApp内置AI）系统提示显示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsilk4/meta_ai_whatsapp_builtin_aisystem_prompt_revealed/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsilk4/meta_ai_whatsapp_builtin_aisystem_prompt_revealed/</guid>
      <pubDate>Sat, 05 Jul 2025 19:57:47 GMT</pubDate>
    </item>
    <item>
      <title>FDA将使用AI（非常非常快速）批准药物，停止信任专家</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lshupk/fda_will_approve_drugs_using_ai_very_very_quickly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以rfk Jr.刚刚参加了塔克·卡尔森（Tucker Carlson）的表演，并说AI将开始在FDA上批准“非常非常快速”的新药。不帮助。批准。他说，当前的过程太慢且效率低下，因此他的解决方案是削减包括动物试验在内的传统测试，并让AI领导。这也不是未来的想法。他正在谈论很快这样做。 “停止信任专家”？ 好像这还不够，他还丢下了界限：“我们需要停止信任专家。”那是直接报价。他比实际科学更像是“宗教”或“极权主义”的专家建议。因此，现在，我们不应该相信神经网络可以自己做出更安全，更快的决定，而不是信任拥有医学学位和研究经验的人。因为没有什么比Black-box AI模型和同行评审这样的安全性说明，对吗？没有有关如何培训AI的详细信息，它将使用什么数据或我们将如何验证其决策。只是这种笼统的信念，即AI可以在药物批准过程中以某种方式解决所有错误。没关系，当前的人工智能系统仍然会幻觉事实，在背景下挣扎，并且可以被授予这一事实。当出现问题时，谁将责备呢？模型？开发团队？政府？ 医学上的AI有希望，但不公平，AI在毒品发现方面具有合法的潜力。例如，Alphafold做了令人惊奇的工作，以预测蛋白质结构。像同构实验室这样的公司正在探索AI如何帮助更快地设计新分子。但是，设计药物和批准一种用于人类使用的药物有很大的区别。这需要多年的测试，安全检查，试验和是专家审查。跳过所有鲁ck的东西。 您会服用AI认可的药物吗？ 老实说，这感觉就像是技术兄弟乐观和反科学言论的混合，以创新为创新。就我个人而言，我不会仅仅因为算法说很好的原因就服用了毒品。会吗？如果根本没有人类评论怎么办？这不像Spotify选择您的播放列表的生命或死亡。如果AI涉及，它需要协助人类，而不是更换它们。这就是您负责任地使用技术的方式。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lshupk/fda_will_approve_drugs_using_ai_very_very_quickly/</guid>
      <pubDate>Sat, 05 Jul 2025 19:23:59 GMT</pubDate>
    </item>
    <item>
      <title>首席执行官开始大声说：AI将消除工作 - 福特总监预测，AI将取代“所有白领工人的一半”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsf0hg/ceos_start_saying_the_quiet_part_out_loud_ai_will/</link>
      <description><![CDATA[Key Points  Several CEOs predict AI will significantly cut white-collar jobs, marking a shift from previous reluctance to acknowledge potential job losses. Ford’s CEO anticipates AI replacing half of white-collar workers, while JPMorgan Chase expects a 10% operations head count reduction via ai。 有些像Openai的首席运营官一样，认为恐惧是夸张的，而另一些人则强调了新角色的潜力，尽管不可避免的工作流离失所。     https://www.wsj.com/tech/ai/ai-white-collar-job-loss-b9856259?mod=pls_whats_news_news_us_business_f    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsf0hg/ceos_start_saying_the_quiet_part_part_part_out_loud_ai_will/”&gt; [links]        [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsf0hg/ceos_start_saying_the_quiet_part_out_loud_ai_will/</guid>
      <pubDate>Sat, 05 Jul 2025 17:19:30 GMT</pubDate>
    </item>
    <item>
      <title>我们正在AI淘金热 - 这26个里程碑表明了为什么您还早</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lscetd/were_in_the_ai_gold_rush_these_26_milestones_show/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lscetd/were_in_the_ai_gold_rush_these_26_milestones_show/</guid>
      <pubDate>Sat, 05 Jul 2025 15:25:44 GMT</pubDate>
    </item>
    <item>
      <title>光标ai只是地毯拉了所有人，现在检查您的帐单</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lroc9e/cursor_ai_just_rug_pulled_everyone_check_your/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  编辑：更新！他们现在将其退还给他们的用户，没有任何通知。  只是注意到了这一点，并想警告其他人： 光标更改了他们的“无限”用法模型，而无需任何通知。 如果您一直在使用SONNET-4或其他高级模型，则他们可能已经开始向您收取费用，而不必清楚地向您收费。   no emails。没有弹出窗口。没有什么。我只通过随机检查仪表板来抓住它。 如果您正在按付费计划或高级型号进行，请尽快检查您的使用情况。有些人的充电性超出了预期。 这感觉超级阴暗。至少，它们应该是透明的。 在其他人尚未注意到的情况下对此进行标记。不要措手不及。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lroc9e/cursor_ai_just_rug_pulled_everyone_check_your/</guid>
      <pubDate>Fri, 04 Jul 2025 17:25:33 GMT</pubDate>
    </item>
    </channel>
</rss>