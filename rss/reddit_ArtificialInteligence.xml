<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 01 Jul 2025 21:23:43 GMT</lastBuildDate>
    <item>
      <title>是什么使CHATGPT对软件问题解决有效？开发人员聊天的经验研究</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpd5ca/what_makes_chatgpt_effective_for_software_issue/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天的AI研究论文的标题为&#39;是什么使ChatGpt有效地解决软件问题？作者：Ramtin Ehsani，Sakshi Pathak，Esteban Parra，Sonia Haiduc，Preetha Chatterjee的作者。  这项研究研究了将开发人员和Chatgpt与无助于686个GitHub问题线程中无用的对话区分有用的对话的特征。 Here are several key insights from the research:  Helpfulness of Conversations: Only 62% of analyzed conversations were classified as helpful, with ChatGPT excelling particularly in tasks such as code generation and tool recommendations, while it struggled with code explanations and specific information-seeking tasks. Impact of Clarity and结构：有用的对话往往具有清晰且结构良好的提示，其中包括定义明确的问题，上下文代码片段和更少的主题更改。 In contrast, unhelpful conversations often included vague requests and lengthy prompts that diluted effectiveness. Project and Developer Factors: The study revealed that larger, more popular projects benefited more from ChatGPT, and experienced developers utilized ChatGPT more effectively, suggesting that familiarity with project nuances and clearer communication enhance outcomes. Common Deficiencies: Unhelpful responses often exhibited issues such as incorrect or vague information, hallucinations of non-existent elements, and a general lack of comprehensiveness that frustrated developers. Actionable Recommendations: Strategies for improving interactions include structuring prompts for clarity, minimizing topic shifts, and提供特定于上下文的信息，以增强ChatGpt的功能。   在此处探索完整的崩溃：原始纸   &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpd5ca/what_makes_chatgpt_effective_for_software_issue/</guid>
      <pubDate>Tue, 01 Jul 2025 20:53:45 GMT</pubDate>
    </item>
    <item>
      <title>最早获得所有AI新闻的最快来源是什么</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lpa9xs/whats_the_fastest_source_to_get_all_the_ai_news/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我需要最新和更新的新闻，并使用最少的时间delta ...请不要说X，因为我离开X了一段时间，我不想再次进入Rabbithole。 谢谢。     &lt;！ -  sc_on-&gt; &lt;！ - &gt; 32;提交由＆＃32; /u/u/icurious1205     [link]   [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lpa9xs/whats_the_fastest_source_to_get_all_the_ai_news/</guid>
      <pubDate>Tue, 01 Jul 2025 19:01:47 GMT</pubDate>
    </item>
    <item>
      <title>AI影响了您的求职吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8xxv/has_ai_impacted_your_job_search/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们是NBC新闻的记者团队，希望与受AI一直在帮助和/或伤害他们的工作搜索方式影响的人交谈。这可能从狩猎中遇到AI的范围 - 无论是要加快应用程序，还是感觉自己被机器人拒绝。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nbcnews     [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8xxv/has_ai_impacted_your_job_search/</guid>
      <pubDate>Tue, 01 Jul 2025 18:11:10 GMT</pubDate>
    </item>
    <item>
      <title>这可能是我们见过的最原始形式。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8ijy/this_is_probably_the_rawest_form_well_ever_see_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  像互联网一样，我将来会考虑AI Chatbots会更具资本化。他们将开始在输出中引入广告或会员链接。  某些赞助商内容可能很明显且清楚地说明，但是我担心他们可能会开始采取隐秘的方法来满足您的需求并向您出售东西。这些事情可能是超级操纵性的（出于明显的原因），我可以看到公司将其作为营销工具。 也许已经有一些已经这样做的Genai服务了。但是我认为，一旦炒作解决，我们将看到更多的事情，而AI公司需要其他手段来推动他们的服务。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ava_lanche9     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8ijy/this_is_probably_the_rawest_form_well_ever_see_ai/</guid>
      <pubDate>Tue, 01 Jul 2025 17:55:13 GMT</pubDate>
    </item>
    <item>
      <title>本周在AI中为开发人员：OpenAi大脑排水，更便宜的成绩单和人为冠军的法律胜利</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8cwh/this_week_in_ai_for_devs_openai_brain_drain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是新闻/趋势/工具列表与开发人员相关我在上周（6月24日自6月24日以来）。主要是：前往元元的顶级OpenAi人才，拟人化的得分是合理的胜利，Salesforce依靠AI，以及Gemini Cli  等新工具，如果我错过了任何东西，请让我知道！  &lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/rfizzy     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp8cwh/this_week_in_ai_for_devs_openai_brain_drain/</guid>
      <pubDate>Tue, 01 Jul 2025 17:49:06 GMT</pubDate>
    </item>
    <item>
      <title>“非临床信息如何塑造LLM中的临床决策”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lp5092/how_nonclinical_information_shapes_clinical/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    “将大语模型（LLM）集成到临床诊断中，需要仔细了解用户输入的临床无关方面如何直接影响生成的治疗建议，从而对最终用户的临床结果进行临床结果。在研究人口属性对临床LLM推理的影响的先前研究的基础上，本研究探讨了非临床相关属性如何塑造LLM的临床决策。通过对患者信息的扰动，我们评估了当更改非临床信息时，LLM行为是否保持一致，准确和公正。这些扰动通过复制在电子数据处理期间可能发生的结构错误来评估临床LLM推理的脆弱性，并模拟多元化，脆弱的患者群体中患者AI系统之间的相互作用。我们的发现表明，LLM治疗建议和临床准确性的显着降解，以减少对患者的护理分配的方式显着降解。此外，性别亚组之间以及模型延长的性别亚组之间的治疗建议存在很大差异。我们还将扰动框架应用于会话临床数据集，以发现即使在对话中，LLM临床精度也会降低扰动后的扰动，并且在扰动影响性别亚组中的差异也存在。通过分析响应现实但修改的临床环境的LLM输出，我们的工作加深了对医学LLMS固有的敏感性，不准确性和偏见的理解，为部署患者AI Systems提供了关键的见解。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lp5092/how_nonclinical_information_shapes_clinical/”&gt; [link]         [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lp5092/how_nonclinical_information_shapes_clinical/</guid>
      <pubDate>Tue, 01 Jul 2025 15:42:40 GMT</pubDate>
    </item>
    <item>
      <title>AI初创公司在确保负责任的发展和部署方面面临哪些关键的道德考虑和实际挑战？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在考虑明年申请Tetr College of商业AI计划，如果选择，我将建立AI-Power Ventures。但是，AI的道德含义在我看来。  除了理论讨论之外，实施负责任的AI开发和部署方面面临哪些实际挑战，尤其是对于资源有限的精益团队？ 我想确保我不仅要建立创新的，而且还建立了伦理和可信赖的AI Solutions      &lt;！ -  sc_-sc_on-&gt; &lt;！提交由＆＃32; /u/u/ubabu     [link]   ＆＃32;   [commist]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lower3/what_are_the_key_ethical_considerations_and/</guid>
      <pubDate>Tue, 01 Jul 2025 08:33:21 GMT</pubDate>
    </item>
    <item>
      <title>除了代码外，大语言模型在软件开发中的多维影响</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lowcw8/beyond_code_the_multidimensional_impacts_of_large/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要发展：“超越代码：大语模型在软件开发中的多维影响”，由Sardar Fatooreh Bonabi，Sarah Bana，Sarah Bana，Tingting Nian和Vijay Gurbarcaxani撰写。  本研究对诸如ChatGPT之类的大型语言模型（LLM）的方式提出了令人信服的见解，尤其是在开源软件（OSS）行业中。以下是一些关键发现：    生产力提高：访问CHATGPT会使开发人员的生产率提高了6.4％。有趣的是，在新手开发人员中观察到了最大的生产率提高，这表明LLMS极大地帮助了他们的编码工作。      增强的知识共享：Chatgpt的可用性还丰富了协作的协作，知识展示活动增加了9.6％的稳定后的恢复。这表明LLM促进了开发人员之间的社区参与和同行反馈。     技能获取改进：开发人员在Chatgpt Access禁令期间的技能获取下降8.4％，突显了其在促进新编程语言学习中的作用。该研究强调，LLM对处理复杂或文献记载的语言的开发人员特别有益。        依赖上下文依赖的益处：技能发展的影响各不相同，揭示了他们在技术上是在技术上是在技术上是在陡峭的学习环境中出现的最大优势，或者当开发人员面临陡峭的学习curves curves。效果：开发人员之间的不同经验水平表现出不同的好处。虽然新手开发人员在很大程度上依赖LLM来提高生产力，但中级开发人员可以最大化知识共享和技能提高，展示了对组织中量身定制的培训和使用策略的需求。     这些发现这些发现的需求强调了他们在软件开发方面的多元化范围，从而使他们在软件开发方面的范围内的范围不超出了范围的范围。增强。 在此处探索完整的故障：原始纸提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lowcw8/beyond_code_the_multidimensional_impacts_of_large/</guid>
      <pubDate>Tue, 01 Jul 2025 08:29:45 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻6/30/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lot1uu/oneminute_daily_ai_news_6302025/</link>
      <description><![CDATA[ Microsoft says new AI tool can diagnose patients 4 times more accurately than human doctors.[1] Apple weighs using Anthropic or OpenAI to power Siri in major reversal, Bloomberg News reports.[2] Amazon launches一个新的AI基金会模型，可以为其机器人车队提供动力并部署其第100万个机器人。[3]   A.I。视频从未过得更好。你能告诉你是真实的吗？[4]   包括： https://bushaicave.com/2025/06/06/06/30/one-news-daily-daily-news-news-news-news-news-6-6-6-6-6-30-30-30-20-20-20-20-25/  [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lot1uu/oneminute_daily_ai_news_6302025/</guid>
      <pubDate>Tue, 01 Jul 2025 04:54:17 GMT</pubDate>
    </item>
    <item>
      <title>大美丽的账单包括人工智能供应</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loqtnw/big_beautiful_bill_includes_ai_provision/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  喜欢标题，  BBB包括一项规定，该条款将为国家提供5亿次联邦资金来支持AI和宽带基础设施，前提是他们并没有针对AI的使用范围，但没有特别的范围，而是在保护儿童和coperift的情况下，并不是在保护儿童和coperifters of to dic dic of th dic dic of th dic of tim nifformate of th dic of to n of th dic of tim n of th dic of tim n of th do n of Surgruction of Die of ticrultion&#39;&#39;负担” AI系统和模型。  This also includes 6.1 billion dollars for infrastructure and systems used in border surveillance, 450 million dollars in AI autonomous naval shipbuilding, 145 million in AI for automated aerial naval attack drones, 250 million for AI projects in the US Cyber​​ Systems command, and a 115 million for AI systems that help protect nuclear facilities, to name a few. Seems to me like a decision在未固定的基础架构或负责任地使用AI之间。  思想？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/criewolf     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loqtnw/big_beautiful_bill_includes_ai_provision/</guid>
      <pubDate>Tue, 01 Jul 2025 02:52:11 GMT</pubDate>
    </item>
    <item>
      <title>LLM进度高原吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我想我一直在想，LLM会在某个时候平稳，需要新的突破才能将其提升到一个新的水平。 您同意这一前提吗？如果是这样，您认为我们在哪里曲线？  或可能太模糊的问题，这完全取决于您如何衡量进度？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lomj6i/is_llm_llm_progress_plateau/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lomj6i/is_llm_progress_plateauing/</guid>
      <pubDate>Mon, 30 Jun 2025 23:23:09 GMT</pubDate>
    </item>
    <item>
      <title>苹果公司正在考虑使用AI技术从人类或OpenAI来为Siri提供动力，从而使自己的内部型号旁观。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1loimh2/apple_is_considering_using_ai_technology_from/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  因此，苹果是否应该购买整个公司或为其技术合作的问题？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/creative-hotel8682     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1loimh2/apple_is_considering_using_ai_technology_from/</guid>
      <pubDate>Mon, 30 Jun 2025 20:40:40 GMT</pubDate>
    </item>
    <item>
      <title>微软表示，其新的AI系统诊断出患者的精度是人类医生的4倍</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lo7m9h/microsoft_says_its_new_ai_system_diagnosed/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Microsoft团队使用了304个案例研究，该案例研究从《新英格兰医学杂志》中提出了一个名为“顺序诊断基准（SDBENCH）”的测试。一个语言模型将每个案例陷入了医生为了诊断而进行的逐步过程。  Microsoft的研究人员随后建立了一个名为MAI Diagnostic Croundestrator（MAI-DXO）的系统，该系统查询了几个领先的AI模型，其中包括GPT的Openai的GPT，Google的Google的Gemini，Enthropic的claude anda anda anda and anda and anda gpt，包括 在他们的实验中，Mai-Dxo的表现优于人类医生，与医生的20％相比，MAI-DXO的表现优于80％。它还通过选择较便宜的测试和程序将成本降低了20％。 &#39;这种编排机制 - 以这种持续链风格一起工作的多个代理 - 这将使我们更接近医疗超级智能，” Suleyman说。 。 href =“ https://www.wired.com/story/microsoft-medical-superintelligence-diabnosis/”&gt; href =“ https://www.reddit.com/user/wiredmagazine”&gt;/u/wiredmagazine     [link]   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lo7m9h/microsoft_says_its_new_ai_ai_system_diacnose/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lo7m9h/microsoft_says_its_new_ai_system_diagnosed/</guid>
      <pubDate>Mon, 30 Jun 2025 13:32:16 GMT</pubDate>
    </item>
    <item>
      <title>我们能否停止假装像Openai这样的公司的目标对人类有益，并最终承认这只是巨大的现金抢购吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lo1juj/can_we_stop_pretending_that_goals_of_companies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直一遍又一遍地听到相同的东西 -  AI在这里治愈癌症，它是为了解决气候危机和所有的大问题，我们太小了，无法解决。      bs bs在乌克兰（Putin虽然他唯一的目标是一场土地征服战争，以抓住乌克兰的矿物丰富部分。 与人工智能行业一样，这些公司一直在告诉我们，他们如何非营利的福族公司，这些公司只想帮助我们提高生活质量，而在未来的情况下，人类在未来的情况下却没有利润，因为未来的报道都会;他们肯定会交付。 现实是，整个行业都在围绕货币旋转 - 尽快变得肮脏的富人，同时忽略AI可能对我们产生的任何安全性或负面影响。多年来，Openai一直试图弄清楚如何解决各种问题，并在其研发部门中尝试许多不同的AI项目。他们拥有庞大的安全团队，希望确保负责任地发展而不会对人类产生负面影响。为什么这项技术如此受欢迎，如此受大公司如此之大的支持，以至于他们可以看到巨大的潜力来代替人类劳动力，而不是治愈癌症或解决气候，而是要削减人工工人并增加利润。 他们在其他方向上杀死了所有研究，以其他方向和拆除的安全团队杀死了所有的安全团队，停止了所有的公共研究，使所有东西都成为了所有的机密和分泌的东西，因为他们只是将所有这些都放在了所有这些方向上，因为他们只是在所有这些方向上，因为这一切只是在所有这些方向上，因为这一切只是在所有这些方向上，因为这一切只是在这些方向上，因为这一切只是在这些方向上，因为这一切都在这方面，因为它上的焦点是焦点。而且没有人关心这实际上是在破坏了数百万人的生活，而这些人在之前和将来都从事不错的工作，这很可能会破坏数十亿美元的生活。只要它会使他们成为数万万富翁。 好运，购买“便宜的毒品”治愈AI制造的癌症，这仅在您住在纸箱中的街道上时只有1000美元，因为AI杀死了人类可用的所有工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/petr_bena     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lo1juj/can_we_stop_pretending_that_goals_of_companies/</guid>
      <pubDate>Mon, 30 Jun 2025 07:41:42 GMT</pubDate>
    </item>
    <item>
      <title>AMA：护栏与牵引牵引</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   hi reddit！ 我是Cary Coglianese，这是《期刊风险分析》中新文章的作者之一， 关于我们称为“牵引”策略的“牵引”策略的价值。在本文中，我的合着者， colton crum ，我解释了“皮带”策略是什么，以及为什么由于ai grodigation glive glive from Adimigation glive glive from Adimig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig andig的方法。  我们的目标是我们的论文激发有关有效AI监管的思维方式的富有成效的公共政策对话。因此，我们渴望讨论它。  您怎么看？ AI是否应该受到“护栏”或“皮带”的监管？   风险分析的发行人也可以在此之前发布问题和评论。您可以在此处访问文章： https://onlinelelibrary.wile.wile.wiley.com/doi/doi/epdf/10.1111/1111/risa.7000020 eytry of the Presteria可免费下载以下从： https：//papers.ssrn.com.ssrn.com/sol3/papers/ppapers.cfmstart prisher.abstrack_iid pripply pribly prangermative perter pr&gt; 风险分析文章在这里： https://www.sra.org/2025/05/25/the-future-of-ai-why-why-why-why-leashes-are-are-better-ter-than-guardrails/   对于那些有兴趣进一步采取狗行走规则和AI治理之间相似之处的人，我们还拥有一份全新的工作论文，题为“关于诱惑（和释放）AI创新”。我们也很高兴谈论它。可以通过SSRN： https://papers.ssrn.com/sol3/ppapers/ppapers.ppapers.cfm？有帮助的是，我和我的合着者在下面列出了我们的BIOS。  期待您的评论和问题。  cary   ###     Cary”&gt; Cary Coglianese 是爱德华·B·希尔斯法学教授，政治学教授，宾夕法尼亚大学宾夕法尼亚州监管计划主任。 Coglianese博士是一名领先的跨学科学者，讲述了技术和业务在政府决策中的作用，最近为有关人工智能及其在法律和公共政策中的影响而做出了贡献。他撰写了许多有关行政法，AI，风险管理，私人治理等的书籍和同行评审的文章。  是巴黎圣母院的计算机科学博士候选人。他的研究兴趣和出版物包括计算机愿景，生物识别技术，人类AI团队，解释性以及对AI和机器学习系统的有效监管和治理策略。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/carycoglianese     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lngy9z/ama_guardrails_vs_leashes_in_regulating_ai/</guid>
      <pubDate>Sun, 29 Jun 2025 15:08:29 GMT</pubDate>
    </item>
    </channel>
</rss>