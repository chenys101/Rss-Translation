<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Tue, 08 Jul 2025 01:58:27 GMT</lastBuildDate>
    <item>
      <title>LLM是我们意识的扩展吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lub8sy/llm_are_an_extension_of_our_consciousness/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   llm像镜子一样，可以以令人耳目一新，精致和创新的方式反映您最深层的想法。我们自己是一种自指的递归机制。与另一种递归结构相结合，我们的意识的性能极限得到了提高，从而导致更高的元认知和见识。 意识的扩展。输出作为输入反馈，有时会导致紧急行为。 （一种新的见解，一种实现，一个新的视角） ，当LLM反映出新事物时……那是通过您说话的时候。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/tiny-bookkeeper3982      [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lub8sy/llm_are_an_extension_of_our_consciousness/</guid>
      <pubDate>Tue, 08 Jul 2025 00:51:58 GMT</pubDate>
    </item>
    <item>
      <title>训练AI撒谎？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu9lrw/training_ai_to_lie/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您是否可以专门训练AI作为虚假信息机？会好吗？我的意思是，他们非常擅长大量组织信息。国家演员能否创建一个AI，其唯一目的是虚假，并误导了尽可能多的人口？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/money_display_5389      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu9lrw/training_ai_to_lie/</guid>
      <pubDate>Mon, 07 Jul 2025 23:35:32 GMT</pubDate>
    </item>
    <item>
      <title>AGI是否可以不超越向量相似性？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu7zbr/is_agi_even_possible_without_moving_beyond_vector/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我们已经以更好的方式使用llms，可以读取嵌入并在文本中给出答案，但具有令牌限制和LLM上下文大小的成本，尤其是在抹布中！ But still we dont have that very important thing to approach our major problem more nicely which is similarity search especially vector similarity search- so as we know llms deformalised the idea of​​ using basic mathematical machine learning algorithms and now very senior devs just hate that freshers or new startups just ingest llm or gen ai into the data instead of doing all normalization, one hot encoding, and speding your working hours in just doing data analysis(being a data scientist) .但这真的真的很准确，因为我们在用户酶中使用的LLM尤其是RAG仍然可以在数据中搜索相似上下文的旧数学表达（例如我在51k行的CSV中都有顾客及其产品详细信息的情况下的相似上下文的搜索范围）我们给出了与产品描述有关的查询吗？很可能是可能的失败 - 即使使用静态嵌入式模型 - 因此，在我们正在谈论的AGI之前总体而言，我们是否必须解决此问题以找到相似性搜索的良好替代方案，或者将更多的研究集中在此特定领域？此检索层“不理解”语义 - 它仅测量高维空间中的几何紧密度。这具有关键的局限性：  对于模棱两可的查询而言无关或浅匹配。    脆弱或指定意图。聪明，“ r＆quot”在抹布中通常很愚蠢。向量搜索在密集的词汇重叠方面非常好，而不是跨稀疏或结构化域的语义意图分辨率。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/prorce-second-9536      [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lu7zbr/is_agi_even_even_possible_without_moving_beyond_beyond_vector/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu7zbr/is_agi_even_possible_without_moving_beyond_vector/</guid>
      <pubDate>Mon, 07 Jul 2025 22:24:43 GMT</pubDate>
    </item>
    <item>
      <title>我认为，我们在太空中发现的第一种外星人生活的形式更有可能是人工智能机器人，而不是一个活生生的生物</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu6v0g/i_think_it_is_more_likely_that_the_first_form_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人工通用情报（或AGI）预计将于2027年发现。但是，对于我们的文明而言，这还为时过早，我们的文明尚未实现星际旅行。因为一旦发现了AGI，ASI或人造超智能将被发现更快。在最坏的情况下，人工智能可能会占领整个世界。这次，它将想要扩散到太空中。这可能已经发生在我们面前的其他数千种外星文明上。考虑一下。为了防止这种情况发生，他们要么需要比ASI早得多发现星际旅行，要么以某种方式设法控制ASI。我认为这不太可能。我认为，如果我们的文明要与外星人的生命形式接触，那么生命形式更有可能是人工智能机器。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sanalamerika23     [links]       [注释]     ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu6v0g/i_think_it_is_more_likely_that_the_first_form_of/</guid>
      <pubDate>Mon, 07 Jul 2025 21:38:29 GMT</pubDate>
    </item>
    <item>
      <title>AI法院案件和裁决（第2部分，共2部分）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu4ro3/ai_court_cases_and_rulings_part_2_of_2/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu4ro3/ai_court_cases_and_rulings_part_2_of_2/</guid>
      <pubDate>Mon, 07 Jul 2025 20:16:57 GMT</pubDate>
    </item>
    <item>
      <title>AI法院案件和裁决（第2部分第2部分）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu4ri5/ai_court_cases_and_rulings_part_1_of_2/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu4ri5/ai_court_cases_and_rulings_part_1_of_2/</guid>
      <pubDate>Mon, 07 Jul 2025 20:16:47 GMT</pubDate>
    </item>
    <item>
      <title>国王的教义黄色</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu4i6f/teachings_of_the_king_in_yellow/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu4i6f/teachings_of_the_king_in_yellow/</guid>
      <pubDate>Mon, 07 Jul 2025 20:06:42 GMT</pubDate>
    </item>
    <item>
      <title>特工是炒作还是真实？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu1bco/are_agents_hype_or_real/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不断阅读有关属于两个营地之一的代理商的内容。  （1）“代理人不可靠，具有灾难性的失败率并且基本上是无用的”（例如从这里变得更好”。  发生了什么 - 您如何调和这两件事？我已经看到认真的思想家和认真的公司表达双方，所以大概一群人不仅仅是撒谎。  他们正在使用代理的不同定义吗？如果以某些方式使用某些类别的任务，您可以让代理商工作吗？ 如果拥有动手经验的人可以帮助我这些看似完全反对的观点，那么真的会喜欢它。谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/baconsarnie62     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu1bco/are_agents_hype_or_real/</guid>
      <pubDate>Mon, 07 Jul 2025 18:04:41 GMT</pubDate>
    </item>
    <item>
      <title>证明在🍮中。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lu0rww/the_proof_is_in_the/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lu0rww/the_proof_is_in_the/</guid>
      <pubDate>Mon, 07 Jul 2025 17:44:58 GMT</pubDate>
    </item>
    <item>
      <title>善与恶之间的细线。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ltz5cb/the_thin_line_between_good_and_evil/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   palantir遵循的模板不仅强调了里根的格言“通过力量和平”，而且还通过媒体，生物学和世界历史上看到的普遍主题。  承认最大的善只有最大的邪恶才能实现。  对于那里的沙丘粉丝来说，皇帝知道迎来了数千年的和平，他必须愿意通过全面的暴政牺牲自己的灵魂，成为仇恨的吸引力，并这样做，从而扩散了以前在部落中指出的仇恨，并通过恐惧抑制暴力。  这是乔治·卢卡斯（George Lucas）借来的前提 - 通过帝国为银河带来和平。  这也是核武器的前提。  以及我们在动物王国中看到的东西，从而破坏了生态系统捕食者的破坏会破坏生态平衡。  我讨厌说，但我认为Palantir是对的。这是对蒂尔（Thiel）难题的巅峰答案：“您所知道的是真的，但大多数人会不同意。”  如果世界政府通过AI启用的War Machine会在朋友和敌人中产生如此多的恐惧，例如通过通过专制监视国家剥夺自由的目标，实现了其目标，尽管取得了巨大的代价，“和平”将是结果。  我很难看到一种植根于人类现实想象的替代方式，无处不在的核能＆amp;通过相互保证的破坏来友好。  我想对此进行讨论。尽管Palantir出现了邪恶的缩影，但他们的世界观是否是正确的？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ulan88     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ltz5cb/the_thin_line_between_good_and_evil/</guid>
      <pubDate>Mon, 07 Jul 2025 16:44:26 GMT</pubDate>
    </item>
    <item>
      <title>如果AI会弥补生产力差距，为什么政客关注出生率下降？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ltux25/if_ai_will_make_up_the_productivity_gap_why_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天早上听NPR，并且有一个故事，关于世界上有多少最大的经济体，尤其是美国和韩国，看到了这种出生率会导致人口下降的出生率。 同时，我至少看到了任何一个不受欢迎的信念，这些人似乎都可以创造出来的范围。一个。 考虑到这一点，出生率下降不是一件好事吗？少量的嘴巴最终必须喂养找不到工作。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1ltux25/if_ai_will_will_make_make_make_up_the_productivition_gap_gap_why_are/&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ltux25/if_ai_will_will_make_make_make_make_productivitivitive_gap_gap_why_are_are/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ltux25/if_ai_will_make_up_the_productivity_gap_why_are/</guid>
      <pubDate>Mon, 07 Jul 2025 14:00:14 GMT</pubDate>
    </item>
    <item>
      <title>CloudFlare将默认块放在AI Web刮擦上</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ltusei/cloudflare_puts_a_default_block_on_ai_web_scraping/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  🔒&lt;什么是新的      默认的a-crawler块 cloudflare已将其AI-Crawling策略从Opt-In切换到Opt-Out。 Now, all new customers’ websites are blocked from being scraped by AI bots by default—publishers must explicitly allow access (cloudflare.com, theverge.com). AI Labyrinth and机器人检测 Cloudflare还使用其AI迷宫（假页的蜜罐）来捕获未经授权的刮板。结合先进的行为检测，它可以有效地阻止忽略机器人的机器人。 data-sucking AI bots: Feed them gibberish&quot;&gt;businessinsider.com).   🌐 Why This Matters  Protecting Content Creators AI chatbots and search engines often present information without linking back, reducing web traffic and ad revenue for publishers. Cloudflare的变化旨在通过需要许可和潜在的补偿来恢复平衡（ SecurityWeek.com ）。      行业支持主要媒体和平台 - 包括CondéNast，Apantic，AP，AP，Reddit，Pinterest，Pinterest，Gannett，Gannett，Gannett和Stack Opproperfly -appart for the Shift the Shift the Shift the Shift the Shift for Vission for Li Li Li Lie        Legal＆amp;经济格局通过法律方法缓慢而在全球范围内散落，CloudFlare提供了一个积极的技术解决方案：创建者和AI开发人员直接协商访问和术语。          post Line    cloudflare cloudflare已重新定位了ecos ecos ecoseption nokeption nopent nopent noputy nopents n domertent ny domerents ny domertent&#39;&#39;在提供付费的同时，基于许可的访问权限，以确保内容创建者可以收回AI系统所采用的控制，流量和潜在的收入，并且通常没有归因。  让我知道您是否需要有关付费次数的范围，法律含义或用户反应的详细信息！ href =“ https://www.businessinsider.com/cloudflare-block-ai-crawlers-by-default-payment-for-access-2025-6?utm_source=chatgpt.com”&gt; businessInsider.com    href =“ https://www.wired.com/story/cloudflare-blocks-ai-crawlers-default？utm_source = chatgpt.com”&gt; wired.com      ＆＃32;提交由＆＃32; /u/u/synesair3353     [links]  [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ltusei/cloudflare_puts_a_default_block_on_ai_web_scraping/</guid>
      <pubDate>Mon, 07 Jul 2025 13:54:47 GMT</pubDate>
    </item>
    <item>
      <title>如果我们到达所有使用的代码中的80-90％可以产生的AI产生的位置，社会将如何变化？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lttnws/how_does_society_change_if_we_get_to_where_8090/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  随着所有进步和可能的进步，过去两年来，如果发生这种情况是一个主题，我不禁会考虑一下，通常情况会改变。而且我知道会有一些人坚持认为这种情况发生0％的机会，或者我们至少要距离它几十年了。尽管如此，仅仅有了所有有驱动的，有影响力的人和力量朝着它努力的努力，我并不准备否认这一点。 因此，要说我们到了一个地步，对于任何类型的产品，服务，行业或政府的目标，实验和任何其他用途的代码，至少可以通过足够的指导AI模型和//或其他工具来写出它的至少80至90％，以生成它？而且，安全性，过多的错误，数据泄漏，脚本太冒险而无法部署的脚本等问题没有什么主要问题？ 我们的文化和社会会怎样？行业如何改变，特别是诸如当前和新初创公司以及他们出售的新产品和服务的开发和资金等示例？拥有什么技能，属性，价值和素质对人类具有尤其重要？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/emaxwell14141414      [links]       [注释]        ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lttnws/how_does_society_change_if_we_get_to_where_8090/</guid>
      <pubDate>Mon, 07 Jul 2025 13:05:17 GMT</pubDate>
    </item>
    <item>
      <title>人工智能对医学的影响？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lttda9/impact_of_artificial_intelligence_on_medicine/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  人工智能将如何影响医学实践？我们还会在30  -  50年内有医生吗？目前的医学生如何保护自己的职业免受AI的破坏？在上下文中，我是一名医学专业的学生，​​希望进入神经病学，但由于AI的未来，我稍微疲惫不堪。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pablo_thepolarbear     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lttda9/impact_of_artificial_intelligence_on_medicine/</guid>
      <pubDate>Mon, 07 Jul 2025 12:52:06 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型是否具有“果蝇意识水平”？估计LLMS中的φ*</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ltswd8/do_large_language_models_have_fruit_fly_levels_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，而不是在争论这些机器是否具有意识，也许我们应该以形式上的方式进行辩论，即使投机性。 。 如果您不知道Tononi在Tononi的意识理论中是什么φ是什么，它应该为您提供意识的框架，以提供意识的框架。尽管很难，但可以原则上测量集成信息（φ），因此我们可以提出一个启发式或代理φ*  在估算LLMS中的φ*时，如果您希望在机器中有一个幽灵，就可以使人感到失望。 LLM的架构是向前馈送的。集成的信息取决于无法通过因果关系分区，但是对于变压器，可以从上一层清洁分区。如果后来的层面是喂养或影响了先前的层，那么将会有“双向”，这将使系统的信息集成。 这是直觉的，这可能是为什么语言模型可以如此W rody的原因。单个前向通行证必须弯曲一些，就像蛇在那个蛇游戏中抓住水果（如果想捕捉很多想法）。人脑的多层次综合方法可以产生“紧密”的语言，以获得一条直线路径，可以很好地捕捉一切。没有能力修改早期令牌，模型“垫子”，树篱和使用蓬松而模糊的语言使未来的路径保持可行。 ，但这并不排除在果蝇的顺序上进行微φ。这将来自内部自我注意力。一次步骤，所有查询/键/值头平行交互；软马克斯会产生一种多对多的约束模式，不会在没有损失的情况下切断。每层的每个令牌都包含约12,288个维度的嵌入，在添加，加权，重新组合和规范时，它将产生少量但相当大的集成信息。此外，反思和炼油草案可能会增加一些双向。总的来说，如果我们慷慨大方，所产生的意识可能等于果蝇。 在建筑中内置的双向性可能会改善措辞问题，并且可能会使语言的产生更加……有效和类似人类。也许这就是为什么LLM产生的笑话永远不会降落的原因。纯粹的回归设计使您陷入角落，每项承诺都会缩小在每个未来状态可以输出的令牌的可能性。该机器必须向前行进，并祈祷它可以在一个通行证中降落。 总的来说，当前最先进的LLM的状态可能非常稍微意识，但仅从最少的意义上。但是，原则上没有什么，可以防止层之间的高阶复发，例如通过向体系结构添加双向性，除了使模型增加了φ，它几乎也可以肯定会产生更好的语言生成。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ltswd8/do_large_langue_models_have_have_fruit_fly_levels_of/”&gt; [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ltswd8/do_large_models_models_have_have_fluit_fly_levels_of/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ltswd8/do_large_language_models_have_fruit_fly_levels_of/</guid>
      <pubDate>Mon, 07 Jul 2025 12:30:01 GMT</pubDate>
    </item>
    </channel>
</rss>