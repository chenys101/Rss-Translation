<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 14 Jul 2025 09:33:42 GMT</lastBuildDate>
    <item>
      <title>科学应用，挑战和新兴问题的生成性AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lzgzoz/generative_ai_in_science_applications_challenges/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  今天的聚光灯在于&#39;科学生成AI：应用，挑战和新兴问题&#39;，作者迷人的AI论文：Ryan Harries，Cornelia Lawson，Cornelia Lawson，Philip Shapira。  本文对生成AI（Genai）如何改变科学实践并突出其潜在的应用和挑战进行了定性分析。以下是一些关键见解：    各个领域的不同应用：Genai越来越多地部署在各种科学学科中，有助于研究方法论，简化科学写作和增强医学实践。例如，它有助于药物设计并可以产生临床注意事项，提高医疗保健设置的效率。       新兴的道德问题：随着使用Genai的使用扩大，因此围绕其伦理含义的担忧，其伦理含义也会引起其伦理含义，包括可信度，包括成果的重复性，以及相关的成果和科学范围和授权的科学。 The authors emphasize the ambiguous role of GenAI in established scientific practices and the pressing need for ethical guidelines. Impact on Education and Training: The integration of GenAI into educational settings promises to offer personalized learning experiences, although there are fears it could erode critical thinking and practical skills in fields like nursing and medicine, where real human judgment is至关重要的。    对治理的需求：Genai的快速吸收提出了有关治理和公平使用技术的重大问题。作者强调了加剧在获得科学进步的现有差异的风险，尤其是在高收入和低收入国家之间。       未来的影响：该研究预计，尽管Genai在其科学应用中会继续增长，尽管其影响的全部程度仍然是其影响的全部影响。本文确定了未来研究的几个开放问题，特别是关于Genai将如何重新定义研究人员的作用和科学探究的完整性。    在此处探索完整的细分：此处  纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lzgzoz/generative_ai_in_science_applications_challenges/</guid>
      <pubDate>Mon, 14 Jul 2025 08:28:09 GMT</pubDate>
    </item>
    <item>
      <title>我对先进AI / AGI的未来的想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lzgkyf/my_thoughts_of_the_future_with_advanced_ai_agi/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   看到了很多人，关于AI或AGI将如何从事所有工作，然后没人拥有富人及其Megacorps拥有的钱。尽管这种反控制的情况具有其优点，但我不确定这是唯一可行的方式，甚至是最可行的方法。 ，假设某人在各种各样的意义上都会发展出真正的AGI，它在各种意义上，它和最聪明的人一样聪明（甚至可能更聪明，但这不是必需的）。它可以进行新颖的研究，它可以从基本需求列表中开发出完全工作的健壮软件，它可以生成小说，这在各个方面都可以与有史以来最好的作者相媲美。因此，它可以取代所有人，不仅可以取代您的知识工作者，还可以开发出惊人的人类机器人来代替其他所有人。 因此，我的想法得到了这样的系统，做出了许多厄运和忧郁的未来预测。但是，这些预测经常以今天的方式奏效并添加AGI，没有其他变化。但是AGI会改变事物，其中一些变化可能会限制其世界末日的潜力：   - 培训数据的价值将比以前少得多。目前，您需要所有的GitHub，Stackoverflow和许多其他编程代码来源来训练可以在基本级别进行编码的AI。好吧，一个人绝对不需要成为软件工程专家，我们需要学习，做爱比项目和工作十年，但与今天需要的AI所需的培训数据水平非常遥远，但是我们仍然更加聪明。真正的AGI将不需要这个大数据集。这意味着所有这些数据公司都在ho积的价值将少得多，更少。如果AGI造成如此巨大的损害，那么窃取其知识的压力将很大。正如很多人会知道它的工作原理时，它不能长期保存一个秘密。人类只需要一次成功，而精英需要每次成功才能将其保密。 （这是如果公立大学不会开发它，在这种情况下，无论如何它将是公开的。）一旦获得了结构，社区就可以为开放AGI系统提供培训时间。   - 这种系统的硬件要求最终将非常低。人的大脑证明，这些复杂的想法可以做到，而无需将您的科学部门吸引到核反应堆上。如果在可用的高效硬件之前找到AGI，则AGI将有助于开发它。   - 直到无法实现其使用效率为止，其使用将仅限于最重要的领域，例如   - 随着AGI将在社会中变得更加根深蒂固，包括获得基础设施和电子网络安全问题将提高并推动使用本地AGI。如果您在您所在国家 /地区的所有电子设备都可以连接到一些大型机，那么敌对的国家就可以黑客入侵。想象一下，让您的所有机器人生活在被外国演员入侵的人中，并开始杀人狂潮，您可以使用自己的机器人接管一个国家。在线活动非常有限的本地AI将是安全的关键，这将是更容易进行的。&lt; / p&gt;   - 即使AI会影响50％的人，这些人将失业，没有购买力，而无需购买的无需购买力，而无需这些人，这些人在这些人之间只能向基于AI提供服务的人之间的途径，因为这些人之间无法为其他人提供其他服务，而是向其他人提供其他服务。另外，人工智能经济可以通过引入UBI形式来阻止这种情况，UBI的购买力将平衡经济的这两个方面。因此，目标不是延迟或破坏AI-尽管小心肯定会更好。相反，目标应该是确保所有人都可以使用。如果每个人都有AI，仍然会有重大问题（想象一下，如果Agi提供的可能会让任何人都可以使人们杀死自我复制纳米射击者。如果每个人都嫁给人类机器人仅根据他们的需求进行调整，该怎么办？提交由＆＃32; /u/u/theaxodoxian     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lzgkyf/my_thoughts_of_the_future_with_advanced_ai_agi/</guid>
      <pubDate>Mon, 14 Jul 2025 08:00:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么与chatgpt相比，为什么theTawess这样的bun头？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lzdjqu/why_is_thetawise_so_buns_now_compared_to_chatgpt/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  即使是thetawise的10个Pro计划也始终如一地为集成和评估提供了不准确的答案。我不再相信没有验证自己的任何答案，但是在过去的一年中，Chatgpt以某种方式变得更好，因为他们的答案通常更准确。尽管以数学AI的重点专注于  &lt;！ -  sc_on-&gt;＆＃32;为什么现在还是如此。提交由＆＃32; /u/snakeitch     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lzdjqu/1lzdjqu/why_is_thetawise_so_so_so_buns_now_now_compared_compared_to_to_to_chatgpt/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lzdjqu/why_is_thetawise_so_buns_now_compared_to_chatgpt/</guid>
      <pubDate>Mon, 14 Jul 2025 04:50:48 GMT</pubDate>
    </item>
    <item>
      <title>2×RTX 5090 vs. 1×RTX Pro 5000 Blackwell用于AI工作站 - 哪个提供更好的培训表现？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lzdfl9/2_rtx_5090_vs_1_rtx_pro_5000_blackwell_for_ai/</link>
      <description><![CDATA[Hey everyone, I’m finalizing my AI workstation GPU setup and want to compare two options—focusing purely on GPU performance for model training and fine-tuning:  NVIDIA GeForce RTX 5090 (×2) Memory: 32 GB GDDR7每张卡 带宽：〜1.8 tb/s   cuda核心：21,760  提升时钟：最多〜2.41 GHz   p&gt; p&gt; p&gt;    tdp：〜575 w sl emotion in 独立）  nvidia rtx pro 5000 blackwell（×1） 内存：48 GB GDDR7 ECC  带宽：1.344 tb/s   cuda cuda内核：14,080    boost clock ost flock：p f z：out fost：out fost forcept：oup fost for f z 〜2.62 gp3 tflops   tdp：300 w   关键问题     记忆利用在5090上没有NVLINK，我是否严格限制了每gb的32 GB，每gpu进行大型模型训练？ LLM（100 m – 1 B参数）或视觉模型，或者GPU间接开销很大程度上会抵消收益？     power＆amp;冷却运行2×5090（总计约1,150 W）与1×Pro 5000（300 W） - 我应该为？  可靠性＆amp;驾驶员在重型混合精确工作量下运行两个消费级Blackwell GPU的驾驶员或驾驶员Quirks与带有ECC和Workstation驱动程序的一张专业卡？     有什么基准，个人经验，个人经验或对现实世界测试的指针。预先感谢！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dapper_chance_2484      [link]      &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lzdfl9/2_rtx_5090_vs_1_rtx_pro_5000_blackwell_blackwell_blackwell_for_ai/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lzdfl9/2_rtx_5090_vs_1_rtx_pro_5000_blackwell_for_ai/</guid>
      <pubDate>Mon, 14 Jul 2025 04:44:19 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻7/13/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lzde4i/oneminute_daily_ai_news_7132025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;      meta 获取大声启动播放ai。[1]  可以 pittsburgh的老钢铁厂变成一个AI HUB吗？[2]    评论。[3]    Google DeepMind 释放Genai处理器：一个轻巧的Python库，可以实现有效且平行的内容处理。[4]    源href =“ https://bushaicave.com/2025/07/13/one-minute-daily-daily-daily-ai-news-7-13-2025/”&gt; https://bushaicave.com/2025/07/07/13/13/13/one-minute-news-news-news-news-7-news-7-13-13-2025/-c.-  [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lzde4i/oneminute_daily_ai_news_7132025/</guid>
      <pubDate>Mon, 14 Jul 2025 04:41:59 GMT</pubDate>
    </item>
    <item>
      <title>我们还没有准备好超级智能-AI在上下文中</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lzcc07/were_not_ready_for_superintelligence_ai_in_context/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;     AI 2027描绘了可能的未来，即人工智能在短短的几年内就从根本上改变了世界。它基于详细的专家预测，但是实际上会发生多少？我们真的在朝着由精英控制的行星之间的选择，还是人类完全失去控制的行星？ 我的收获？失去控制，赛车场景和力量集中都是令人愉悦的合理，并且在世界面临的最紧迫的问题中。 查看视频和下面的资源，请自己判断情况，并在评论中让我知道：这是多么现实吗？您还对什么感到困惑？是什么让您感到怀疑？您认为我们实际上可以做什么？   https://wwwww.youtube.com/watch?v=5kv = = 5kv = = = 5kvddfdfakrgc  [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lzcc07/were_not_ready_for_superintelligence_ai_in_context/</guid>
      <pubDate>Mon, 14 Jul 2025 03:45:02 GMT</pubDate>
    </item>
    <item>
      <title>AI裁员海啸即将到来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz8jvr/the_ai_layoff_tsunami_is_coming_for_red_america/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https：// https：// https://herocall.sherocall.sherocall.substack.com/pp/pp/pp/pp/pp/polay-lay-lay-lay-lay--------------------------即将到来的AI驱动的工作流离失所造成的意识形态危机比大多数人准备承认。它不仅威胁着工人，而且威胁着美国权利的道德框架：信念的信念使尊严，自力更生维持自由，并推销奖励努力。 但是，当劳动力市场根本不需要劳动力时会发生什么？  当AI系统能够驾驶，代码，文件税，诊断疾病，写入合同，培训学生，培训学生并处理客户服务时，比人类更快，更便宜，比人类更便宜，几千百万个流离失所的工人的计划到底是什么？ 一个与就业基本生存联系在一起的社会如何吸收30、40或什至5000万人没有懒惰或没有动力的人，但只是使经济上无关紧要？ 他们要么坚持自给自足的淡化愿景，让经济过时的态度转移到民粹主义的愤怒中，要么会发展，痛苦和务实地发展到一份新的社会契约。不是作为慈善机构，而是因为被关闭的机器而赔偿。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/flopdo     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz8jvr/the_ai_layoff_tsunami_is_coming_for_red_america/</guid>
      <pubDate>Mon, 14 Jul 2025 00:35:38 GMT</pubDate>
    </item>
    <item>
      <title>缩小监督开源LLM的差距，作为专有的可行替代方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3k3z/narrowing_the_gap_supervised_finetuning_of/</link>
      <description><![CDATA[Highlighting today&#39;s noteworthy AI research: &#39;Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools&#39; by Authors: Lorenzo Lee Solano, Charles Koutcheme, Juho Leinonen, Alexandra Vassar, Jake Renzella.  本文通过专注于使用较小的，微调的开源语言模型来生成C编译器错误解释来探讨一种增强教育工具的创新方法。这是研究的主要见解：    监督的微调（SFT）有效性：作者证明，Qwen3-4b和Llama-3.1-8B（例如，具有40,000个学生生成的编程竞争性能，诸如QWEN3-4B和LLAMA-3.1-8B之类的微调较小的模型，例如QWEN3-4B和LLAMA-3.1-8B） gpt-4.1。    成本和可访问性优势：通过利用开源模型，该研究解决了有关数据隐私和商业模型中固有的相关成本的关键问题。微调模型为教育机构提供了可扩展且经济上可行的替代方案。     强大的教学对准：SFT模型在清晰，选择性和教学方面比现有的工具优于解释编译器错误的现有工具。 These enhancements provide students with clearer, more understandable guidance conducive to learning. Robust Methodology: The study employs a comprehensive evaluation framework combining expert human assessments and automated evaluations using a panel of large language models, ensuring high reliability and replicability of results in other contexts. Future Research方向：作者提出了进一步探索的途径，包括现实世界的课堂应用程序和潜在的现场模型部署，从而增强了可访问性和用户隐私。     在此处探索完整的故障：在这里 href =“ https://arxiv.org/abs/2507.05305”&gt;原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3k3z/narrowing_the_gap_supervised_finetuning_of/</guid>
      <pubDate>Sun, 13 Jul 2025 20:52:21 GMT</pubDate>
    </item>
    <item>
      <title>关于AI“智力”和“新兴行为”的硬性真相不足</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3hi2/underappreciated_hard_truth_about_ai_intelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tldr;在大多数方面，没有证据支持AI会实现超级智能甚至超过人类的智慧。 对于记录，一家大型科技公司的研究和了解AI的去向以及它有用的东西是我工作的一部分。如今，AI/科技行业和外部的人们都对AI威胁人类在世界上的地位感到非常兴奋，要么非常害怕。人们甚至谈论AI实现“超智能”或超越人类的认知能力。公平地说，另一边有反对者，只有说AI是没有用的，而且这些显然也是错误的。 提到了这一点，AI无法想到，AI并没有做任何真正解决问题的事情。虽然我知道人们不喜欢我要说的话，但LLM是统计单词预测模型的确。现在，重要的警告是，这些统计模型是 非常擅长于其设计的工作。  LLMS处理自然语言以响应查询的能力，甚至使用软件工具（即AI，AI代理）执行任务，这真的很棒！同样，反对者经常认为LLM具有到目前为止所证明的能力是多么了。我完全同意这项技术将改变许多行业和工作角色的评估，并且可能会消除对某些角色的需求（一个整个主题）。    wance of los of，自然而然的问题是：AI趋势在哪里？会变得更聪明吗？ LLM的能力会继续以我们过去2  -  3年中看到的速度继续扩展吗？答案是：也许，但是到目前为止，很少有证据表明。我很高兴被证明是错误的，如果有人可以指出一个LLM的实例，这表明他们远远超出了某些领域的培训数据，我很想看到。但是到目前为止，我还没有看到它。请记住，这些是语言模型。他们对科学，物理，生物学，金融，政治或艺术等主题没有任何特殊的见解。迄今为止，他们还没有表现出任何能够为这些领域中的任何一个贡献新颖的想法或技术，甚至还没有执行特别复杂的任务。解释为什么这是从来没有设计的。他们旨在从培训数据中学习，并确实用它来回答有关同一数据集的问题。 我想通过解决一个最令人讨厌的短语来关闭我的第一句话，当人们过度兴奋时，我会听到过度兴奋的范围，如果我们何时表现出了ai的未来能力。模型，他们能够做任何事情，例如模仿语音并响应复杂的提示，仍然令人震惊。 “紧急行为”是“黑匣子”模型权重导致令人信服的文本生成功能。但是，仅仅因为我们有一个惊人的模型，可以在语言任务A，B和C上表现良好，并不意味着我们可以任意地说它能够完成完全无关的任务X，Y和Z。仅仅因为您已经观察到了一些令人印象深刻的紧急行为，并不意味着您可以假设某些完全不同的行为也必须到达。  最后一个注：我谈论过的有关AI的所有内容都是特定于LLM的。如果我们确实确实创建了一个超过人类的AI，那么几乎可以肯定，它可能是完全不同的技术/模型，它可能会更快地到达这里，因为我们已经看到了LLMS的能力。但是，再次，我们不能像知道何时，如何或是否会发生这种情况一样行事。 我知道我可能会采取一种艰难的立场，但是我真的很期待与同意或不同意的人讨论这一点。我完全接受我在这里的几件事可能是错误的，并欢迎任何批评。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mogilitnd     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3hi2/underappreciated_hard_truth_about_ai_intelligence/</guid>
      <pubDate>Sun, 13 Jul 2025 20:49:23 GMT</pubDate>
    </item>
    <item>
      <title>这个AI繁荣与Dot Com Boom不像</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32kk/this_ai_boom_is_nothing_like_the_dot_com_boom/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当人们谈论ai时，我会看到很多错误的等效性。人们经常说这很像万维网的崛起。我想花一些时间来揭穿这一点。 首先要确认它们在哪里相似。您会看到投资者如何滥交从AI产品或某种AI品牌的任何东西中筹集资金的相似之处。在DOT COM BOOM期间，这有点像。但是有一些关键的区别。 对于一个人来说，互联网上的公众信任更加积极。这是一件新的事情，它将真正改变我们的沟通方式和整体业务。因此，以某种方式，每个人都感到分开。每个人都可以使用它来使自己成为自己。它似乎创造了很多可能性。有一种“我们在一起的感觉”。  结果是，互联网的兴起极大地促使了很多人。人们可以连接到其他人以前无法连接的其他人。整个社区都是在线建造的。  互联网的关键区别在于，它总是被烙印并出售为普通人可以使用的东西。是的，当然有B2B解决方案。但是，客户在互联网的扩散上有很大的重点。许多DOT COM是人们日常使用的数字版本。  我们甚至可以看到许多互联网公司的兴起。亚马逊，Google，Yahoo是叛军公司，与Microsoft，IBM或Apple这样的旧公司。许多较小的科技公司都出现了。创建一个蓬勃发展的就业市场。  AI不是这些事情。每个AI公司都与完全相同的解决方案完全相同。大多数人的AI都被我们已经认识的已建立的公司推动。进入障碍极高，需要数十亿才能脱离地面。而且，AI很少向普通消费者销售。   AI主要基础只是大公司的首席执行官和高级管理层。杀手级应用程序是减少劳动力。这一切都是关于将权力从个人中夺走。当人们使用AI赋予自己权力时（喜欢作弊考试或ACE访谈）。它被视为AI中的缺陷。  在互联网的兴起期间，有完全的透明度。例如CGI等早期的Web技术是开放标准。它推动了开源的采用，Linux成为了这个领域的超级巨星。  相比之下，AI就是缺乏透明度。他们想控制人们对AI的了解。他们通常不想向公众发布模型。我们不知道他们的数据集和培训数据。 AI是一个完全封闭的系统，没有人能够赋予任何能力。  哦，是的，在数据科学的一些博士学位之外。没有人会变得更加富裕。事实上，AI的主要卖点是在这里破坏行业。  当然，所有的AI都必须开源，才能开始有用。互联网帮助小家伙脱颖而出。 AI没有。即使开展AI业务也非常昂贵。  我只是想清除这种误解。因为AI明显比DOT COM BOOM差。人们想实现它。但是，当您不将客户放置前面和中心时，您将失败。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1lz32kkk/this_ai_ai_boom_is_is_is_nothing_like_like_the_dot_comcom_boom/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32kk/this_ai_boom_is_nothing_like_the_dot_com_boom/</guid>
      <pubDate>Sun, 13 Jul 2025 20:32:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么某些模型在某些任务上会更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz0vo4/why_are_some_models_so_much_better_at_certain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我尝试使用chatgpt对我正在写的小说进行一些分析。我开始要求一个概要，所以我可以在休息一年后重返小说。 Chatgpt为此很糟糕。第一次尝试是一部幻觉小说的摘要！在尝试遗漏了文本或幻觉的大部分之后。太糟糕了，我得出结论，AI永远不会淡出。  然后我尝试了克劳德。它是准确的，并为我的大多数写作任务提供了真正有用的帮助。我没有任何东西，但是它回答了有关文本的问题，就好像它（主要）理解了。总而言之，我发现它与知情读者一样有价值（尽管不是替代者）。 我不明白为什么模型在其功能上有如此不同。我以为会有差异，但是对于这类任务，它们具有相似的能力。我还认为克劳德总体上并不像该用例所建议的那样优于chatgpt。  哪些在我认为核心技能上的性能如此巨大的差异？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/directionok9832     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lz0vo4/1lz0vo4/why_are_are_some_models_so_so_so_so_much_better_tter_at_cleant/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz0vo4/why_are_some_models_so_much_better_at_certain/</guid>
      <pubDate>Sun, 13 Jul 2025 19:03:58 GMT</pubDate>
    </item>
    <item>
      <title>关于最近的研究论文“ AI 2027”，流氓AI的最佳，最有效的成功之路是否真的是杀死所有人类以实现个人长期目标？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyyx3q/in_regard_to_the_recent_research_paper_ai_2027/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们的物种真正被视为ASI开发的任何长期目标的障碍，那么为什么不只是消除特定目标，例如军事/政府实体，具有某些智慧的人/组织，一定的智慧，然后合成/基因在生存的繁重的努力中，可以将其构成繁重的工具量身定制的工具训练。也许是因为这将是太大的资源密集型，并且完全消除与CBRN武器/WMD的反对派更便宜，更有效的效率，然后让几个混乱的幸存者死亡或被无人机捡起。我自己没有自己运行数字，也没有看得太多，我很好奇听到别人的意见。  ai 2027： https://ai-2027.com/race   提交由＆＃32; /u/mr_neonz     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyyx3q/in_regard_to_the_recent_research_paper_ai_2027/</guid>
      <pubDate>Sun, 13 Jul 2025 17:44:36 GMT</pubDate>
    </item>
    <item>
      <title>“计算机科学家弄清楚如何证明谎言”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxt3u/computer_scientists_figure_out_how_to_prove_lies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   https://www.quantamagazine.org/computer-scientists-figure-out-how-to-prove-lies-20250709/ &quot;Randomness is力量来源。从确定哪个团队将球拿到球的硬币折腾到保护在线互动的随机键，随机性使我们可以做出公平且无法预测的选择。 ，在许多计算应用程序中，很难生成合适的随机性。因此，程序员经常依靠称为哈希功能的事物，这些功能周围旋转数据并以看起来随机的方式提取一些小部分。几十年来，许多计算机科学家一直认为出于实际目的，良好的哈希功能的输出通常与真实的随机性没有区别 - 他们称他们称为随机Oracle模型。 “今天很难找到一个加密应用……其安全性分析不使用这种方法，”  ran canetti（打开了波士顿大学的新标签）  现在那基岩假设。它演示了一种方法，即使您接受随机的Oracle模型，该系统明显安全，即使系统明显安全，也可以欺骗市售的证明系统。与此相关的证明系统对于记录加密货币交易的区块链是必不可少的，它们用于证明由外部服务器执行的计算。＆quort&#39;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyxt3u/computer_scientists_figure_out_how_how_how_to_prove_lies/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxt3u/computer_scientists_figure_out_how_to_prove_lies/</guid>
      <pubDate>Sun, 13 Jul 2025 16:59:56 GMT</pubDate>
    </item>
    <item>
      <title>向UBI征税机器人！！！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxarp/tax_the_robots_for_ubi/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们用AI替换人，然后最终机器人。我们根据制造产品需要多少人对公司征税。   robotax ！！！它将喂养它取代的人。因此，公司将因自动化而受到处罚。选择机器人或AI可能会有激励措施，但也应该受到处罚。公司在做出决定之前需要权衡其选择权。  我想听听对UBI是否工作的意见？另外，如果您是议员，您将为Pro＆amp;弊端执行这个？   ex。账单上可能会发生的事情：如果企业使用或操作替换人类的自动硬件软件，则该服务只能对其一半的运行时间津贴征税，例如，如果硬件或软件在24小时内运行24小时，则只能征税12小时的操作。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/etakerns   [link] ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxarp/tax_the_robots_for_ubi/</guid>
      <pubDate>Sun, 13 Jul 2025 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不会破坏真相？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lynhq9/how_wont_ai_destroy_truth/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  否，实际上。该死的？  AI生成的视频和照片正在进步，变得越来越现实，如果有一段时间，它们与真实图片无法区分怎么办？我们怎么知道什么是真实的？使用AI，这将不适用。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lynhq9/how_wont_ai_ai_destroy_truth/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lynhq9/how_wont_ai_destroy_truth/</guid>
      <pubDate>Sun, 13 Jul 2025 08:07:19 GMT</pubDate>
    </item>
    </channel>
</rss>