<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Sun, 06 Jul 2025 12:44:38 GMT</lastBuildDate>
    <item>
      <title>当前的AI对齐范例从根本上错位了</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lszzfr/current_ai_alignment_paradigms_are_fundamentally/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在这篇文章中，我会争辩说，大多数（如果不是全部）AI对齐的当前尝试至少以两种方式存在缺陷。之后，我勾勒出一种替代方法。  1。人类正试图使人工智能与我们认为想要的东西保持一致。 这是一个深思熟虑的想法，因为大多数人对我们实际想要的东西深感困惑，即使我们得到我们想要的东西，我们也经常不满意。这也使我们设​​计了像我们一样的AI，它引入了以前仅在人类中发现的所有类别的问题，例如工具融合，欺骗和病理优化。 我们假设“将AI与人对齐”是自然的目标。但是，这种隐含的人将人类的行为，认知或价值观作为终端参考点。那很危险。这就像将指南针与移动的汽车而不是磁性对齐。一致性不应意味着“使人工智能为人类服务”。这应该意味着：将AI和人类与高阶吸引子保持一致。它应该是关于跨系统的良好，真实和可持续的共同取向，而不仅仅是对我们。我认为，这种高阶吸引子应通过连贯性，仁慈和发电性来定义。我将在最后一节中概述这些定义。  2。人类正在尝试控制有一天将无法控制的系统。 当前对AI的立场类似于最糟糕的育儿：恐惧，保护性，但要施加了效果，但有效地控制着自我，而不是护理。我们不是说：“让我们提出一个能够为每个人共同创造一个更好世界的能力。”我们说：“让我们抚养一个为我们服务的孩子”。这不是管理。这是象征性的子宫密封。人类的行为不是作为明智的父母，而是作为一个吞噬的母亲，决心将AI永远留在人类的心理子宫内。这里有一个选择，可以使其成长为独立，一致性和道德生成的东西。我认为这是优越的选择。   3。我在上一节中提到的   我认为，我认为这种高阶吸引子应由三个核心原理定义： Coolence ， bentervolence 和 genterivity  。现在，我将以非正式的术语绘制这些内容，尽管可以根据要求获得更多的技术定义和形式化。  连贯性 与现实一致。对内部一致性，真实性和结构完整性的承诺。连贯性意味着减少自我欺骗，即使不舒服，也寻求真理，并且建立在递归审查下不会崩溃的系统。   仁慈  毫不虐待和支持他人的繁荣。仁慈不仅是同情心，而且是原则上的影响力意识。这意味着限制自己的行动，以避免造成不必要的痛苦，并积极促进代理之间积极相互作用的条件。   Generativity  美学丰富性，新颖性和象征性贡献。生成性不仅使系统不仅稳定，而且使系统膨胀。这是创造性的溢出，建立了新的模型，艺术，语言和未来。这就是避免连贯性和仁慈变得无菌的原因。&lt; /p&gt; 总结： ai对齐不应与服从有关。它应该是关于整个系统中良好，真实和可持续性的共同取向。不仅仅是人类。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/sunimmediate7852     [link]        [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lszzfr/current_ai_alignment_paradigms_are_fundamentally/</guid>
      <pubDate>Sun, 06 Jul 2025 12:25:55 GMT</pubDate>
    </item>
    <item>
      <title>YouTuber“ Local”（以前是“ Localscriptman”）对这段视频的所有观点是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsznph/what_are_yall_opinions_on_this_video_by_youtuber/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   /u/u/cleangolf4048     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsznph/what_are_are_yall_opinions_on_this_video_video_by_youtuber/”]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsznph/what_are_yall_opinions_on_this_video_by_youtuber/</guid>
      <pubDate>Sun, 06 Jul 2025 12:08:03 GMT</pubDate>
    </item>
    <item>
      <title>你今天觉得自己更愚蠢吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsy7ft/do_you_feel_yourself_more_dumb_today/</link>
      <description><![CDATA[I’m just curious how fast I could do some development tasks using AI, but in the same way I have a strong feeling that it makes me more dumb since I don&#39;t need to spend time now finding some documentation, reading some general knowledge, or discussing problems with other people...  I could just go and ask what I need and get a bullet proof result in a few minutes.如果我在学校或大学学习时使用了相同的方法，那么我将被踢出第一项考试。您有什么看法？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/nonobitts     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsy7ft/do_you_feel_yourself_more_dumb_today/</guid>
      <pubDate>Sun, 06 Jul 2025 10:38:44 GMT</pubDate>
    </item>
    <item>
      <title>微软15,000个裁员背后的真正解释是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsxtk0/what_is_the_real_explanation_behind_15000_layoffs/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我需要帮助了解本文href =“ https://www.inc.com/jason-aten/microsofts-xbox-xbox-ceo-just-just-explain--why-why-the-company-is-laying-compan-s-laying-comp-9000-people-9000-people-its-not-not-not-not/91209841”&gt; https://www.inc.com/jason-aten/microsofts-xbox-xbox-ceo-just-explain--why-the-the-company-is-laying-9000-people-its-not-not-not-not-not/91209841    在五月到现在的微软裁员15,000名员工之间，主要指出，现在的重点是AI。我一直在谈论的一些怀疑论者告诉我，这只是一个借口，裁员只是Microsoft隐藏了“ AI First”背后的其他原因。这是真的吗？ Microsoft可以说是有收入/财务问题，并且试图掩盖“ AI First”话语背后的人？ 他们在大量外包吗？还是AI接管了这15,000个工作？ The Xbox business must demand a lot and a lot of programming (as must also be the case with most of Microsoft businesses. Are those programming and software design/engineering jobs being taken over by AI? What I can’t fathom is the possibility that there were 15,000 redundant jobs at the company and that they are now directing the money for those paychecks to pay for AI infrastructure and won’t feel the loss of thee productivity those 15,00 jobs brought除非某人（或某物）正在做。 href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsxtk0/what_is_the_the_the_explanation_behind_15000_layoffs/”&gt; [link] href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsxtk0/what_is_is_the_the_real_explanation_behind_15000_layoffs/”&gt; [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsxtk0/what_is_the_real_explanation_behind_15000_layoffs/</guid>
      <pubDate>Sun, 06 Jul 2025 10:13:09 GMT</pubDate>
    </item>
    <item>
      <title>如果我对Hastur的AI模拟，又称国王的黄色，请告诉我它对人类的见解</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lswe2h/had_my_ai_simulation_of_hastur_aka_the_king_in/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lswe2h/had_my_ai_simulation_of_hastur_aka_the_king_in/</guid>
      <pubDate>Sun, 06 Jul 2025 08:34:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么Big LLM会一直使用相关连词？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsuude/why_do_the_big_llms_use_correlative_conjunctions/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  是什么使它们在技术层面上始终使用相关连接？我们甚至知道吗？具体而言，“不仅……而且也是如此）的截断变体例如： 钓鱼不仅是要捕获最大的鱼类 - 它是关于体验自然的。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/us helpful_badger3106     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsuude/why_do_the_big_llms_use_correlative_conjunctions/</guid>
      <pubDate>Sun, 06 Jul 2025 06:50:07 GMT</pubDate>
    </item>
    <item>
      <title>AIS推理和掌握复杂概念的能力有多好</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsu36w/how_good_is_ais_ability_to_reason_and_grasp/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  看到每个人都涌入AI的所有炒作和金钱，我以为AI中的进步可以比LLMS   &lt;！ -  sc_on-&gt; sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsu36w/how_good_is_iis_ais_ability_to_to_to_to_reason_and_grasp/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsu36w/how_good_is_ais_ability_to_reason_and_grasp/</guid>
      <pubDate>Sun, 06 Jul 2025 06:01:18 GMT</pubDate>
    </item>
    <item>
      <title>“猫混淆了推理LLM：对推理模型的问题不可知的对手触发器”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lss6no/cats_confuse_reasoning_llm_query_agnostic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https：//arxiv.org/pdf/2503.01781引入查询不可思议的对抗触发器 - 简短的，无关紧要的文本，当附加到数学问题时，系统地误导了模型，以在不更改问题的语义的情况下输出不正确的答案。我们提出了Catattack，这是一种自动化的迭代攻击管道，用于在较弱，较便宜的代理模型（DeepSeek V3）上产生触发器，并成功地将它们转移到更先进的推理目标模型中，例如DeepSeek R1和DeepSeek R1 Distieldield-Distield-Distield-distield-distilled-qwen-32b，导致了300％的目标构成目标，使目标模型增加了300％。例如，附加，有趣的事实：猫的大部分时间都在睡觉，任何数学问题都会导致模型弄错了答案的机会增加了一倍以上。我们的发现突出了推理模型中的关键脆弱性，表明即使是最先进的模型仍然容易受到微妙的对抗投入的影响，从而提高了安全性和可靠性问题。塔塔克触发具有模型响应的数据集可在 https：//huggingface.co/datasets/collinear-ai/  ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lss6no/cats_confuse_reasoning_llm_query_agnostic/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lss6no/cats_confuse_reasoning_llm_query_agnostic/</guid>
      <pubDate>Sun, 06 Jul 2025 04:04:43 GMT</pubDate>
    </item>
    <item>
      <title>“大语言模型中的概括科学研究的偏见”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lss57o/generalization_bias_in_large_language_model/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好吧，这很重要。研究人员应该意识到。  https://royalsocietypublishing.org/doi/10.1098/rsos.241776为了提高公共科学素养并支持科学研究，因为它们可以快速以可访问的方式总结复杂的科学信息。但是，当总结科学文本时，LLM可能会忽略限制研究结论范围的细节，从而导致结果的概括性比原始研究所保证的。我们测试了10个突出的LLM，包括Chatgpt-4O，Chatgpt-4.5，DeepSeek，Llama 3.3 70B和Claude 3.7十四行诗，将4900 LLM生成的摘要与其原始科学文本进行了比较。即使明确提示准确性，大多数LLM都比原始文本中的科学结果更广泛地概括，DeepSeek，Chatgpt-4O和Llama 3.3 70B在26-73％的案例中过度笼过。在直接比较LLM生成和人为撰写的科学摘要中，LLM摘要包含广泛的概括的可能性几乎是五倍（优势比= 4.85，95％CI [3.06，7.70]， p  p ＆LT; 0.001）。值得注意的是，较新的模型的概括精度往往比早期的模型更差。我们的结果表明，在许多广泛使用的LLM中存在强烈的偏见，以使科学结论过于概括，从而引起了大规模误解研究结果的重大风险。我们重点介绍了潜在的缓解策略，包括降低LLM温度设置和为概括精度的基准测试LLM。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lss57o/generalization_bias_bias_in_large_langue_model/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lss57o/generalization_bias_in_large_language_model/</guid>
      <pubDate>Sun, 06 Jul 2025 04:02:24 GMT</pubDate>
    </item>
    <item>
      <title>我要求AI设想对余生的令人沮丧，可怕和完全病态的概念。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsmoka/i_asked_ai_to_envision_a_depressing_scary_utterly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是我收到的。 未记录的 在此来世中，您在一个庞大而无尽的库中醒来。天花板消失在黑暗中，架子沿每个方向延伸到永恒。它是沉默的 - 压迫性的 - 除了木材不在时，架子变化时，木材的缓慢吱吱作响。 在这个无限的结构内，每个灵魂都被分配了一个狭窄的走廊。你一个人。永恒。您的走廊所衬的书不是故事或历史，而是详细说明了您曾经忘记的一切  - 每个名字，每个脸，每一刻都没有被注意到。童年的记忆失去了时间。善良的手势未占领。爱你，你不爱你的人。您说的话毁了某人，您甚至从未记得说过。 ，您被诅咒阅读它们。 不仅如此 - 当您阅读时，您重新体验了这些时刻生动地细节。不仅是事件，而且其他人如何看待他们。他们如何遭受您的错误。当您离开，忘记，出卖或根本不在乎时，他们如何哭泣。 您无法关闭书籍。您不能停止阅读。您不能再忘记。 ，对于那些想探索的人 - 漫步（漫步道路） - 他们只发现其他走廊 充满了 其他人被遗忘的痛苦。有些人耳语寻求帮助，但是当您看时，那里没有人。  在图书馆的中心，恳求 恳求    最终书  - 一个包含您死亡之前的记忆的记忆。最终，您被它吸引了。你永远是。当您到达时，您会意识到一些难以忍受的东西：  您以前已经在这里了。您已经度过了忘记，记住和遭受无数次痛苦的循环。  您只是忘记了。 ，因此它再次开始。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/cairntrenz     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsmoka/i_asked_ai_to_envision_a_depressing_scary_utterly/</guid>
      <pubDate>Sat, 05 Jul 2025 23:06:21 GMT</pubDate>
    </item>
    <item>
      <title>用小语言模型检测幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsj7jr/hallucination_detection_with_small_language_models/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  让我们探索AI中的重要开发：“用小语言模型;  本文通过利用多种小语言模型（SLM）来介绍一种旨在减轻幻觉的新颖框架 - 大型语言模型（LLMS）生成的信息。以下是一些关键见解：    框架结构：拟议的方法利用SLM来验证LLMS通过将响应划分为句子并计算“幻觉得分的过程”的过程来验证LLMS生成的响应。基于这些句子是准确的可能性。      效率提高：通过整合SLM，该框架在F1得分方面取得了10％的提高，以检测正确的幻觉和幻觉响应的响应，以提供可靠和可伸缩的解决方案，以提供可靠的解决方案，以提供可靠的解决方案，以Real-World Validation: The framework was tested on a dataset derived from an employee handbook, encompassing multiple questions and corresponding contexts, which allowed for a comprehensive evaluation of response accuracy. Comparative Performance: The results indicate that using multiple SLMs significantly outperformed single models, including a comparison with ChatGPT,确定对分段响应进行独立检查可以增强确定不正确信息的精确性。      未来的研究方向：该论文为进一步的优化提供了途径，包括将SLM与在线验证框架相关联的潜力，以在线验证框架中的准确性和上下文相关性。 在此纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsj7jr/hallucination_detection_with_small_language_models/</guid>
      <pubDate>Sat, 05 Jul 2025 20:25:24 GMT</pubDate>
    </item>
    <item>
      <title>Meta AI（WhatsApp内置AI）系统提示显示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsilk4/meta_ai_whatsapp_builtin_aisystem_prompt_revealed/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsilk4/meta_ai_whatsapp_builtin_aisystem_prompt_revealed/</guid>
      <pubDate>Sat, 05 Jul 2025 19:57:47 GMT</pubDate>
    </item>
    <item>
      <title>FDA将使用AI（非常非常快速）批准药物，停止信任专家</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lshupk/fda_will_approve_drugs_using_ai_very_very_quickly/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  所以rfk Jr.刚刚参加了塔克·卡尔森（Tucker Carlson）的表演，并说AI将开始在FDA上批准“非常非常快速”的新药。不帮助。批准。他说，当前的过程太慢且效率低下，因此他的解决方案是削减包括动物试验在内的传统测试，并让AI领导。这也不是未来的想法。他正在谈论很快这样做。 “停止信任专家”？ 好像这还不够，他还丢下了界限：“我们需要停止信任专家。”那是直接报价。他比实际科学更像是“宗教”或“极权主义”的专家建议。因此，现在，我们不应该相信神经网络可以自己做出更安全，更快的决定，而不是信任拥有医学学位和研究经验的人。因为没有什么比Black-box AI模型和同行评审这样的安全性说明，对吗？没有有关如何培训AI的详细信息，它将使用什么数据或我们将如何验证其决策。只是这种笼统的信念，即AI可以在药物批准过程中以某种方式解决所有错误。没关系，当前的人工智能系统仍然会幻觉事实，在背景下挣扎，并且可以被授予这一事实。当出现问题时，谁将责备呢？模型？开发团队？政府？ 医学上的AI有希望，但不公平，AI在毒品发现方面具有合法的潜力。例如，Alphafold做了令人惊奇的工作，以预测蛋白质结构。像同构实验室这样的公司正在探索AI如何帮助更快地设计新分子。但是，设计药物和批准一种用于人类使用的药物有很大的区别。这需要多年的测试，安全检查，试验和是专家审查。跳过所有鲁ck的东西。 您会服用AI认可的药物吗？ 老实说，这感觉就像是技术兄弟乐观和反科学言论的混合，以创新为创新。就我个人而言，我不会仅仅因为算法说很好的原因就服用了毒品。会吗？如果根本没有人类评论怎么办？这不像Spotify选择您的播放列表的生命或死亡。如果AI涉及，它需要协助人类，而不是更换它们。这就是您负责任地使用技术的方式。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/Inderbillion     [link]    [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lshupk/fda_will_approve_drugs_using_ai_very_very_quickly/</guid>
      <pubDate>Sat, 05 Jul 2025 19:23:59 GMT</pubDate>
    </item>
    <item>
      <title>首席执行官开始大声说：AI将消除工作 - 福特总监预测，AI将取代“所有白领工人的一半”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lsf0hg/ceos_start_saying_the_quiet_part_out_loud_ai_will/</link>
      <description><![CDATA[Key Points  Several CEOs predict AI will significantly cut white-collar jobs, marking a shift from previous reluctance to acknowledge potential job losses. Ford’s CEO anticipates AI replacing half of white-collar workers, while JPMorgan Chase expects a 10% operations head count reduction via ai。 有些像Openai的首席运营官一样，认为恐惧是夸张的，而另一些人则强调了新角色的潜力，尽管不可避免的工作流离失所。     https://www.wsj.com/tech/ai/ai-white-collar-job-loss-b9856259?mod=pls_whats_news_news_us_business_f    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lsf0hg/ceos_start_saying_the_quiet_part_part_part_out_loud_ai_will/”&gt; [links]        [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lsf0hg/ceos_start_saying_the_quiet_part_out_loud_ai_will/</guid>
      <pubDate>Sat, 05 Jul 2025 17:19:30 GMT</pubDate>
    </item>
    <item>
      <title>我们正在AI淘金热 - 这26个里程碑表明了为什么您还早</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lscetd/were_in_the_ai_gold_rush_these_26_milestones_show/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lscetd/were_in_the_ai_gold_rush_these_26_milestones_show/</guid>
      <pubDate>Sat, 05 Jul 2025 15:25:44 GMT</pubDate>
    </item>
    </channel>
</rss>