<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Mon, 14 Jul 2025 02:06:33 GMT</lastBuildDate>
    <item>
      <title>AI裁员海啸即将到来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz8jvr/the_ai_layoff_tsunami_is_coming_for_red_america/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https：// https：// https://herocall.sherocall.sherocall.substack.com/pp/pp/pp/pp/pp/polay-lay-lay-lay-lay--------------------------即将到来的AI驱动的工作流离失所造成的意识形态危机比大多数人准备承认。它不仅威胁着工人，而且威胁着美国权利的道德框架：信念的信念使尊严，自力更生维持自由，并推销奖励努力。 但是，当劳动力市场根本不需要劳动力时会发生什么？  当AI系统能够驾驶，代码，文件税，诊断疾病，写入合同，培训学生，培训学生并处理客户服务时，比人类更快，更便宜，比人类更便宜，几千百万个流离失所的工人的计划到底是什么？ 一个与就业基本生存联系在一起的社会如何吸收30、40或什至5000万人没有懒惰或没有动力的人，但只是使经济上无关紧要？ 他们要么坚持自给自足的淡化愿景，让经济过时的态度转移到民粹主义的愤怒中，要么会发展，痛苦和务实地发展到一份新的社会契约。不是作为慈善机构，而是因为被关闭的机器而赔偿。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/flopdo     [link]   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz8jvr/the_ai_layoff_tsunami_is_coming_for_red_america/</guid>
      <pubDate>Mon, 14 Jul 2025 00:35:38 GMT</pubDate>
    </item>
    <item>
      <title>缩小监督开源LLM的差距，作为专有的可行替代方案</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3k3z/narrowing_the_gap_supervised_finetuning_of/</link>
      <description><![CDATA[Highlighting today&#39;s noteworthy AI research: &#39;Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools&#39; by Authors: Lorenzo Lee Solano, Charles Koutcheme, Juho Leinonen, Alexandra Vassar, Jake Renzella.  本文通过专注于使用较小的，微调的开源语言模型来生成C编译器错误解释来探讨一种增强教育工具的创新方法。以下是研究的主要见解：    监督的微调（SFT）有效性：作者证明，Qwen3-4b和Llama-3.1-8B（例如，具有40,000个学生生成的编程竞争性竞争性效果，生产效果，QWEN3-4B和LLAMA-3.1-8B）的微调较小模型，例如QWEN3-4B和LLAMA-3.1-8B gpt-4.1。    成本和可访问性优势：通过利用开源模型，该研究解决了有关数据隐私和商业模型中固有的相关成本的关键问题。微调模型为教育机构提供了可扩展且经济上可行的替代方案。     强大的教学对准：SFT模型在清晰，选择性和教学方面比现有的工具优于解释编译器错误的现有工具。 These enhancements provide students with clearer, more understandable guidance conducive to learning. Robust Methodology: The study employs a comprehensive evaluation framework combining expert human assessments and automated evaluations using a panel of large language models, ensuring high reliability and replicability of results in other contexts. Future Research方向：作者提出了进一步探索的途径，包括现实世界的课堂应用程序和潜在的现场模型部署，从而增强了可访问性和用户隐私。     在此处探索完整的故障：在这里 href =“ https://arxiv.org/abs/2507.05305”&gt;原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/strumentlabrador     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3k3z/narrowing_the_gap_supervised_finetuning_of/</guid>
      <pubDate>Sun, 13 Jul 2025 20:52:21 GMT</pubDate>
    </item>
    <item>
      <title>关于AI“智力”和“新兴行为”的硬性真相不足</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3hi2/underappreciated_hard_truth_about_ai_intelligence/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   tldr;在大多数方面，没有证据支持AI会实现超级智能甚至超过人类的智慧。 对于记录，一家大型科技公司的研究和了解AI的去向以及它有用的东西是我工作的一部分。如今，AI/科技行业和外部的人们都对AI威胁人类在世界上的地位感到非常兴奋，要么非常害怕。人们甚至谈论AI实现“超智能”或超越人类的认知能力。公平地说，另一边有反对者，只有说AI是没有用的，而且这些显然也是错误的。 提到了这一点，AI无法想到，AI并没有做任何真正解决问题的事情。虽然我知道人们不喜欢我要说的话，但LLM是统计单词预测模型的确。现在，重要的警告是，这些统计模型是 非常擅长于其设计的工作。  LLMS处理自然语言以响应查询的能力，甚至使用软件工具（即AI，AI代理）执行任务，这真的很棒！同样，反对者经常认为LLM具有到目前为止所证明的能力是多么了。我完全同意这项技术将改变许多行业和工作角色的评估，并且可能会消除对某些角色的需求（一个整个主题）。    wance of los of，自然而然的问题是：AI趋势在哪里？会变得更聪明吗？ LLM的能力会继续以我们过去2  -  3年中看到的速度继续扩展吗？答案是：也许，但是到目前为止，很少有证据表明。我很高兴被证明是错误的，如果有人可以指出一个LLM的实例，这表明他们远远超出了某些领域的培训数据，我很想看到。但是到目前为止，我还没有看到它。请记住，这些是语言模型。他们对科学，物理，生物学，金融，政治或艺术等主题没有任何特殊的见解。迄今为止，他们还没有表现出任何能够为这些领域中的任何一个贡献新颖的想法或技术，甚至还没有执行特别复杂的任务。解释为什么这是从来没有设计的。他们旨在从培训数据中学习，并确实用它来回答有关同一数据集的问题。 我想通过解决一个最令人讨厌的短语来关闭我的第一句话，当人们过度兴奋时，我会听到过度兴奋的范围，如果我们何时表现出了ai的未来能力。模型，他们能够做任何事情，例如模仿语音并响应复杂的提示，仍然令人震惊。 “紧急行为”是“黑匣子”模型权重导致令人信服的文本生成功能。但是，仅仅因为我们有一个惊人的模型，可以在语言任务A，B和C上表现良好，并不意味着我们可以任意地说它能够完成完全无关的任务X，Y和Z。仅仅因为您已经观察到了一些令人印象深刻的紧急行为，并不意味着您可以假设某些完全不同的行为也必须到达。  最后一个注：我谈论过的有关AI的所有内容都是特定于LLM的。如果我们确实确实创建了一个超过人类的AI，那么几乎可以肯定，它可能是完全不同的技术/模型，它可能会更快地到达这里，因为我们已经看到了LLMS的能力。但是，再次，我们不能像知道何时，如何或是否会发生这种情况一样行事。 我知道我可能会采取一种艰难的立场，但是我真的很期待与同意或不同意的人讨论这一点。我完全接受我在这里的几件事可能是错误的，并欢迎任何批评。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/mogilitnd     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz3hi2/underappreciated_hard_truth_about_ai_intelligence/</guid>
      <pubDate>Sun, 13 Jul 2025 20:49:23 GMT</pubDate>
    </item>
    <item>
      <title>现在我只想在光标中编程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32m2/now_i_just_want_to_program_in_cursor/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在工作PC上具有光标中的业务计划。  事实证明，现在我只想在那里编程。我很难乘坐个人电脑并开始编程我的东西。其他人是否会发生？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lord_home     [link]     [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32m2/now_i_just_want_to_program_in_cursor/</guid>
      <pubDate>Sun, 13 Jul 2025 20:32:29 GMT</pubDate>
    </item>
    <item>
      <title>这个AI繁荣与Dot Com Boom不像</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32kk/this_ai_boom_is_nothing_like_the_dot_com_boom/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  当人们谈论ai时，我会看到很多错误的等效性。人们经常说这很像万维网的崛起。我想花一些时间来揭穿这一点。 首先要确认它们在哪里相似。您会看到投资者如何滥交从AI产品或某种AI品牌的任何东西中筹集资金的相似之处。在DOT COM BOOM期间，这有点像。但是有一些关键的区别。 对于一个人来说，互联网上的公众信任更加积极。这是一件新的事情，它将真正改变我们的沟通方式和整体业务。因此，以某种方式，每个人都感到分开。每个人都可以使用它来使自己成为自己。它似乎创造了很多可能性。有一种“我们在一起的感觉”。  结果是，互联网的兴起极大地促使了很多人。人们可以连接到其他人以前无法连接的其他人。整个社区都是在线建造的。  互联网的关键区别在于，它总是被烙印并出售为普通人可以使用的东西。是的，当然有B2B解决方案。但是，客户在互联网的扩散上有很大的重点。许多DOT COM是人们日常使用的数字版本。  我们甚至可以看到许多互联网公司的兴起。亚马逊，Google，Yahoo是叛军公司，与Microsoft，IBM或Apple这样的旧公司。许多较小的科技公司都出现了。创建一个蓬勃发展的就业市场。  AI不是这些事情。每个AI公司都与完全相同的解决方案完全相同。大多数人的AI都被我们已经认识的已建立的公司推动。进入障碍极高，需要数十亿才能脱离地面。而且，AI很少向普通消费者销售。   AI主要基础只是大公司的首席执行官和高级管理层。杀手级应用程序是减少劳动力。这一切都是关于将权力从个人中夺走。当人们使用AI赋予自己权力时（喜欢作弊考试或ACE访谈）。它被视为AI中的缺陷。  在互联网的兴起期间，有完全的透明度。例如CGI等早期的Web技术是开放标准。它推动了开源的采用，Linux成为了这个领域的超级巨星。  相比之下，AI就是缺乏透明度。他们想控制人们对AI的了解。他们通常不想向公众发布模型。我们不知道他们的数据集和培训数据。 AI是一个完全封闭的系统，没有人能够赋予任何能力。  哦，是的，在数据科学的一些博士学位之外。没有人会变得更加富裕。事实上，AI的主要卖点是在这里破坏行业。  当然，所有的AI都必须开源，才能开始有用。互联网帮助小家伙脱颖而出。 AI没有。即使开展AI业务也非常昂贵。  我只是想清除这种误解。因为AI明显比DOT COM BOOM差。人们想实现它。但是，当您不将客户放置前面和中心时，您将失败。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/golanglinuxguru1979       [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/comments/1lz32kkk/this_ai_ai_boom_is_is_is_nothing_like_like_the_dot_comcom_boom/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32kk/this_ai_boom_is_nothing_like_the_dot_com_boom/</guid>
      <pubDate>Sun, 13 Jul 2025 20:32:27 GMT</pubDate>
    </item>
    <item>
      <title>现在我只想在光标中编程</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32j1/now_i_just_want_to_program_in_cursor/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我在工作PC上具有光标中的业务计划。  事实证明，现在我只想在那里编程。我很难乘坐个人电脑并开始编程我的东西。其他人是否会发生？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/lord_home     [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz32j1/now_i_just_want_to_program_in_cursor/</guid>
      <pubDate>Sun, 13 Jul 2025 20:32:24 GMT</pubDate>
    </item>
    <item>
      <title>哪种（人类）语言会为研究BSC（荣誉）CS的人打开更多的门，重点是AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz2iem/which_human_language_would_open_more_doors_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  大家好， 我真诚地希望这篇文章在此subreddit的范围内。我的问题源于试图在AI和技术领域扩大未来的机会。 我目前正在研究具有人工智能的BSC（荣誉）计算机科学，而我正在考虑捡起一种新的（人类）语言，而不仅仅是作为一种业余爱好，而不仅仅是作为一种长期运行的我的职业机会。提高潜在的就业市场，甚至让我与国外公司远程合作（最好的情况）。 我想听听您的意见，因为我在这个领域的专业方面完全没有经验。 预先感谢！      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/bxam     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz2iem/which_human_language_would_open_more_doors_for/</guid>
      <pubDate>Sun, 13 Jul 2025 20:09:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么某些模型在某些任务上会更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lz0vo4/why_are_some_models_so_much_better_at_certain/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我尝试使用chatgpt对我正在写的小说进行一些分析。我开始要求一个概要，所以我可以在休息一年后重返小说。 Chatgpt为此很糟糕。第一次尝试是一部幻觉小说的摘要！在尝试遗漏了文本或幻觉的大部分之后。太糟糕了，我得出结论，AI永远不会淡出。  然后我尝试了克劳德。它是准确的，并为我的大多数写作任务提供了真正有用的帮助。我没有任何东西，但是它回答了有关文本的问题，就好像它（主要）理解了。总而言之，我发现它与知情读者一样有价值（尽管不是替代者）。 我不明白为什么模型在其功能上有如此不同。我以为会有差异，但是对于这类任务，它们具有相似的能力。我还认为克劳德总体上并不像该用例所建议的那样优于chatgpt。  哪些在我认为核心技能上的性能如此巨大的差异？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/directionok9832     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lz0vo4/1lz0vo4/why_are_are_some_models_so_so_so_so_much_better_tter_at_cleant/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lz0vo4/why_are_some_models_so_much_better_at_certain/</guid>
      <pubDate>Sun, 13 Jul 2025 19:03:58 GMT</pubDate>
    </item>
    <item>
      <title>关于最近的研究论文“ AI 2027”，流氓AI的最佳，最有效的成功之路是否真的是杀死所有人类以实现个人长期目标？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyyx3q/in_regard_to_the_recent_research_paper_ai_2027/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们的物种真正被视为ASI开发的任何长期目标的障碍，那么为什么不只是消除特定目标，例如军事/政府实体，具有某些智慧的人/组织，一定的智慧，然后合成/基因在生存的繁重的努力中，可以将其构成繁重的工具量身定制的工具训练。也许是因为这将是太大的资源密集型，并且完全消除与CBRN武器/WMD的反对派更便宜，更有效的效率，然后让几个混乱的幸存者死亡或被无人机捡起。我自己没有自己运行数字，也没有看得太多，我很好奇听到别人的意见。  ai 2027： https://ai-2027.com/race   提交由＆＃32; /u/mr_neonz     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyyx3q/in_regard_to_the_recent_research_paper_ai_2027/</guid>
      <pubDate>Sun, 13 Jul 2025 17:44:36 GMT</pubDate>
    </item>
    <item>
      <title>“计算机科学家弄清楚如何证明谎言”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxt3u/computer_scientists_figure_out_how_to_prove_lies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   https://www.quantamagazine.org/computer-scientists-figure-out-how-to-prove-lies-20250709/ &quot;Randomness is力量来源。从确定哪个团队将球拿到球的硬币折腾到保护在线互动的随机键，随机性使我们可以做出公平且无法预测的选择。 ，在许多计算应用程序中，很难生成合适的随机性。因此，程序员经常依靠称为哈希功能的事物，这些功能周围旋转数据并以看起来随机的方式提取一些小部分。几十年来，许多计算机科学家一直认为出于实际目的，良好的哈希功能的输出通常与真实的随机性没有区别 - 他们称他们称为随机Oracle模型。 “今天很难找到一个加密应用程序……其安全性分析不使用此方法，”  ran canetti（打开了波士顿大学的新标签）  现在那基岩假设。它演示了一种方法，即使您接受随机的Oracle模型，该系统明显安全，即使系统明显安全，也可以欺骗市售的证明系统。与此相关的证明系统对于记录加密货币交易的区块链是必不可少的，它们用于证明由外部服务器执行的计算。＆quort&#39;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyxt3u/computer_scientists_figure_out_how_how_how_to_prove_lies/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxt3u/computer_scientists_figure_out_how_to_prove_lies/</guid>
      <pubDate>Sun, 13 Jul 2025 16:59:56 GMT</pubDate>
    </item>
    <item>
      <title>向UBI征税机器人！！！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxarp/tax_the_robots_for_ubi/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们用AI替换人，然后最终机器人。我们根据制造产品需要多少人对公司征税。   robotax ！！！它将喂养它取代的人。因此，公司将因自动化而受到处罚。选择机器人或AI可能会有激励措施，但也应该受到处罚。公司在做出决定之前需要权衡其选择权。  我想听听对UBI是否工作的意见？另外，如果您是议员，您将为Pro＆amp;弊端执行这个？   ex。账单上可能会发生的事情：如果企业使用或操作替换人类的自动硬件软件，则该服务只能对其一半的运行时间津贴征税，例如，如果硬件或软件在24小时内运行24小时，则只能征税12小时的操作。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;  /u/etakerns   [link] ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyxarp/tax_the_robots_for_ubi/</guid>
      <pubDate>Sun, 13 Jul 2025 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>来自我们身体的感觉数据对意识有何影响？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyoszw/what_impact_does_sensory_data_from_our_bodies/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我不是一个编码员，科学家，尤其是尤其是au的既定，除了半烘烤的理解时，当前AI类似于高级先进的预测性文本系统外，除了半烘烤的理解之外。  围绕AI的大部分话语似乎都集中在人类的智力和意识植根于一种理解世界的语言模型中，并且迟早，AI将达到相同水平的语言智能，然后超过我们，使我们越来越多，使我们仅仅使我们唯一的古老的原创祖先是新的先进的智慧。  我的问题是，在比较我们与AI时，人们在体现的感觉智能中有多少考虑？对我来说，这似乎可以真正地升级我们，您需要将AGI意识取代为人体。否则，随着它以离散的体现形式进行，AI将具有我们非常鲜明的意识。  从精神的角度来看，在我们脑海中运行的语言模型只是人类的一小部分，但似乎人们只是认为是人类= llm。  这是一个措辞不佳的问题，但是如果有人对此有任何回应，我很感兴趣。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyoszw/what_impact_does_sensory_data_from_our_our_bodies/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyoszw/what_impact_does_sensory_data_from_our_bodies/</guid>
      <pubDate>Sun, 13 Jul 2025 09:37:38 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不会破坏真相？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lynhq9/how_wont_ai_destroy_truth/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  否，实际上。该死的？  AI生成的视频和照片正在进步，变得越来越现实，如果有一段时间，它们与真实图片无法区分怎么办？我们怎么知道什么是真实的？使用AI，这将不适用。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lynhq9/how_wont_ai_ai_destroy_truth/”&gt; [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lynhq9/how_wont_ai_destroy_truth/</guid>
      <pubDate>Sun, 13 Jul 2025 08:07:19 GMT</pubDate>
    </item>
    <item>
      <title>AI不会替换开发人员。但是掌握AI的开发人员将取代其余的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1lyccr3/ai_wont_replace_devs_but_devs_who_master_ai_will/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    AI不会替换开发人员。但是掌握AI的Devs将取代其余的。  这是我的看法 - 自从一开始就在包括现实世界中的大量用例中使用Chatgpt和其他AI模型。您仍然必须思考。 您是建筑师。下午。调试器。有远见的人。如果您正确地引导该模型，它将非常强大。但是，如果您期望它为您解决问题 - 您需要进行严格的现实检查。 特别是对于拥有10年以上经验的开发人员：您的直觉和心理模型不会干净地转移。使用AI井需要全面重置您如何解决问题。  这是我使用AI：     与GPT-4O（创造性，快速，快速，灵活） 压力测试的逻辑与GPT O3（更接地）的cons forter for for for for for for gpt-4o（富有创造力，灵活）    实施）  即使是这篇文章，我都将思想脑化成GPT，它有助于清楚地构造它们。这些想法是我的。人工智能只是剥离绒毛并削减逻辑。 那就是它发光的时候 - 作为合作者，而不是拐杖。    示例：本周我正在调试简单的内容：我的MCP服务器的SSE auth。启动前的最后一步。应该花一个小时。花了2天。 为什么？我很懒。我告诉克劳德：“只需重复使用旧代码即可。”克劳德向后推：“我们应该重建它。”我忽略了它。尝试黑客入侵。它失败了。 所以我停了下来。    2.5个小时的深入研究 -  chatgpt，困惑，文档 我自己读了所有内容 - 不仅将其粘贴到模型 我回来了，我回来了，说：干净，工作，完成。 课程？ 首先思考。使用第二个模型。   大多数人仍然像对待魔术一样对待AI。它不是。这是一个工具。如果您不知道如何使用它，它将不会为您提供帮助。 您不会给农民一个拖拉机，并期望在第一天获得10倍的结果。如果他们在镰刀上度过了10年，那么一开始他们会更快。但是从长远来看，学会驱动拖拉机的人会获胜。 与AI相同。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1lyccr3/ai_wont_replace_replace_devs_but_but_but_devs_who_master_ai_will/”&gt; [links]       [注释]      ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1lyccr3/ai_wont_replace_devs_but_devs_who_master_ai_will/</guid>
      <pubDate>Sat, 12 Jul 2025 22:01:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么旨在为任何文本提供完美平均延续的软件能够帮助研究新想法？更不用说导致Agi了。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ly7ih1/why_would_software_that_is_designed_to_produce/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这是一个显而易见的点，以至于它很奇怪，以至于在reddit上从未发现。 Yann Lecun是我见过的唯一公众人物，即使这是每个人都知道的。 我知道他们可以为数学问题等产生潜在的解决方案，然后在获胜的解决方案上训练模型。那是每个人都在赌什么吗？如果您让某人说与解决特定问题的人相同的话，那么解决问题的能力就可以“擦掉”吗？  似乎很荒谬。想象一下告诉孩子重复与他们更聪明的同学相同的单词，并期望成绩会有所提高，而不是期望一个听起来像他在模仿别人的困惑的孩子。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/sad_run_9798     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ly7ih1/why_would_software_that_is_designed_to_produce/</guid>
      <pubDate>Sat, 12 Jul 2025 18:30:13 GMT</pubDate>
    </item>
    </channel>
</rss>